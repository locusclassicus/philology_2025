[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Программирование на R для филологов",
    "section": "",
    "text": "Введение",
    "crumbs": [
      "Введение"
    ]
  },
  {
    "objectID": "index.html#об-этом-курсе",
    "href": "index.html#об-этом-курсе",
    "title": "Программирование на R для филологов",
    "section": "Об этом курсе",
    "text": "Об этом курсе\nЭтот сайт содержит материалы к курсу “Программирование на R для филологов” для магистерской программы НИУ ВШЭ “Русская литература и компаративистика”.",
    "crumbs": [
      "Введение"
    ]
  },
  {
    "objectID": "index.html#программа",
    "href": "index.html#программа",
    "title": "Программирование на R для филологов",
    "section": "Программа",
    "text": "Программа\nКурс 2025/2026 г. читается два модуля и включает в себя 8 основных тем.\nМодуль 1. Основы работы в R\n\nНачало работы. Контроль версий.\nТабличные данные. Анализ датасета.\nРаспознавание изображений.\nНормализация. Регулярные выражения.\n\nМодуль 2. Редакторские инструменты\n\nОсновы работы с TEI XML.\nДобавление разметки с использованием LLM.\nПубликационная система Quarto.\nКонсолидирующий проект.",
    "crumbs": [
      "Введение"
    ]
  },
  {
    "objectID": "index.html#расписание",
    "href": "index.html#расписание",
    "title": "Программирование на R для филологов",
    "section": "Расписание",
    "text": "Расписание\nЗанятия в первом модуле: 6 и 13 сентября, 4 и 18 октября Занятия во втором модуле: 1, 15 и 29 ноября, 13 декабря.",
    "crumbs": [
      "Введение"
    ]
  },
  {
    "objectID": "index.html#оценивание",
    "href": "index.html#оценивание",
    "title": "Программирование на R для филологов",
    "section": "Оценивание",
    "text": "Оценивание\nДве домашние, одна лабораторная и проект в каждом модуле.",
    "crumbs": [
      "Введение"
    ]
  },
  {
    "objectID": "index.html#благодарности",
    "href": "index.html#благодарности",
    "title": "Программирование на R для филологов",
    "section": "Благодарности",
    "text": "Благодарности\nВ разработке этого курса мне помогало множество людей: Дарья Глебова, Александра Горшенина, Георгий Мороз, Борис Орехов, Софья Порфирьева, Анастасия Орлова, Екатерина Гуреева, Анастасия Богданова и многие другие. Все недостатки остаются на моей совести.",
    "crumbs": [
      "Введение"
    ]
  },
  {
    "objectID": "index.html#обратная-связь",
    "href": "index.html#обратная-связь",
    "title": "Программирование на R для филологов",
    "section": "Обратная связь",
    "text": "Обратная связь\nЭтот курс находится в разработке. Если вы заметили ошибку или опечатку, можно сообщить по почте oalieva@hse.ru или оставить issue в репозитории курса на GitHub.",
    "crumbs": [
      "Введение"
    ]
  },
  {
    "objectID": "start.html",
    "href": "start.html",
    "title": "1  Начало работы",
    "section": "",
    "text": "1.1 Установка R и RStudio\nМы будем использовать R, так что для занятий понадобятся:\nВместо RStudio можно поставить VS Code или Positron. По сути, Positron – это тот же VS Code, но без необходимости устанавливать расширения.\nМы будем использовать следующую версию R:\nR version 4.5.0 (2025-04-11)\nДля работы в облаке ☁️ можно использовать RStudio Cloud, но в бесплатной версии есть ограничения.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Начало работы</span>"
    ]
  },
  {
    "objectID": "start.html#установка-r-и-rstudio",
    "href": "start.html#установка-r-и-rstudio",
    "title": "1  Начало работы",
    "section": "",
    "text": "R\n\nна Windows\nна Mac\nна Linux.\n\nRStudio — IDE для R (можно скачать здесь)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Начало работы</span>"
    ]
  },
  {
    "objectID": "start.html#знакомство-с-r-rstudio",
    "href": "start.html#знакомство-с-r-rstudio",
    "title": "1  Начало работы",
    "section": "1.2 Знакомство с R & RStudio",
    "text": "1.2 Знакомство с R & RStudio\nRStudio — основная среда разработки (IDE) для R. После установки R и RStudio можно открыть RStudio и перед вами предстанет что-то похожее на изображение ниже:\n\n\n\nRStudio при первом открытии\n\n\nПосле нажатия на двойное окошко чуть левее надписи Environment откроется окно скрипта.\n\n\n\nПодокна RStudio\n\n\nВсе следующие команды можно:\n\nвводить в окне консоли, и тогда для исполнения следует нажимать клавишу Enter.\nвводить в окне скрипта, и тогда для исполнения следует нажимать клавиши Ctrl/Cmd + Enter или на команду Run на панели окна скрипта. Все, что введено в окне скрипта можно редактировать как в любом текстовом редакторе, в том числе сохранять Ctrl/Cmd + S.\n\nДля начала попробуйте получить информацию о сессии, введя в консоли такую команду:\n\nsessionInfo()\n\nsessionInfo() – это функция. О функциях можно думать как о глаголах (“сделай то-то!”). За названием функции всегда следуют круглые скобки, внутри которых могут находиться аргументы функции. Аргументы – это что-то вроде дополнений и обстоятельств. Аргументы могут быть обязательные и необязательные. Чтобы узнать, каких аргументов требует функция, надо вызывать help: ?mean(). В правой нижней панели появится техническая документация. Но также можно воспользоваться функцией args(). Попробуйте набрать в консоли args(round).\n\n\n\n\n\n\nВопрос\n\n\n\nСколько аргументов функции round() имеют значения по умолчанию?\n\n\nОтвет: \n\n1.2.1 Пакеты\nПосле установки R вы получите доступ к уже готовым методам статистического анализа и инструментам для визуализации. Если в базовой инсталляции R нет нужного решения – надо поискать в библиотеке пакетов. Пакет – это набор функций и иногда датасетов, созданный пользователями. На 1 июля 2023 г. в репозитории CRAN доступно 19789 пакетов. И это далеко не все: многие пакеты доступны только на GitHub.\n\n\n\n\n\n\nНа заметку\n\n\n\nНекоторые функции, которые вы найдете в пакетах, частично дублируют друг друга – это нормально, как и в естественном языке, “сказать” что-то можно разными способами.\n\n\nПо технической документации и так называемым “виньеткам” можно понять, какой пакет вам нужен. Например, вот так выглядит виньетка пакета RPerseus, при помощи которого можно получить доступ к корпусу греческой и латинской литературы.\nБывают еще “пакеты пакетов”, то есть очень большие семейства функций, своего рода “диалекты” R. Таково семейство tidyverse, объединяемое идеологией “опрятных” данных. Про него мы еще будем говорить.\nПакеты для работы устанавливаются один раз, однако подключать их надо во время каждой сессии. Чтобы установить новый пакет, можно воспользоваться меню Tools &gt; Install Packages. Также можно устанавливать пакеты из консоли. Установим пакет с интерактивными уроками программирования на языке R:\n\ninstall.packages(\"swirl\")\n\nДля подключения используем функцию library(), которой передаем в качестве аргумента название пакета без кавычек:\n\nlibrary(swirl)\n\n\n\n1.2.2 Рабочая директория\nПеред началом работы проверьте свою рабочую директорию при помощи getwd(). Для смены можно использовать как абсолютный, так и относительный путь:\n\nsetwd(\"/Users/name/folder\")\n\n# искать в текущей директории\nsetwd(\"./folder\")\n\n# перейти на уровень вверх\nsetwd(\"../\")\n\nТакже для выбора рабочей директории можно использовать меню R Session &gt; Set Working Directory.\n\n\n1.2.3 R как калькулятор\nМожно использовать R как калькулятор. Для этого вводим данные рядом с символом приглашения &gt;, который называется prompt.\n\nsqrt(4) # квадратный корень\n\n[1] 2\n\n2^3 # степень\n\n[1] 8\n\nlog10(100) #логарифм\n\n[1] 2\n\n\nЕсли в начале консольной строки стоит +, значит предыдущий код не завершен. Например, вы забыли закрыть скобку функции. Ее можно дописать на следующей строке. Попробуйте набрать sqrt(2 в консоли.\n\n\n1.2.4 Операторы присваивания\nЧтобы в окружении появился новый объект, надо присвоить результат вычислений какой-нибудь переменной при помощи оператора присваивания &lt;- (Alt + - (Windows) или Option + - (Mac)). Знак = также работает как оператор присваивания, но не во всех контекстах, поэтому им лучше не пользоваться.\n\nx &lt;- 2 + 2 # создаем переменную\ny &lt;- 0.1 # создаем еще одну переменную\nx &lt;- y # переназначаем  \nx + y\n\n[1] 0.2\n\n\nСочетание клавиш для оператора присваивания: Option/Alt + -. Имя переменной, как и имя функции, может содержать прописные и строчные буквы, точку и знак подчеркивания.\nТеперь небольшое упражнение.\n\n\n\n\n\n\nЗадание\n\n\n\nУстановите курс программирования на R: install_course(\"R Programming\"). После этого привяжите пакет командой library(swirl) и наберите: swirl(). Укажите ваше имя. Пройдите урок 1 Basic Building Blocks.\n\n\nЕсли все получилось, можно двигаться дальше! Но сначала зафиксируем несколько новых функций из этих первого урока.\n\n\n\n\n\n\nВопрос\n\n\n\nЧто вычисляет функция abs()?\n\n\nОтвет: среднеемодульквадратный корень\n\n\n\n\n\n\nВопрос\n\n\n\nСколько значений вернет функция, если разделить c(2, 4, 6) на 2?\n\n\nОтвет: \n\n\n\n\n\n\nВопрос\n\n\n\nБуква “c” в названии функции c() означает…\n\n\nОтвет: covercollapseconcatenate\n\n\n1.2.5 Пайпы (конвееры)\nВ нашем коде мы часто будем использовать знаки конвеера (или пайпы): |&gt; (в вашей версии он может выглядить иначе: %&gt;%; переключить оператор можно в Global Options). Они призваны показывать последовательность действий. Сочетание клавиш: Ctrl/Cmd + Shift + M.\n\nmean(sqrt(abs(sin(1:100)))) \n\n[1] 0.7654264\n\n1:100 |&gt; \n  sin() |&gt; \n  abs() |&gt; \n  sqrt() |&gt; \n  mean()\n\n[1] 0.7654264\n\n\n\n\n1.2.6 Векторы\nВектор – это объект, предназначенный для хранения данных. К таким же объектам относятся также матрицы, списки, датафреймы и др. Заметим, что в языке R нет скаляров (отдельных чисел). Числа считаются векторами из одного элемента.\n\nx &lt;- 2\nclass(x) # числовой вектор\n\n[1] \"numeric\"\n\nlength(x) # длина вектора\n\n[1] 1\n\n\nКак вы уже поняли, функция c() позволяет собрать несколько элементов в единый вектор:\n\nx &lt;- c(3, 5, 7)\nx_mean &lt;- mean(x) \nx_mean\n\n[1] 5\n\n\n Над векторами можно совершать арифметические операции, но будьте внимательны, применяя операции к векторам разной длины: в этом случае более короткий вектор будет переработан, то есть повторен до тех пор, пока его длина не сравняется с длиной вектора большей длины.\n\nx &lt;- 2\ny &lt;- c(10, 20, 30)\ny / x \n\n[1]  5 10 15\n\nx + y \n\n[1] 12 22 32\n\n\nВекторы можно индексировать, то есть забирать из них какие-то элементы:\n\nx &lt;- seq(1, 5, 0.5)\nx[4:5] # индексы начинаются с 1 (в отличие от Python)\n\n[1] 2.5 3.0\n\n\nВектор может хранить данные разных типов:\n\nцелое число (integer);\nчисло с плавающей точкой (numeric, также называются double, то есть число двойной точности);\nстроку (character);\nлогическую переменную (logical);\nкатегориальную переменную, или фактор (factor).\n\n\n# проверить тип данных \nx &lt;- sqrt(2)\nclass(x)\n\n[1] \"numeric\"\n\nis.integer(x)\n\n[1] FALSE\n\nis.numeric(x)\n\n[1] TRUE\n\n\nСоздавать векторы можно не только при помощи c(). Вот еще два способа.\n\nseq(1, 5, 0.5)\n\n[1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0\n\nrep(\"foo\", 5)\n\n[1] \"foo\" \"foo\" \"foo\" \"foo\" \"foo\"\n\n\n\nФакторы внешне похожи на строки, но в отличие от них хранят информацию об уровнях категориальных переменных. Уровень может обозначаться как числом (например, 1 и 0), так и строкой.\n\nt &lt;- factor(c(\"A\", \"B\", \"C\"), levels = c(\"A\", \"B\", \"C\"))\nt\n\n[1] A B C\nLevels: A B C\n\n\nВажно: вектор может хранить данные только одного типа. При попытке объединить в единый вектор данные разных типов они будут принудительно приведены к одному типу:\n\nx &lt;- c(TRUE, 1, 3, FALSE)\nx # логические значения приведены к числовым\n\n[1] 1 1 3 0\n\ny &lt;- c(1, \"a\", 2, \"лукоморье\") \ny # числа превратились в строки\n\n[1] \"1\"         \"a\"         \"2\"         \"лукоморье\"\n\n\nЛогические векторы можно получить в результате применения логических операторов (== “равно”, != “не равно”, &lt;= “меньше или равно”) к данным других типов:\n\nx &lt;- 1:10 # числа от 1 до 10\ny &lt;- x &gt; 5\ny # значения TRUE соответствуют единице, поэтому их можно складывать\n\n [1] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n\nsum(y)\n\n[1] 5\n\n\nФункции all() и any() также возвращают логические значения:\n\nx &lt;- 10:20 \nany(x == 15)\n\n[1] TRUE\n\nall(x &gt; 9)\n\n[1] TRUE\n\n\n\n\n1.2.7 Отсутствие данных\nОтсутствие данных любого типа в R передается двумя способами. NULL означает, что значение не существует. Например, если мы создадим пустой вектор, то при попытке распечатать его получим NULL. А вот длина пустого вектора равна нулю!\n\ny &lt;- c() \ny \n\nNULL\n\nlength(y) \n\n[1] 0\n\n\nNA (not available) указывает на то, что значение существует, но оно неизвестно. Любые операции с NA приводят к появлению новых NA! Сравните:\n\nx &lt;- c(1, NA, 2)\nmean(x)\n\n[1] NA\n\ny &lt;- c(1, NULL, 2)\nmean(y)\n\n[1] 1.5\n\n\nКак проверить, есть ли в данных NA или NULL? Знак == здесь не подойдет.\n\nx &lt;- NA\nx == NA\n\n[1] NA\n\ny &lt;- NULL\ny == NULL\n\nlogical(0)\n\n\nДля этого есть специальные функции.\n\nis.na(x)\n\n[1] TRUE\n\nis.null(y)\n\n[1] TRUE\n\n\n\nWhen some people first get to R, they spend a lot of time trying to get rid of NAs. People probably did the same sort of thing when zero was invented. NA is a wonderful thing to have available to you. It is seldom pleasant when your data have missing values, but life if much better with NA than without.\nBurns (2012)\n\nКак избавиться от NA? В некоторых случаях достаточно аргумента функции.\n\nmean(c(1, NA, 2), na.rm=T) \n\n[1] 1.5",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Начало работы</span>"
    ]
  },
  {
    "objectID": "start.html#контроль-версий-с-git",
    "href": "start.html#контроль-версий-с-git",
    "title": "1  Начало работы",
    "section": "1.3 Контроль версий с GIT",
    "text": "1.3 Контроль версий с GIT\n\n1.3.1 Установка GIT\n\nСначала надо создать учетную запись на GitHub. https://github.com/\nПотом поставить локально Git https://git-scm.com/downloads.\n\nПосле установки перезапустите RStudio.\nПроверьте установку в терминале:\n\ngit --version\n\n\n\n1.3.2 Настройка GIT и связска с RStudio\nОткройте терминал (Git Bash на Windows или Terminal на macOS). Укажите имя, email (тот же, что на GitHub), и ветку по умолчанию.\n\ngit config --global user.name \"Ваше Имя\"\ngit config --global user.email your_email@example.com\ngit config --global init.defaultBranch main\ngit config --list\n\n\nRStudio: Tools &gt; Global Options &gt; Git/SVN.\nУбедитесь, что выбран Git и путь к git.exe корректен. Apply/OK.\nСоздайте SSH-ключ:\n\nTools &gt; Global Options &gt; Git/SVN &gt; Create RSA Key, дождитесь генерации, Close.\nНажмите View public key и скопируйте ключ.\nGitHub: Settings &gt; SSH and GPG keys &gt; New SSH key.\nВставьте публичный ключ, задайте понятный Title, подтвердите.\n\n\n\n\n1.3.3 Создание репозитория и проекта RStudio\n\nНа GitHub: New repository → задайте имя и описание → Create repository.\n\nСкопируйте SSH-URL вида git@github.com:username/repo.git.\n\nВ RStudio: File &gt; New Project &gt; Version Control &gt; Git → вставьте URL → выберите папку → Create Project.\n\nRSTudio создаст локальный проект, связанный с удалённым репозиторием.\n\n\n1.3.4 Базовый рабочий цикл\n\nВносите изменения в файлы проекта.\nВкладка Git в RStudio:\n\nОтметьте (Stage) нужные файлы → Commit (введите сообщение) → Push (отправка на GitHub).\n\nДля получения изменений из GitHub используйте Pull.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Начало работы</span>"
    ]
  },
  {
    "objectID": "start.html#видео-к-этому-уроку",
    "href": "start.html#видео-к-этому-уроку",
    "title": "1  Начало работы",
    "section": "1.4 Видео к этому уроку",
    "text": "1.4 Видео к этому уроку\n\nВидео 2025 г.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Начало работы</span>"
    ]
  },
  {
    "objectID": "start.html#домашнее-задание",
    "href": "start.html#домашнее-задание",
    "title": "1  Начало работы",
    "section": "1.5 Домашнее задание",
    "text": "1.5 Домашнее задание\nВ форме сдачи оставьте ссылку на созданный вами репозиторий. Задание оценивается по шкале 0/1. Считается сданным, если выполнены все требования и соблюдён дедлайн.\nТребования:\n\nРепозиторий называется hellow_world.\nВ нём лежит файл под названием hello.R.\nВ файле есть код, который создаёт переменную hello с присвоенным ей любым значением.\nРепозиторий принадлежит тому пользователю, который сдаёт задание.\nРепозиторий не содержит служебные файлы .gitignore, .Rproj и т. п.\n\nДедлайн: 20 сентября, 21:00 мск.\n\n\n\n\nBurns, Patrick. 2012. The R inferno. Lulu.com.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Начало работы</span>"
    ]
  },
  {
    "objectID": "tabular.html",
    "href": "tabular.html",
    "title": "2  Табличные данные. Анализ датасета",
    "section": "",
    "text": "2.1 Импорт табличных данных\nВ этом уроке мы научимся работать с “прямоугольными”, т.е. табличными, данными на примере корпуса русской элегии 1815—1835 гг., собранного и опубликованного Антониной Мартыненко в 2020 г.\nСуществуют два основных “диалекта” R, один из которых опирается главным образом на функции и структуры данных базового R, а другой пользуется синтаксисом tidyverse. Tidyverse – это семейство пакетов (метапакет), разработанных Хадли Уикхемом и др., которое включает в себя в том числе пакеты dplyr, ggplot2 и многие другие.\nФайл можно скачать вручную по ссылке выше или воспользоваться специальной функцией.\nurl &lt;- \"https://dataverse.pushdom.ru/api/access/datafile/:persistentId?persistentId=doi:10.31860/openlit-2019.11-C001/6EPZFO\"\nВ окружении появится объект url. Это строка, т.е. последовательность символов. Передаем ее в качестве аргумента функции download.file(); вторым аргументом указываем название файла-назначения:\ndownload.file(url, destfile = \"elegies.tab\")\nПосле этого можно прочитать файл в окружение:\nelegies_tbl &lt;- read_tsv(\"elegies.tab\")\nRows: 509 Columns: 20\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (18): Signature, Author, Title, First line, Meter, Razmer, Razmer_wclaus...\ndbl  (2): id, Year1\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Табличные данные. Анализ датасета</span>"
    ]
  },
  {
    "objectID": "tabular.html#анализ-и-обобщение-данных",
    "href": "tabular.html#анализ-и-обобщение-данных",
    "title": "2  Табличные данные. Анализ датасета",
    "section": "2.2 Анализ и обобщение данных",
    "text": "2.2 Анализ и обобщение данных\n\n2.2.1 Tibble\nОсновная структура данных в tidyverse – это tibble, современный вариант датафрейма. Тиббл, как говорят его разработчики, это ленивые и недовольные датафреймы: они делают меньше и жалуются больше. Это позволяет решать проблемы на более ранних этапах, что, как правило, приводит к созданию более чистого и выразительного кода.\nОсновные отличия от обычного датафрейма:\n\nусовершенствованный метод print(), не нужно постоянно вызывать head();\nнет имен рядов;\nдопускает синтаксически “неправильные” имена столбцов;\nпри индексировании не превращается в вектор.\n\nПреобразуем наш тиббл в датафрейм для сравнения.\n\nelegies_df &lt;- as.data.frame(elegies_tbl)\n\n\n\n2.2.2 Dplyr\n“Грамматика манипуляции данных”, лежащая в основе dplyr, предоставляет последовательный набор глаголов, которые помогают решать наиболее распространенные задачи манипулирования данными:\n\nmutate() добавляет новые переменные, которые являются функциями существующих переменных;\nselect() выбирает переменные (столбцы) на основе их имен;\nfilter() выбирает наблюдения (ряды) на основе их значений;\nsummarise() обобщает значения;\narrange() изменяет порядок следования строк.\n\nВсе эти глаголы естественным образом сочетаются с функцией group_by(), которая позволяет выполнять любые операции “по группам”, и с оператором pipe |&gt; из пакета magrittr.\nВ итоге получается лаконичный и читаемый код. Узнаем, за какие года у нас есть элегии.\n\nelegies_tbl |&gt; \n  count(Year) |&gt; \n  print()\n\n# A tibble: 23 × 2\n   Year      n\n   &lt;chr&gt; &lt;int&gt;\n 1 1815      5\n 2 1816      8\n 3 1817     33\n 4 1818     13\n 5 1819     15\n 6 1820     33\n 7 1821     37\n 8 1822     29\n 9 1823     25\n10 1824     31\n# ℹ 13 more rows\n\n\nОтберем элегии 1824 г. и выясним, какие авторы их писали.\n\nelegies_tbl |&gt; \n  filter(Year == 1824) |&gt; # используем логический оператор для выбора\n  count(Author) |&gt;  #  можно задать  аргумент sort = TRUE\n  arrange(-n)  |&gt;   # не нужно, если sort = TRUE\n  print()\n\n# A tibble: 24 × 2\n   Author                  n\n   &lt;chr&gt;               &lt;int&gt;\n 1 Жуковский В.А.          3\n 2 Бестужев-Рюмин М.А.     2\n 3 Дмитриев М.А.           2\n 4 Павлов Н.Ф.             2\n 5 Туманский В.И.          2\n 6 Языков Н.М.             2\n 7 [**]                    1\n 8 [-й-]                   1\n 9 [2.17]                  1\n10 [Без подписи]           1\n# ℹ 14 more rows\n\n\n\n\n\n\n\n\nЗадание\n\n\n\nТеперь попробуйте сформулировать новые вопросы и ответить на них при помощи этого датасета.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Табличные данные. Анализ датасета</span>"
    ]
  },
  {
    "objectID": "tabular.html#импорт-текстовых-данных",
    "href": "tabular.html#импорт-текстовых-данных",
    "title": "2  Табличные данные. Анализ датасета",
    "section": "2.3 Импорт текстовых данных",
    "text": "2.3 Импорт текстовых данных\nСкачаем архив элегий и распакуем его.\n\nurl = \"https://dataverse.pushdom.ru/api/access/datafile/:persistentId?persistentId=doi:10.31860/openlit-2019.11-C001/SKGO9Q\"\n\ndownload.file(url, \"corpus.zip\")\n# trying URL 'https://dataverse.pushdom.ru/api/access/datafile/:persistentId?persistentId=doi:10.31860/openlit-2019.11-C001/SKGO9Q'\n# Content type 'application/zip; name=\"elegies_corpus.zip\";charset=UTF-8' length 806772 bytes (787 KB)\n# ==================================================\n# downloaded 787 KB\n\nПосле выполнения команды ниже в рабочей директории должна появиться папка corpus.\n\nunzip(\"corpus.zip\")\n\nЗаглянем в папку и сохраним список файлов.\n\nelegies_files &lt;- list.files(\"corpus\", full.names = TRUE)\n\nЧтобы распечатать пути к первым шести файлам, используйте команду head().\n\nhead(elegies_files)\n\n[1] \"corpus/1_DGlebov_1818.txt\"     \"corpus/10_Baratynsky_1820.txt\"\n[3] \"corpus/100_Pushkin_1825.txt\"   \"corpus/101_Jazykov_1825.txt\"  \n[5] \"corpus/102_Jazykov_1825.txt\"   \"corpus/103_Jazykov_1825.txt\"  \n\n\nСоздадим таблицу со всеми текстами и их id.\nСначала напишем небольшую вспомогательную функцию read_text. Тело функции всегда заключается в фигурные скобки. Эта функция читает построчно каждый файл, а затем “схлопывает” строки в единый вектор через пробел (это делает функция str_c() из пакета stringr). Функция map_chr() из пакета purrr позволяет запустить нашу “доморощенную” функцию 509 раз, по числу файлов (их список отдаем ей первым аргументом). Результат возвращается в виде длинного вектора, который мы превращаем в столбец нового тиббла.\n\nread_text &lt;- function(file){\n  read_lines(file) |&gt; \n    str_c(collapse = \" \")\n  }\n\nelegies_texts &lt;- tibble(\n  title = elegies_files, # в столбец title кладем имена файлов\n  text = map_chr(elegies_files, read_text) # в столбец text кладем тексты элегий\n  )\n\nelegies_texts |&gt; \n  print()\n\n# A tibble: 509 × 2\n   title                         text                                           \n   &lt;chr&gt;                         &lt;chr&gt;                                          \n 1 corpus/1_DGlebov_1818.txt     \"Надеясь сердца грусть разлукой облегчить, Беж…\n 2 corpus/10_Baratynsky_1820.txt \"Мечты волшебные, вы скрылись от очей! Сбылися…\n 3 corpus/100_Pushkin_1825.txt   \"Когда, любовию и негой упоенный, Безмолвно пр…\n 4 corpus/101_Jazykov_1825.txt   \"Счастлив, кто с юношеских дней, Живыми чувств…\n 5 corpus/102_Jazykov_1825.txt   \"Свободен я: уже не трачу Ни дня, ни ночи, ни …\n 6 corpus/103_Jazykov_1825.txt   \"Я знал живое заблужденье; Любовь певал я - бы…\n 7 corpus/104_Jazykov_1825.txt   \"Моя Камена ей певала; Но сила взора красоты Н…\n 8 corpus/105_Unknown_1826.txt   \"Время быстро Пролетает; Пламя жизни Угасает. …\n 9 corpus/11_Pushkin_1820.txt    \"Погасло дневное светило;  На море синее вечер…\n10 corpus/112_Jazykov_1824.txt   \"Скажи: воротишься ли ты,  Моя пленительная ра…\n# ℹ 499 more rows\n\n\nТеперь преобразуем столбец title: оставим только id.\n\nelegies_sep &lt;- elegies_texts |&gt; \n  mutate(title = str_remove(title, \"corpus/\")) |&gt; \n  separate(title, into = c(\"id\", NA)) |&gt;  # отбрасываем все после id \n  mutate(id = as.numeric(id))\n\nWarning: Expected 2 pieces. Additional pieces discarded in 509 rows [1, 2, 3, 4, 5, 6,\n7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, ...].\n\nelegies_sep |&gt; \n  print()\n\n# A tibble: 509 × 2\n      id text                                                                   \n   &lt;dbl&gt; &lt;chr&gt;                                                                  \n 1     1 \"Надеясь сердца грусть разлукой облегчить, Бежал я милых мест, неверно…\n 2    10 \"Мечты волшебные, вы скрылись от очей! Сбылися времени угрозы! Хладеет…\n 3   100 \"Когда, любовию и негой упоенный, Безмолвно пред тобой коленопреклонен…\n 4   101 \"Счастлив, кто с юношеских дней, Живыми чувствами убогой, Идет просело…\n 5   102 \"Свободен я: уже не трачу Ни дня, ни ночи, ни стихов За милый взгляд, …\n 6   103 \"Я знал живое заблужденье; Любовь певал я - были дни: Теперь умчалися …\n 7   104 \"Моя Камена ей певала; Но сила взора красоты Не мучала, не услаждала М…\n 8   105 \"Время быстро Пролетает; Пламя жизни Угасает. Нет замены Наслажденьям;…\n 9    11 \"Погасло дневное светило;  На море синее вечерний пал туман.  Шуми, шу…\n10   112 \"Скажи: воротишься ли ты,  Моя пленительная радость?  Ужель моя погасн…\n# ℹ 499 more rows",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Табличные данные. Анализ датасета</span>"
    ]
  },
  {
    "objectID": "tabular.html#объединение-данных",
    "href": "tabular.html#объединение-данных",
    "title": "2  Табличные данные. Анализ датасета",
    "section": "2.4 Объединение данных",
    "text": "2.4 Объединение данных\nТеперь мы можем объединить метаданные с конкретными текстами.\nОтберем из датасета только Пушкина и Баратынского (Пушкиных там двое, так что указываем инициалы. Вертикальная черта - это логичеческий оператор “ИЛИ”. Функция str_detect() возвращает логический вектор, который используется для фильтрации.\n\nelegies_selection &lt;- elegies_tbl |&gt; \n  filter(str_detect(Author, \"Баратынский |Пушкин А.С.\")) |&gt; \n  rename(First_line = `First line`) |&gt;  # убираем пробел из названия столбца\n  select(id, Author, Year, Source_name, Title, First_line)\n\nПосле этого объединяем два тиббла:\n\nelegies_joined &lt;- elegies_selection |&gt; \n  left_join(elegies_sep)\n\nJoining with `by = join_by(id)`",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Табличные данные. Анализ датасета</span>"
    ]
  },
  {
    "objectID": "tabular.html#токенизация",
    "href": "tabular.html#токенизация",
    "title": "2  Табличные данные. Анализ датасета",
    "section": "2.5 Токенизация",
    "text": "2.5 Токенизация\nРазделим тексты на токены. Для этого надо установить библиотеку tidytext.\n\nlibrary(tidytext)\nelegies_tokens &lt;- elegies_joined |&gt; \n  unnest_tokens(output = \"word\", input = \"text\")\n\nСлова можно лемматизировать, подробнее об этом см. здесь.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Табличные данные. Анализ датасета</span>"
    ]
  },
  {
    "objectID": "tabular.html#удаление-стоп-слов",
    "href": "tabular.html#удаление-стоп-слов",
    "title": "2  Табличные данные. Анализ датасета",
    "section": "2.6 Удаление стоп-слов",
    "text": "2.6 Удаление стоп-слов\nУдалим самые частотные слова. Для этого сначала сохраним их список. Подробнее см. здесь.\n\nlibrary(stopwords)\nsw &lt;- stopwords(\"ru\")\nsw\n\n  [1] \"и\"       \"в\"       \"во\"      \"не\"      \"что\"     \"он\"      \"на\"     \n  [8] \"я\"       \"с\"       \"со\"      \"как\"     \"а\"       \"то\"      \"все\"    \n [15] \"она\"     \"так\"     \"его\"     \"но\"      \"да\"      \"ты\"      \"к\"      \n [22] \"у\"       \"же\"      \"вы\"      \"за\"      \"бы\"      \"по\"      \"только\" \n [29] \"ее\"      \"мне\"     \"было\"    \"вот\"     \"от\"      \"меня\"    \"еще\"    \n [36] \"нет\"     \"о\"       \"из\"      \"ему\"     \"теперь\"  \"когда\"   \"даже\"   \n [43] \"ну\"      \"вдруг\"   \"ли\"      \"если\"    \"уже\"     \"или\"     \"ни\"     \n [50] \"быть\"    \"был\"     \"него\"    \"до\"      \"вас\"     \"нибудь\"  \"опять\"  \n [57] \"уж\"      \"вам\"     \"сказал\"  \"ведь\"    \"там\"     \"потом\"   \"себя\"   \n [64] \"ничего\"  \"ей\"      \"может\"   \"они\"     \"тут\"     \"где\"     \"есть\"   \n [71] \"надо\"    \"ней\"     \"для\"     \"мы\"      \"тебя\"    \"их\"      \"чем\"    \n [78] \"была\"    \"сам\"     \"чтоб\"    \"без\"     \"будто\"   \"человек\" \"чего\"   \n [85] \"раз\"     \"тоже\"    \"себе\"    \"под\"     \"жизнь\"   \"будет\"   \"ж\"      \n [92] \"тогда\"   \"кто\"     \"этот\"    \"говорил\" \"того\"    \"потому\"  \"этого\"  \n [99] \"какой\"   \"совсем\"  \"ним\"     \"здесь\"   \"этом\"    \"один\"    \"почти\"  \n[106] \"мой\"     \"тем\"     \"чтобы\"   \"нее\"     \"кажется\" \"сейчас\"  \"были\"   \n[113] \"куда\"    \"зачем\"   \"сказать\" \"всех\"    \"никогда\" \"сегодня\" \"можно\"  \n[120] \"при\"     \"наконец\" \"два\"     \"об\"      \"другой\"  \"хоть\"    \"после\"  \n[127] \"над\"     \"больше\"  \"тот\"     \"через\"   \"эти\"     \"нас\"     \"про\"    \n[134] \"всего\"   \"них\"     \"какая\"   \"много\"   \"разве\"   \"сказала\" \"три\"    \n[141] \"эту\"     \"моя\"     \"впрочем\" \"хорошо\"  \"свою\"    \"этой\"    \"перед\"  \n[148] \"иногда\"  \"лучше\"   \"чуть\"    \"том\"     \"нельзя\"  \"такой\"   \"им\"     \n[155] \"более\"   \"всегда\"  \"конечно\" \"всю\"     \"между\"  \n\n\n\nelegies_clean &lt;- elegies_tokens |&gt; \n  filter(!word %in% sw)\n\nelegies_clean |&gt; \n  print()\n\n# A tibble: 5,993 × 7\n      id Author           Year  Source_name   Title First_line             word \n   &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;                  &lt;chr&gt;\n 1    10 Баратынский Е.А. 1820  Соревнователь Весна Мечты волшебные, вы с… мечты\n 2    10 Баратынский Е.А. 1820  Соревнователь Весна Мечты волшебные, вы с… волш…\n 3    10 Баратынский Е.А. 1820  Соревнователь Весна Мечты волшебные, вы с… скры…\n 4    10 Баратынский Е.А. 1820  Соревнователь Весна Мечты волшебные, вы с… очей \n 5    10 Баратынский Е.А. 1820  Соревнователь Весна Мечты волшебные, вы с… сбыл…\n 6    10 Баратынский Е.А. 1820  Соревнователь Весна Мечты волшебные, вы с… врем…\n 7    10 Баратынский Е.А. 1820  Соревнователь Весна Мечты волшебные, вы с… угро…\n 8    10 Баратынский Е.А. 1820  Соревнователь Весна Мечты волшебные, вы с… хлад…\n 9    10 Баратынский Е.А. 1820  Соревнователь Весна Мечты волшебные, вы с… серд…\n10    10 Баратынский Е.А. 1820  Соревнователь Весна Мечты волшебные, вы с… юнос…\n# ℹ 5,983 more rows",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Табличные данные. Анализ датасета</span>"
    ]
  },
  {
    "objectID": "tabular.html#подсчет-частотностей",
    "href": "tabular.html#подсчет-частотностей",
    "title": "2  Табличные данные. Анализ датасета",
    "section": "2.7 Подсчет частотностей",
    "text": "2.7 Подсчет частотностей\nУзнаем, сколько всего слов приходится на каждого автора в корпусе.\n\nelegies_clean |&gt; \n  group_by(Author) |&gt; \n  summarise(n = n()) |&gt; \n  print()\n\n# A tibble: 3 × 2\n  Author               n\n  &lt;chr&gt;            &lt;int&gt;\n1 Баратынский Е.А   2066\n2 Баратынский Е.А.  1538\n3 Пушкин А.С.       2389\n\n\nУпс! У нас два Баратынских. Исправим:\n\nelegies_clean &lt;- elegies_clean |&gt; \n  mutate(Author = case_when(str_detect(Author, \"Баратынский\") ~ \"Баратынский Е.А.\",\n                   .default = Author))\n\nСнова проверим.\n\nelegies_clean |&gt; \n  group_by(Author) |&gt; \n  summarise(n = n()) |&gt; \n  print()\n\n# A tibble: 2 × 2\n  Author               n\n  &lt;chr&gt;            &lt;int&gt;\n1 Баратынский Е.А.  3604\n2 Пушкин А.С.       2389\n\n\nНайдем самые частотные слова у Пушкина и Баратынского. Обратите внимание, что результат вычислений не сохраняется.\n\nelegies_clean |&gt; \n  count(word, sort = TRUE) |&gt; \n  print()\n\n# A tibble: 3,620 × 2\n   word       n\n   &lt;chr&gt;  &lt;int&gt;\n 1 моей      46\n 2 любви     41\n 3 твой      32\n 4 ль        22\n 5 любовь    22\n 6 друг      21\n 7 мечты     21\n 8 мной      20\n 9 вновь     18\n10 душе      17\n# ℹ 3,610 more rows\n\n\nТак мы получили абсолютные значения. Чтобы посчитать долю, немного изменим код:\n\ntop_words &lt;- elegies_clean |&gt; \n  group_by(Author) |&gt; \n  count(word, sort = TRUE) |&gt; \n  mutate(perc = (n / sum(n)) * 100) |&gt; \n  arrange(-perc) |&gt; \n  slice_max(n = 10, order_by = perc)\n\ntop_words |&gt; \n  print()\n\n# A tibble: 21 × 4\n# Groups:   Author [2]\n   Author           word          n  perc\n   &lt;chr&gt;            &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt;\n 1 Баратынский Е.А. моей         31 0.860\n 2 Баратынский Е.А. любви        17 0.472\n 3 Баратынский Е.А. твой         17 0.472\n 4 Баратынский Е.А. душе         14 0.388\n 5 Баратынский Е.А. друг         13 0.361\n 6 Баратынский Е.А. дней         12 0.333\n 7 Баратынский Е.А. ль           12 0.333\n 8 Баратынский Е.А. душой        11 0.305\n 9 Баратынский Е.А. мечты        11 0.305\n10 Баратынский Е.А. последний    11 0.305\n# ℹ 11 more rows",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Табличные данные. Анализ датасета</span>"
    ]
  },
  {
    "objectID": "tabular.html#визуализации",
    "href": "tabular.html#визуализации",
    "title": "2  Табличные данные. Анализ датасета",
    "section": "2.8 Визуализации",
    "text": "2.8 Визуализации\nВ tidyverse входит пакет ggplot2 для визуализации данных. В его основе лежит идея “грамматики графических элементов” Лиланда Уилкинсона (Мастицкий 2017) (отсюда “gg” в названии).\nФункция ggplot() имеет два основных аргумента: data и mapping. Аргумент mapping задает эстетические атрибуты геометрических объектов. Обычно используется в виде mapping = aes(x, y), где aes() означает aesthetics.\nПод “эстетикой” подразумеваются графические атрибуты, такие как размер, форма или цвет. Вы не увидите их на графике, пока не добавите какие-нибудь “геомы” – геометрические объекты (точки, линии, столбики и т.п.). Эти объекты могут слоями накладываться друг на друга (Wickham и Grolemund 2016).\nМы построим столбиковую диаграмму.\n\ntop_words |&gt; \n  ggplot(aes(word, perc, fill = Author)) +\n  geom_col() +\n  facet_wrap(~Author, scales=\"free\") +\n  coord_flip() +\n  theme_bw()\n\n\n\n\n\n\n\n\nКаждый геометрический объект может иметь свои специфические параметры. Например, geom_point() может варьировать размер, цвет, форму и прозрачность точек, а geom_line() — тип, толщину и цвет линии. Эти параметры можно задавать как внутри aes() (когда они зависят от данных), так и вне её (когда задаются константы).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Табличные данные. Анализ датасета</span>"
    ]
  },
  {
    "objectID": "tabular.html#видео-к-этому-уроку",
    "href": "tabular.html#видео-к-этому-уроку",
    "title": "2  Табличные данные. Анализ датасета",
    "section": "2.9 Видео к этому уроку",
    "text": "2.9 Видео к этому уроку\n\nВидео 2025 г.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Табличные данные. Анализ датасета</span>"
    ]
  },
  {
    "objectID": "tabular.html#домашнее-задание",
    "href": "tabular.html#домашнее-задание",
    "title": "2  Табличные данные. Анализ датасета",
    "section": "2.10 Домашнее задание",
    "text": "2.10 Домашнее задание\n\nВ этом задании вы исследуете корпус русской песни. Источник.\nОценка 0-10. Выполнять все пункты задания не обязательно: на оценку 9-10 требования очень высокие (так и задумано).\nСам корпус и заготовку для кода вы найдете, приняв задание по ссылке: https://classroom.github.com/a/zlrC_zDL. Если вы не видите себя в списке студентов, напишите преподавателю.\nПосле этого GitHub создаст репозиторий для сдачи домашнего задания. Клонируйте его (т.е. создайте локальный проект под контролем версий, как мы делали в первом уроке).\nВнесите необходимые изменения в файл hw2.R, после чего закоммитьте изменения и сделайте push. Если не получится, используйте кнопку Upload files.\n\n\nКритерии оценивания:\n\nДля всех решений (импорт, статистика и др.) использована библиотека tidyverse. - 1 б.\nОформление кода: пайпы |&gt;, каждая функция с новой строки, есть отступы, осмысленные имена переменных. - 1 б.\nПосчитана статистика по годам публикации. - 1 б.\nВсе текстовые файлы прочитаны и записаны в единый тиббл. - 2 б.\nТиббл с текстами корректно (!) объединен с метаданными, в итоговом тиббле только нужные столбцы. - 2 б.\nТекст песен токенизирован - 1 б.\nУдалены стоп-слова - 1 б.\nДополнительные визуализации на усмотрение автора - 1 б.\n\n\n\nВесь код должен запускаться без ошибок (в противном случае – минус 4 балла).\nВ случае выявления плагиата всем соучастникам ставится оценка 0 без возможности пересдачи.\nПосле дедлайна (3 октября 21-00 мск) задание не принимается.\n\n\n\n\n\nWickham, Hadley, и Garrett Grolemund. 2016. R for Data Science. O’Reilly. https://r4ds.had.co.nz/index.html.\n\n\nМастицкий, Сергей. 2017. Визуализация данных с помощью ggplot2. ДМК.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Табличные данные. Анализ датасета</span>"
    ]
  },
  {
    "objectID": "ocr.html",
    "href": "ocr.html",
    "title": "3  Распознавание изображений",
    "section": "",
    "text": "3.1 Что такое OCR и tesseract\nВ этом уроке мы освоим основной инструмент для распознавания печатного текста в R – пакет tesseract, а также научимся дообучать модели под конкретные задачи и шрифты. Для работы нам понадобятся следующие библиотеки:\nOCR (Optical Character Recognition) — это технология автоматического распознавания печатного текста на изображениях и преобразования его в машинно-читаемый формат. Эта технология позволяет “извлекать” текст из сканированных документов, фотографий, PDF-файлов и других графических форматов.\nTesseract — это одна из самых популярных библиотек OCR с открытым исходным кодом, разработанная компанией Google. Tesseract поддерживает более 100 языков и может работать с различными типами изображений и форматами документов. Это совершенно бесплатно. Последние версии Tesseract используют обучение при помощи нейросетей (LSTM), и их можно дообучать под свои задачи, что очень удобно и не требует больших мощностей и продвинутых навыков программирования.\nПакет tesseract в R представляет собой обертку для библиотеки Tesseract, которая позволяет:\nВ отличие от онлайн-сервисов OCR, пакет tesseract работает локально, что обеспечивает:\nОднако качество распознавания сильно зависит от качества исходного изображения, типа шрифта, языка документа и правильности настройки параметров. Именно поэтому важно уметь не только использовать готовые модели, но и дообучать их под специфические задачи.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Распознавание изображений</span>"
    ]
  },
  {
    "objectID": "ocr.html#что-такое-ocr-и-tesseract",
    "href": "ocr.html#что-такое-ocr-и-tesseract",
    "title": "3  Распознавание изображений",
    "section": "",
    "text": "Распознавать текст с изображений различных форматов (PNG, JPEG, TIFF, PDF);\nРаботать с многостраничными документами;\nИспользовать предобученные модели для разных языков (список);\nНастраивать параметры распознавания под конкретные задачи;\nДообучать модели для улучшения качества распознавания специфических шрифтов или типов документов.\n\n\n\nКонфиденциальность — данные не передаются третьим лицам;\nСкорость — нет задержек на передачу данных по сети;\nНастраиваемость — возможность тонкой настройки под конкретные задачи;\nБесшовную интеграцию с экосистемой R для дальнейшего анализа данных.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Распознавание изображений</span>"
    ]
  },
  {
    "objectID": "ocr.html#данные",
    "href": "ocr.html#данные",
    "title": "3  Распознавание изображений",
    "section": "3.2 Данные",
    "text": "3.2 Данные\nВ качестве упражнения мы возьмем ч. 6 № 6 журнала “Невский зритель” за 1821 г. (источник). Чтобы не запутаться в выпусках, заберите нужный номер из репозитория курса и сохраните его на компьютер.\nЖурнал «Невский зритель» издавался в Петербурге ежемесячно с января 1820 г. по июнь 1821 г. Всего вышло 18 книжек журнала, составивших 6 частей. Все они доступны на сайте “Пушкинского дома”.\n\nОфициальным издателем журнала был выпускник Московского университета Иван Матвеевич Сниткин (род. ок. 1792 г.). С января по апрель 1820 г. соиздателем «Невского зрителя» был В. К. Кюхельбекер; намеревался войти в число издателей и К. Ф. Рылеев (1797-1826), активный сотрудник журнала с октября 1820-го по февраль 1821 г. В разное время в журнале печатались произведения Пушкина, Кюхельбекера, Жуковского, Баратынского, Дельвига, а также Рылеева, поместившего в октябрьской книжке 1820 г. острейшую сатиру на Аракчеева «К временщику». (Источник.)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Распознавание изображений</span>"
    ]
  },
  {
    "objectID": "ocr.html#выбор-страниц",
    "href": "ocr.html#выбор-страниц",
    "title": "3  Распознавание изображений",
    "section": "3.3 Выбор страниц",
    "text": "3.3 Выбор страниц\nДля начала вырежем несколько страниц из pdf. Таким образом вы легко можете делить любые издания на главы, разделы и т.д. Сначала сохраняем путь к файлу в виде строки (у меня он лежит в папке ocr, но у вас путь может быть иной).\n\nmy_files &lt;- list.files(\"../ocr\", pattern = \"pdf\", full.names = TRUE)\nmy_files[2] # нужный файл\n\n[1] \"../ocr/НЗ1821_6_6[50-51].pdf\"\n\n\nТеперь вырежем из журнала две страницы. В input отдаем путь к файлу (как он выглядит на вашем компьютере); в output – любой путь (или только имя и расширение) для нового файла (можете придумать свое); аргументу pages передайте номера страниц.\n\npdf_subset(input = my_files[2],\n           output = \"../ocr/НЗ1821_6_6[50-51].pdf\",\n           pages = 50:51)\n\nПосле этого у вас на компьютере должен появиться pdf вот такого элегического содержания.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nВопрос\n\n\n\nНайдите в метаданных к корпусу русских элегий предположительную фамилию автора.\n\n\nОтвет: .",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Распознавание изображений</span>"
    ]
  },
  {
    "objectID": "ocr.html#извлечение-текста-из-pdf",
    "href": "ocr.html#извлечение-текста-из-pdf",
    "title": "3  Распознавание изображений",
    "section": "3.4 Извлечение текста из pdf",
    "text": "3.4 Извлечение текста из pdf\nЕсли вам повезло, то pdf хранит уже распознанный текст. Такое бывает довольно часто (хотя иногда распознавание настолько плохое, что проще сделать вид, что его нет, и распознать заново). Проверим.\n\ntext1 &lt;- pdf_text(pdf = \"../ocr/НЗ1821_6_6[50-51].pdf\")\n# как print(), но больше подходит для вывода текста (можете сравнить)\ncat(text1)\n\nЭЭСЮЭЭЭЭЭСКЮЭЭЭЭЭСЮС»ЭЭЭ&lt;Э&lt;ЗС&gt;Э(ІЭ(99ЭС933 э о э з о з э з э\n\n                   РАЗЛУКА.\n                     ( Э л е г і я ,)\n\n\n\nРозалія, мой спутникъ неизмѣнный\n     На полѣ радостей земныхъ!\nРозалія, мой другъ, хранитель несравненный!\nКогда я отдохну въ объятіяхъ твоихъ? . •.\nСъ тобою горестей душа моя незнаетъ,\nИ сердцу скорбному не измѣнитъ покой!\nНадежда мрачный путь звѣздою озаряетъ,\n     И я мирюсь съ враждебною судьбой! . . •\nТеперь, за дальними, свирѣпыми морями\n  Твой сладкій гласъ не оживитъ меня!\nВзойдетъ заря надъ злачными холмами,\n  Появится въ лучахъ свѣтило дня —\n  Напрасно! все кругомъ покрыто мглою.\n  Неслышится мнѣ сладкій ігівой привѣтъ.\n  Всѣ радости, надежды всѣ съ тобою —\n     И опустѣлъ безъ милой свѣтъ!\nПодруга милая, скажи, что край прелестный,\n   Что мирныя, тѣнисты я поля,\nЧто своенравныя судьбы привѣтъ мнѣ лестный,\n     Когда съ тобой въ разлукѣ я.\n     Но другъ мои! горесть отл етаетъ\n                     243\n\n    На быстрыхъ времени крылахъ,\n    И радость сердце посѣщ аетъ. . . .\n    Моя надежда — въ небесахъ!. . .\n  Когдажъ опять смягченными судьбами\n  Я въ радости къ подругѣ понесусь,\nКоснусь волшебныхъ струнъ волшебными пер\n                                       стами\n  И, съ рѣзвою мечтою примирюсь.\n\n                             А, Б   —   фЪ.\n\n\nТекст распознан достаточно хорошо, есть мелкие ошибки, но их можно исправить (о чем речь пойдет в следующем уроке). Если необходимо сохранить извлеченный из pdf текст для дальнейшей работы, это делается так:\n\n# укажите свой путь или одно только имя\nwriteLines(text1, con = \"../ocr/rosalia_1.txt\")\n\nПрежде чем двигаться дальше, убедитесь, что тест сохранился.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Распознавание изображений</span>"
    ]
  },
  {
    "objectID": "ocr.html#распознавание",
    "href": "ocr.html#распознавание",
    "title": "3  Распознавание изображений",
    "section": "3.5 Распознавание",
    "text": "3.5 Распознавание\nЕсли текст не распознан (притворимся, что так и есть), то можно попробовать распознать при помощи tesseract. Однако есть нюанс: tesseract не знает дореформенного русского. Это значит, что все яти (ѣ), еры (ъ), фиты (Ѳ) и десятеричные и (і) превратятся во что-то странное. А еще трудности бывают с буквой “т”, т.к. в XVIII и XIX в. ее иногда печатали по-другому.\nЧтобы использовать предобученную модель, ее надо скачать при помощи функции tesseract_download(). Это делается один раз (поэтому у меня эта строчка закомментирована). Кстати, тессеракт способен “читать” тексты на нескольких языках, для этого передаем значение аргументу language так: \"rus+deu\". Важно правильно указать код; если не уверены, еще раз загляните в список моделей. После этого выведите список моделей.\n\n# tesseract_download(\"rus\")\ntesseract_info()$available\n\nМодель скачана, мы можем использовать ее для распознавания. Но на многое не рассчитываем, ведь это модель для современного русского, со старой орфографией она не знакома.\nФункция pdf_ocr_text() из пакета {pdftools} преобразует наш pdf в серию картинок и обращается к пакету {tesseract} для распознавания.\n\ntext2 &lt;- pdf_ocr_text(\"../ocr/НЗ1821_6_6[50-51].pdf\", \n                      language = \"rus\")\n\ncat(text2)\n\n# Converting page 1 to НЗ1821_6_6[50-51]_1.png... done!\n# Converting page 2 to НЗ1821_6_6[50-51]_2.png... done!\n\n# 999939993993999999339993399999939939 9039303939\n# РАЗЛУКА.\n# (Элегтя.)\n# ————-\n# Розамя, мой спушникъь неизмённый\n# На полЪ радосшей земныхь!\n# Розал!я, мой другь, хранишель несравненный!\n# Когда я ошдохну въ объяпияхь швоихъ?...\n# Съ шобою горестей душа моя незнаеть,\n# И сердцу скорбному не измЪнить покой!\n# Надежда мрачный пушь звЪздою озаряепть,\n# И я мирюсь съ враждебною судьбой!...\n# ’Геперь, за дальними, свиофпыми морями\n# Твой сладк!й гласъ не оживишьъ меня!\n# Взойдеть заря надъ злачными холмами,\n# Появишся въ лучахъ свЪшило дня —\n# Напрасно! все кругомъ покрыпю мглою.\n# Неслышишся мнЪ сладюй тивой привЪфить,\n# ВсЪ5 радосши, надежды всЪ съ шобою —\n# И опусш$ль безъ милой свЪзить’\n# Подруга милая, скажи, чшо край прелесшный,\n# Чпо мирвыя, тифвисптыя поля,\n# Чтпо своенравныя судьбы привЪтьъ мн лесшный,\n# Когда съ шобой въ разлук я.\n# Но другь мой! горесмь ошленаепть\n#  245\n# На бысшрыхь времени крылахь,\n# И радосшь сердце посфщаеть....\n# Моя надежда — въ небесахь!...\n# Когдажъ опяшь смягченными судьбами\n# Я въ радосши къ подругЪ понесусь,\n# Коснусь волшебныхь сшрунь волшебными пер-\n# сшами\n# И, сь рфзвою мечтшою примирюсь.\n# Я, Б — $5.\n\nСохраним text2 в отдельный файл для сравнения.\n\nwriteLines(text2, con = \"../ocr/rosalia_2.txt\")\n\nКак быть, если результат распознавания не устраивает?\n\nПервое: проверить, нет ли обученных моделей, которые справятся с вашей задачей. Можно поискать, например, модели на Hugging Face. Но результат может будет зависеть от того, на каких шрифтах учили модель.\nВторое: обученные модели можно также поискать в Транскрибусе (например, здесь и здесь). Но у Транскрибуса есть ряд ограничений: модели нельзя использовать локально, за расширенный функционал придется платить, и др. Бесплатно можно пользоваться готовыми приложениями.\nНаконец, можно дообучить уже существующую модель tesseract, как показано вот в этом примере. Этим мы сейчас и займемся.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Распознавание изображений</span>"
    ]
  },
  {
    "objectID": "ocr.html#конвертация-pdf",
    "href": "ocr.html#конвертация-pdf",
    "title": "3  Распознавание изображений",
    "section": "3.6 Конвертация pdf",
    "text": "3.6 Конвертация pdf\nФункция pdf_ocr_text() “подметет” за собой все картинки. Чтобы преобразовать pdf изображения и сохранить их на компьютере (например, для внешнего приложения по распознаванию текста или для создания обучающих данных), используем другую функцию.\n\npdf_convert(\"../ocr/НЗ1821_6_6[50-51].pdf\", \n            format = \"png\", \n            dpi = 300,\n            pages = NULL,  # все страницы, или c(1,3,5) для конкретных\n            filenames = NULL)\n\nЗапустите код и убедитесь, что в выбранной директории появились два файла с расширением .png. Они нам пригодятся чуть позже.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Распознавание изображений</span>"
    ]
  },
  {
    "objectID": "ocr.html#препроцессинг-изображений",
    "href": "ocr.html#препроцессинг-изображений",
    "title": "3  Распознавание изображений",
    "section": "3.7 Препроцессинг изображений",
    "text": "3.7 Препроцессинг изображений\nТочность OCR зависит от качества исходного изображения. Часто можно улучшить результат, правильно масштабируя изображение, удаляя шум и артефакты или обрезая область, где находится текст. Отличный пакет {magick} содержит множество полезных функций для улучшения качества изображения. Что можно попробовать:\n\nЕсли изображение наклонено, используйте image_deskew() и image_rotate(), чтобы выровнять текст по горизонтали.\nimage_trim() обрезает поля с пробельными областями.\nИспользуйте image_convert() для преобразования изображения в градации серого.\nДля изменения размера используйте image_resize().\nФункции image_modulate() или image_contrast() подходят для регулировки яркости/контраста.\nПопробуйте image_reducenoise() для автоматического удаления шума.\n\nВозьмем вот такое изображение и сравним результат распознавания до и после препроцессинга.\n\n\ninput &lt;- image_read(\"./images/IMG_5539.jpg\")\n\n\n# Обработка изображения\nprocessed &lt;- input |&gt;\n  image_deskew() |&gt; \n  image_resize(\"2000x\") |&gt;          \n  image_convert(colorspace = \"gray\") |&gt; \n  image_trim(fuzz = 40)  |&gt; \n  image_modulate(brightness = 120, saturation = 0)  |&gt;\n  image_contrast(sharpen = 1) |&gt;\n  image_normalize() |&gt;  \n  image_despeckle() \n\n\n# Сохранение на диск (посмотреть результат)\nimage_write(processed, path = \"./images/processed.png\", format = \"png\", density = \"300x300\")\n\n\n\n# OCR на обработанном изображении\ntesseract::ocr(processed, engine = \"rus\")\n\n[1] \"„Просимъ огласить слёдующий фактъ: БъЪжавшй въ 1\\n‘изъ Вятской губ. Бауманъ (Ветеринарный врачъ, служинц\\nСаратовскомъ земств въ 95-96 г.) удачно скрывшись от п\\nдовай шшоновъ, попалъ случайно въ совершенно негнану,\\nмЪстность, село ХлЪбное, Задонскаго у$Ззда, Воронежеко м\\nИзмученный голодомъ и продолжительной дорогой ПЪШкКом,\\nрфшилъ обратиться за содфйстнемъ къ самому интеллигент\\nпредставителю деревни, къ земскому врачу Валерану Веленн,\\n\"\n\n\nЕсли проблема в том, что строки имеют разный наклон (например, из-за деформации страницы), то может потребоваться нелинейное преобразование (например, коррекция искажения). Это сложнее, и в {magick} нет прямых функций для этого. Возможно, потребуется использование других инструментов, в том числе предобработка в специализированном ПО.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Распознавание изображений</span>"
    ]
  },
  {
    "objectID": "ocr.html#файн-тюнинг",
    "href": "ocr.html#файн-тюнинг",
    "title": "3  Распознавание изображений",
    "section": "3.8 Файн-тюнинг",
    "text": "3.8 Файн-тюнинг\nНачиная с версии 4, Tesseract использует нейронную сеть для распознавания текста, что позволяет дообучать модель для конкретных задач. Для дообучения необходимы эталонные данные — фрагменты изображений с соответствующим им текстом.\n\n3.8.1 Подготовка изображений\nСоздайте папку с именем {язык}-ground-truth/ (например, orus-ground-truth/) и поместите туда изображения текста. Названия файлов могут быть любыми.\n\ndir.create(\"orus-ground-truth\")\n\nСамый простой способ: сделать скриншоты вручную (чем больше, тем лучше). Вот пример:\n\nБолее продвинутый подход к нарезке изображений можно найти здесь (для Python). Мы нарежем изображение на отдельные слова в R. Для этого скачайте следующий скрипт и запустите его:\n\nsource(\"../helper_scripts/crop_words.R\")\n\nВ глобальном окружении появится функция crop_words(). Если хотите заглянуть внутрь, просто наберите View(crop_words). Но разбираться в начинке необязательно. Вы же не всегда интересуетесь, что там под капотом других функций? Просто эту вы взяли не из пакета, а из GitHub’а. А можете сами написать, сохранить себе, и так же использовать внутри других скриптов.\nФункция crop_words() принимает на входе путь до изображения (обязательный аргумент), название директории, куда будут сохранены слова (по умолчанию words), язык базовой модели (код tesseract, по умолчанию rus) и отступ вокруг слова при обрезке (в пикселях). Аргумент overwrite управляет тем, очищать ли существующие файлы word_*.png в out_dir перед сохранением (по умолчанию FALSE).\nТакже функция проверяет наличие пакетов magick, tesseract, tidyverse; при отсутствии пытается установить их вместе с зависимостями и затем подключает. Для корректной работы OCR с выбранным языком в системе должны быть установлены языковые данные Tesseract. Функция сохранит в папку изображения, а также вернет таблицу с метаданными.\n\ncrop_words(image_path = \"../ocr/НЗ1821_6_6[50-51]_1.png\",\n           out_dir = \"../ocr/orus-ground-truth\",\n           lang = \"rus\",\n           pad = 0,\n           overwrite = TRUE)\n\nПосле этого в папке должно появиться нечто похожее:\n Чтобы “разрезать” на слова несколько изображений, используем функции для итераций из пакета purrr (мы встречались с ними, когда читали сразу несколько текстовых файлов в окружение).\nСначала собираем все пути до файлов в символьный вектор.\n\nimg_paths &lt;- list.files(\"../ocr\", pattern = \"png\", full.names = TRUE)\nimg_paths\n\n[1] \"../ocr/НЗ1821_6_6[50-51]_1.png\" \"../ocr/НЗ1821_6_6[50-51]_2.png\"\n\n\nИ запускаем итерации!\n\nwalk(img_paths, crop_words, \n     out_dir = \"../ocr/orus-ground-truth\",\n     overwrite = FALSE)\n\nПосле запуска кода в папке должно появиться 157 файлов png.\n\nlist.files(\"../ocr/orus-ground-truth\") |&gt; \n  length()\n\nОбратите внимание на то, что функция walk(), в отличие от map_chr() из того же пакета {purrr}, ничего не сохраняет в окружение. Мы используем ее для повторного запуска crop_words(), которая последовательно нарезает страницы на слова и “сбрасывает” изображения слов в указанную директорию. То же самое можно было бы сделать так:\n\ncrop_words(image_paths[1])\ncrop_words(image_paths[2])\n\n# ...и так далее!\n\nНо, согласитесь, повторять это действие больше двух раз достаточно утомительно. Кроме того, у программистов считается плохим тоном “копипастить” один кусок кода более двух раз. Поэтому мы использовали функцию-итератор. Вжух.\n\n\n3.8.2 Текстовые файлы\nТеперь для каждого изображения добавим текст (файлы в формате .gt.txt). Для ускорения процесса создания эталонных файлов можно использовать пакет tesseractgt. Для создания таких файлов используем базовую модель.\n\ncreate_gt_txt(\n  folder = \"../ocr/orus-ground-truth\",\n  extension = \"png\", \n  engine = tesseract::tesseract(language = \"rus\")\n)\n\nУбедитесь, что файлы появились в директории. Это должно выглядеть примерно так:\n\nТеперь самый важный этап: корректировка текстовых файлов. Отредактируйте несколько файлов (чем больше, тем лучше). Исправить автоматически созданные файлы .gt.txt поможет специальная функция:\n\ncorrect_gt_txt() \n\n\n\n\nИсточник\n\n\nЕсли не видно папки с изображениями, смените рабочую директорию. Вот несколько полезных символов:\n\n\n\n\n\n\nНа заметку\n\n\n\nЧаще всего используемые в дореформенной русской орфографии:\n\nЯть: Ѣ (U+0462), ѣ (U+0463)\nИ десятеричное: І (U+0406), і (U+0456)\nФита: Ѳ (U+0472), ѳ (U+0473)\nИжица: Ѵ (U+0474), ѵ (U+0475)\nТвёрдый знак, еръ: Ъ (U+042A), ъ (U+044A)\n\n\n\n🛠️ Если видите ошибку Warning: Error in writeImpl: Text to be written must be a length-one character vector, сделайте следующее:\n\nfix_gt_txt &lt;- function(folder) {\n  txts &lt;- list.files(folder, pattern = \"\\\\.txt$\", full.names = TRUE)\n  for (f in txts) {\n    # читаем файл\n    x &lt;- readLines(f, warn = FALSE, encoding = \"UTF-8\")\n    \n    # если пусто → оставляем пустую строку\n    if (length(x) == 0) {\n      one_line &lt;- \"\"\n    } else {\n      # склеиваем все строки через пробел\n      one_line &lt;- paste(x, collapse = \" \")\n      # убираем лишние пробелы\n      one_line &lt;- trimws(one_line)\n    }\n    \n    # записываем обратно в файл\n    writeLines(enc2utf8(one_line), f, useBytes = TRUE)\n  }\n  message(\"Готово: все txt-файлы приведены к одной строке\")\n}\n\n# запускаем\nfix_gt_txt(\"../ocr/orus-ground-truth\") # ваш путь к файлу\n\n\n\n3.8.3 Проверка версий\nВ терминале Linux / MacOS проверьте версию make. Чтобы провести дообучение на Windows, используйте WSL. Это полноценный Linux внутри Windows. (Если это пока сложно, пока пропустите этот шаг).\n\nmake --version # для Linux\n\nНа MacOS системный make — BSD и ведёт себя иначе, чем GNU Make, который обычно ожидают учебники и инструкции по сборке/обучению. Установить новую GNU Make можно через Homebrew (это менеджер пакетов, его надо отдельно поставить: https://brew.sh/). Homebrew ставит GNU Make под именем gmake, чтобы не конфликтовать с системным make. Команды ниже нужно выполнить в терминале после установки Homebrew.\n\nbrew install make\n\n\ngmake --version # для MacOS\n\n\n\n3.8.4 Дообучение\nЗадача этого шага — подготовить материалы, нужные для обучения Tesseract. Сначала скачиваем служебный проект tesstrain, потом — языковые данные.\n\nОткройте терминал и скачайте проект tesstrain с GitHub.\n\n\ngit clone https://github.com/tesseract-ocr/tesstrain.git\n\nПосле этого у вас появится папка tesstrain. В ней лежат скрипты и файл Makefile.\n\nПерейдите в папку tesstrain. Команда cd означает смену каталога.\n\n\ncd tesstrain\n\n\nСкачайте языковые данные для обучения\n\n\nmake tesseract-langdata\n# ИЛИ на MacOS\ngmake tesseract-langdata\n\nКоманда gmake tesseract-langdata (или make tesseract-langdata) запускает утилиту (небольшую программу) make и выполняет задачу tesseract-langdata, описанную в Makefile проекта. В результате автоматически скачиваются официальные языковые данные Tesseract, необходимые для обучения, а именно langdata и/или langdata_lstm — наборы текстов, списки слов, правила пунктуации/нормализации и прочие файлы, которые используются при подготовке и обучении модели. Одним словом, данные готовятся для обучения.\nЕсли все хорошо, на экране забегают какие-то цифирки. Все нормально, подождите.\n\n# Connecting to raw.githubusercontent.com... connected. HTTP request sent, awaiting response... OK... Saving to...\n\n\n\n3.8.5 Структура каталога\nИтог: после этих мучений команд у вас есть локальная копия tesstrain, вы находитесь в её каталоге, и в него загружены исходные языковые данные (data), без которых обучение своей модели Tesseract не запустится.\nНа этом этапе структура каталога выглядит так:\n\n# ../tesstrain\n# ├── LICENSE\n# ├── Makefile\n# ├── README.md\n# ├── count_chars.py\n# ├── data\n# │   └── langdata\n# │       ├── Arabic.unicharset\n# │       ├── Armenian.unicharset\n# │       ├── Bengali.unicharset\n# │       ├── ...\n# │       └── radical-stroke.txt\n# ├── generate_eval_train.py\n# ├── generate_gt_from_box.py\n# ├── generate_line_box.py\n# ├── generate_line_syllable_box.py\n# ├── generate_wordstr_box.py\n# ├── normalize.py\n# ├── ocrd-testset.zip\n# ├── ocrd.plot_cer.png\n# ├── plot_cer.py\n# ├── plot_log.py\n# ├── requirements.txt\n# ├── shuffle.py\n# └── src\n#     ├── README.md\n#     ├── setup.cfg\n#     ├── setup.py\n#     └── tesstrain\n#         ├── __init__.py\n#         ├── __main__.py\n#         ├── arguments.py\n#         ├── generate.py\n#         ├── language_specific.py\n#         └── wrapper.py\n\nТеперь нам надо переместить обучающие данные – в нашем случае это orus-ground-truth в папку data. Можете просто скопировать вручную.\nТакже создайте еще одну папку внутри tesstrain и загрузите туда необходимые языковые данные.\n\nmkdir -p usr/share/tessdata\nwget -P usr/share/tessdata https://github.com/tesseract-ocr/tessdata_best/raw/main/rus.traineddata\n\nПосле этого можно запускать дообучение.\n\n# в терминале! или make на Linux\ngmake training MODEL_NAME=orus START_MODEL=rus FINETUNE_TYPE=Impact LANG_TYPE=Both\n\nКоманда выше запускает “рецепт” обучения нейросети Tesseract. Этот рецепт под названием training автоматически готовит данные и запускает процесс дообучения модели распознавания текста.\nЧто означает каждая часть команды:\n\ngmake training — запустить задание training из файла правил (Makefile). Оно скачает/подготовит данные, запустит обучение и положит результат в папку с моделями.\nMODEL_NAME=orus — имя новой модели, которую вы хотите получить. В конце появится файл вроде orus.traineddata.\nSTART_MODEL=rus — не учить с нуля, а взять за основу существующую русскую модель rus и “докрутить” ее под новые данные. Это быстрее и надежнее.\nFINETUNE_TYPE=Impact — “бережное” дообучение: меняются только части сети, чтобы сохранить сильные стороны базовой модели и адаптировать её под ваши тексты.\nLANG_TYPE=Both — использовать оба набора языковых данных Tesseract (классический и LSTM), чтобы шире покрыть правила, словари и примеры.\n\nДообучение занимает несколько минут. Воспользуйтесь перерывом, чтобы похвалить себя за выполнение сложнейшей задачи. Вы инициировали дообучение нейросети вообще-то 🆒 🆒 🆒\n\n\n3.8.6 Установка модели\nНайдите системную папку Tesseract:\n\ntesseract::tesseract_info()$datapath\n\n[1] \"/Users/olga/Library/Application Support/tesseract5/tessdata/\"\n\n\nСкопируйте сюда новую модель orus.trainedata, которая должна появиться в папке data после обучения.\nПроверьте доступные модели:\n\ntesseract::tesseract_info()$available\n\n[1] \"deu\"  \"eng\"  \"grc\"  \"lat\"  \"orus\" \"osd\"  \"rus\" \n\n\nТеперь можем использовать новую модель:\n\ntext3 &lt;- pdf_ocr_text(\"../ocr/НЗ1821_6_6[50-51].pdf\", language = \"orus\")\n\nConverting page 1 to НЗ1821_6_6[50-51]_1.png... done!\nConverting page 2 to НЗ1821_6_6[50-51]_2.png... done!\n\n\nСнова запишем.\n\n# укажите свой путь или одно только имя\nwriteLines(text3, con = \"../ocr/rosalia_3.txt\")\n\nЭти тексты можно будет использовать для сравнения моделей. Для лучшего результата используйте больше обучающих данных.\nТаким образом, дообучение Tesseract позволяет улучшить качество распознавания специализированных текстов; Пакет tesseractgt существенно упрощает процесс подготовки обучающих данных.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Распознавание изображений</span>"
    ]
  },
  {
    "objectID": "ocr.html#видео-к-этому-уроку",
    "href": "ocr.html#видео-к-этому-уроку",
    "title": "3  Распознавание изображений",
    "section": "3.9 Видео к этому уроку",
    "text": "3.9 Видео к этому уроку\n\nВидео 2025 г.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Распознавание изображений</span>"
    ]
  },
  {
    "objectID": "ocr.html#домашнее-задание",
    "href": "ocr.html#домашнее-задание",
    "title": "3  Распознавание изображений",
    "section": "3.10 Домашнее задание",
    "text": "3.10 Домашнее задание\n\n\n\n _______________________ \n&lt;Будет добавлено позже&gt;\n ----------------------- \n    \\\n     \\\n\n       /\\___/\\\n       {o}{o}|\n       \\ v  /|\n       |    \\ \\\n        \\___/_/       [ab]\n          | |",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Распознавание изображений</span>"
    ]
  },
  {
    "objectID": "regex.html",
    "href": "regex.html",
    "title": "4  Нормализация и оценка",
    "section": "",
    "text": "4.1 Регулярные выражения\nЕсть старая шутка, ее приписывают программисту Джейми Завински: если у вас есть проблема, и вы собираетесь ее решать при помощи регулярных выражений, то у вас две проблемы. Регулярные выражения – это формальный язык, который используется для того, чтобы находить, извлекать и заменять части текста. Мы воспользуемся регулярными выражениями для того, чтобы привести в порядок распознанный текст.\nДля работы нам понадобится пакет stringr из библиотеки tidyverse.\nlibrary(tidyverse)\nЗагрузим распознанный текст элегии.\ntext &lt;- readLines(con = \"../ocr/rosalia_1.txt\")\ntext\n\n [1] \"ЭЭСЮЭЭЭЭЭСКЮЭЭЭЭЭСЮС»ЭЭЭ&lt;Э&lt;ЗС&gt;Э(ІЭ(99ЭС933 э о э з о з э з э\"\n [2] \"\"                                                            \n [3] \"\"                                                            \n [4] \"\"                                                            \n [5] \"\"                                                            \n [6] \"                   РАЗЛУКА.\"                                 \n [7] \"                     ( Э л е г і я ,)\"                       \n [8] \"\"                                                            \n [9] \"\"                                                            \n[10] \"\"                                                            \n[11] \"Розалія, мой спутникъ неизмѣнный\"                            \n[12] \"     На полѣ радостей земныхъ!\"                              \n[13] \"Розалія, мой другъ, хранитель несравненный!\"                 \n[14] \"Когда я отдохну въ объятіяхъ твоихъ? . •.\"                   \n[15] \"Съ тобою горестей душа моя незнаетъ,\"                        \n[16] \"И сердцу скорбному не измѣнитъ покой!\"                       \n[17] \"Надежда мрачный путь звѣздою озаряетъ,\"                      \n[18] \"     И я мирюсь съ враждебною судьбой! . . •\"                \n[19] \"Теперь, за дальними, свирѣпыми морями\"                       \n[20] \"  Твой сладкій гласъ не оживитъ меня!\"                       \n[21] \"Взойдетъ заря надъ злачными холмами,\"                        \n[22] \"  Появится въ лучахъ свѣтило дня —\"                          \n[23] \"  Напрасно! все кругомъ покрыто мглою.\"                      \n[24] \"  Неслышится мнѣ сладкій ігівой привѣтъ.\"                    \n[25] \"  Всѣ радости, надежды всѣ съ тобою —\"                       \n[26] \"     И опустѣлъ безъ милой свѣтъ!\"                           \n[27] \"Подруга милая, скажи, что край прелестный,\"                  \n[28] \"   Что мирныя, тѣнисты я поля,\"                              \n[29] \"Что своенравныя судьбы привѣтъ мнѣ лестный,\"                 \n[30] \"     Когда съ тобой въ разлукѣ я.\"                           \n[31] \"     Но другъ мои! горесть отл етаетъ\"                       \n[32] \"\"                                                            \n[33] \"                    243\"                                     \n[34] \"\"                                                            \n[35] \"\"                                                            \n[36] \"    На быстрыхъ времени крылахъ,\"                            \n[37] \"    И радость сердце посѣщ аетъ. . . .\"                      \n[38] \"    Моя надежда — въ небесахъ!. . .\"                         \n[39] \"  Когдажъ опять смягченными судьбами\"                        \n[40] \"  Я въ радости къ подругѣ понесусь,\"                         \n[41] \"Коснусь волшебныхъ струнъ волшебными пер\"                    \n[42] \"                                       стами\"                \n[43] \"  И, съ рѣзвою мечтою примирюсь.\"                            \n[44] \"\"                                                            \n[45] \"                             А, Б   —   фЪ.\"                 \n[46] \"\"",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Нормализация и оценка</span>"
    ]
  },
  {
    "objectID": "regex.html#регулярные-выражения",
    "href": "regex.html#регулярные-выражения",
    "title": "4  Нормализация и оценка",
    "section": "",
    "text": "На заметку\n\n\n\nЧаще всего используемые в дореформенной русской орфографии:\n\nЯть: Ѣ (U+0462), ѣ (U+0463)\nИ десятеричное: І (U+0406), і (U+0456)\nФита: Ѳ (U+0472), ѳ (U+0473)\nИжица: Ѵ (U+0474), ѵ (U+0475)\nТвёрдый знак, еръ: Ъ (U+042A), ъ (U+044A)\n\n\n\n\n4.1.1 Литералы и классы\nРегулярные выражения (regex, regexp) объединяют буквальные символы (литералы) и метасимволы (символы-джокеры, англ. wildcard characters).\nДля поиска используется строка-образец (англ. pattern, по-русски её часто называют “шаблоном”, “маской”), которая задает правило поиска. Строка замены также может содержать в себе специальные символы.\n\n\n\n\n\n\nНа заметку\n\n\n\nОтличный путеводитель по миру регулярных выражений в R можно найти здесь.\n\n\nБуквальные символы – это то, что вы ожидаете увидеть (или не увидеть – для управляющих и пробельных символов); можно сказать, что это символы, которые ничего не “имеют в виду”. Их можно объединять в классы при помощи квадратных скобок.\nДля поиска совпадений используются три функции: str_detect(), str_which() и str_subset(). Первая возвращает логический вектор (то есть вектор значений TRUE / FALSE); вторая – индексы элементов, а третья – сами эти элементы. Сравним.\n\n# возвращает логический вектор\nstr_detect(text, \"[ѣъ]\")\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE\n[13]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE\n[25]  TRUE  TRUE FALSE  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE  TRUE\n[37]  TRUE  TRUE  TRUE  TRUE  TRUE FALSE  TRUE FALSE FALSE FALSE\n\n\nТак мы нашли все строки, где есть еры или яти. Можно сохранить логический вектор и использовать его для индексации. Функция head() позволяет ограничить вывод первыми элементами вектора.\n\n# создаем индекс\nidx &lt;- str_detect(text, \"[ѣъ]\")\n\n# используем его для отбора строк\ntext[idx] \n\nТеперь узнаем, в каких строках находятся рядом буквы ія. Мы не объединяем их в класс при помощи квадратных скобок, поэтому фукнция ищет не что-то одно, а именно сочетание.\n\nstr_which(text, \"ія\")\n\n[1] 11 13 14\n\n\nЭту функцию тоже можно использовать для индексации. На этот раз не сохраняем переменную idx.\n\ntext[str_which(text, \"ія\")]\n\n[1] \"Розалія, мой спутникъ неизмѣнный\"           \n[2] \"Розалія, мой другъ, хранитель несравненный!\"\n[3] \"Когда я отдохну въ объятіяхъ твоихъ? . •.\"  \n\n\nНаконец, str_subset() сама индексирует вектор. Попробуем.\n\nstr_subset(text, \"i\")\n\ncharacter(0)\n\n\nУпс. Что произошло, куда делись все i? Дело в том, что я набрала i в латинской клавиатуры, а это другой знак в Юникоде. Проверим (первую i копирую из текста выше):\n\n\"і\" == \"i\"\n\n[1] FALSE\n\n\nИсправляем.\n\nstr_subset(text, \"і\")\n\n[1] \"                     ( Э л е г і я ,)\"      \n[2] \"Розалія, мой спутникъ неизмѣнный\"           \n[3] \"Розалія, мой другъ, хранитель несравненный!\"\n[4] \"Когда я отдохну въ объятіяхъ твоихъ? . •.\"  \n[5] \"  Твой сладкій гласъ не оживитъ меня!\"      \n[6] \"  Неслышится мнѣ сладкій ігівой привѣтъ.\"   \n\n\nВ некоторых случаях удобнее использовать непосредственно код буквы.\n\nstr_subset(text, \"[\\u0406\\u0456]\")\n\n[1] \"ЭЭСЮЭЭЭЭЭСКЮЭЭЭЭЭСЮС»ЭЭЭ&lt;Э&lt;ЗС&gt;Э(ІЭ(99ЭС933 э о э з о з э з э\"\n[2] \"                     ( Э л е г і я ,)\"                       \n[3] \"Розалія, мой спутникъ неизмѣнный\"                            \n[4] \"Розалія, мой другъ, хранитель несравненный!\"                 \n[5] \"Когда я отдохну въ объятіяхъ твоихъ? . •.\"                   \n[6] \"  Твой сладкій гласъ не оживитъ меня!\"                       \n[7] \"  Неслышится мнѣ сладкій ігівой привѣтъ.\"                    \n\n\nОбратите внимание, что у прописных и строчных букв свои коды, и в предыдущем случае мы упустили строку с буквой І.\nДля некоторых классов есть специальные обозначения.\n\n\n\n\n\n\n\n\nКласс\nЭквивалент\nЗначение\n\n\n\n\n[:upper:]\n[A-Z]\nСимволы верхнего регистра\n\n\n[:lower:]\n[a-z]\nСимволы нижнего регистра\n\n\n[:alpha:]\n[[:upper:][:lower:]]\nБуквы\n\n\n[:digit:]\n[0-9], т. е. \\d\nЦифры\n\n\n[:alnum:]\n[[:alpha:][:digit:]]\nБуквы и цифры\n\n\n[:word:]\n[[:alnum:]], т. е. \\w\nСимволы, образующие «слово»\n\n\n[:punct:]\n[-!“#$%&’()*+,./:;&lt;=&gt;?@[\\]_`{|}~]\nЗнаки пунктуации\n\n\n[:blank:]\n[\\s\\t]\nПробел и табуляция\n\n\n[:space:]\n[[:blank:]\\v\\r\\n\\f], т. е. \\s\nПробельные символы\n\n\n[:cntrl:]\n\nУправляющие символы (перевод строки, табуляция и т.п.)\n\n\n[:graph:]\n\nПечатные символы\n\n\n[:print:]\n\nПечатные символы с пробелом\n\n\n\nЭти классы тоже можно задавать в качестве паттерна. Знак \\\\b означает любую границу слова (начало строки, конец строки, пробел, пунктуация).\n\nstr_subset(text, \"[[:digit:]]\")\n\n[1] \"ЭЭСЮЭЭЭЭЭСКЮЭЭЭЭЭСЮС»ЭЭЭ&lt;Э&lt;ЗС&gt;Э(ІЭ(99ЭС933 э о э з о з э з э\"\n[2] \"                    243\"                                     \n\n\nРаботы с регулярными выражениями требует навыка; поначалу, прежде чем преобразовывать строки, удобно просто посмотреть, что попало в ваш невод.\nstr_view(text[1:8], \"[[:punct:]]\", html = TRUE)\n\n\nВнутри квадратных скобор знак ^ означает отрицание. Сравните:\n\n# удаляем всю пунктуацию\nstr_remove_all(text[1:8], \"[[:punct:]]\") \n\n[1] \"ЭЭСЮЭЭЭЭЭСКЮЭЭЭЭЭСЮСЭЭЭ&lt;Э&lt;ЗС&gt;ЭІЭ99ЭС933 э о э з о з э з э\"\n[2] \"\"                                                         \n[3] \"\"                                                         \n[4] \"\"                                                         \n[5] \"\"                                                         \n[6] \"                   РАЗЛУКА\"                               \n[7] \"                      Э л е г і я \"                       \n[8] \"\"                                                         \n\n\n\n# удаляем все, кроме пунктуации\nstr_remove_all(text[1:8], \"[^[:punct:]]\") \n\n[1] \"»((\" \"\"    \"\"    \"\"    \"\"    \".\"   \"(,)\" \"\"   \n\n\nВ качестве классов можно рассматривать и следующие обозначения:\n\n\n\n\n\n\n\n\nПредставление\nЭквивалент\nЗначение\n\n\n\n\n\\d\n[0-9]\nЦифра\n\n\n\\D\n[^\\\\d]\nЛюбой символ, кроме цифры\n\n\n\\w\n[A-Za-zА-Яа-я0-9_]\nСимволы, образующие «слово» (буквы, цифры и символ подчёркивания)\n\n\n\\W\n[^\\\\w]\nСимволы, не образующие «слово»\n\n\n\\s\n[ \\t\\v\\r\\n\\f]\nПробельный символ\n\n\n\\S\n[^\\\\s]\nНепробельный символ\n\n\n\nНайдем все строки с числами и удалим их (в нашем случае либо номера страниц, либо ошибки распознавания). Также удалим все пустые строки.\n\n# вторая косая черта \"экранирует\" первую\ntext2 &lt;- text[!str_detect(text, \"\\\\d\") & nchar(text) != 0]\ntext2\n\n [1] \"                   РАЗЛУКА.\"                 \n [2] \"                     ( Э л е г і я ,)\"       \n [3] \"Розалія, мой спутникъ неизмѣнный\"            \n [4] \"     На полѣ радостей земныхъ!\"              \n [5] \"Розалія, мой другъ, хранитель несравненный!\" \n [6] \"Когда я отдохну въ объятіяхъ твоихъ? . •.\"   \n [7] \"Съ тобою горестей душа моя незнаетъ,\"        \n [8] \"И сердцу скорбному не измѣнитъ покой!\"       \n [9] \"Надежда мрачный путь звѣздою озаряетъ,\"      \n[10] \"     И я мирюсь съ враждебною судьбой! . . •\"\n[11] \"Теперь, за дальними, свирѣпыми морями\"       \n[12] \"  Твой сладкій гласъ не оживитъ меня!\"       \n[13] \"Взойдетъ заря надъ злачными холмами,\"        \n[14] \"  Появится въ лучахъ свѣтило дня —\"          \n[15] \"  Напрасно! все кругомъ покрыто мглою.\"      \n[16] \"  Неслышится мнѣ сладкій ігівой привѣтъ.\"    \n[17] \"  Всѣ радости, надежды всѣ съ тобою —\"       \n[18] \"     И опустѣлъ безъ милой свѣтъ!\"           \n[19] \"Подруга милая, скажи, что край прелестный,\"  \n[20] \"   Что мирныя, тѣнисты я поля,\"              \n[21] \"Что своенравныя судьбы привѣтъ мнѣ лестный,\" \n[22] \"     Когда съ тобой въ разлукѣ я.\"           \n[23] \"     Но другъ мои! горесть отл етаетъ\"       \n[24] \"    На быстрыхъ времени крылахъ,\"            \n[25] \"    И радость сердце посѣщ аетъ. . . .\"      \n[26] \"    Моя надежда — въ небесахъ!. . .\"         \n[27] \"  Когдажъ опять смягченными судьбами\"        \n[28] \"  Я въ радости къ подругѣ понесусь,\"         \n[29] \"Коснусь волшебныхъ струнъ волшебными пер\"    \n[30] \"                                       стами\"\n[31] \"  И, съ рѣзвою мечтою примирюсь.\"            \n[32] \"                             А, Б   —   фЪ.\" \n\n\nТеперь удалим лишние пробелы и заменим яти на е. Функция str_replace() заменяет только первое вхождение в каждом элементе вектора, поэтому в строке 16 осталось “привѣтъ” (ср. 17, 18 и 21).\n\ntext2 |&gt; \n  str_squish() |&gt; \n  str_replace(\"ѣ\", \"е\")\n\n [1] \"РАЗЛУКА.\"                                   \n [2] \"( Э л е г і я ,)\"                           \n [3] \"Розалія, мой спутникъ неизменный\"           \n [4] \"На поле радостей земныхъ!\"                  \n [5] \"Розалія, мой другъ, хранитель несравненный!\"\n [6] \"Когда я отдохну въ объятіяхъ твоихъ? . •.\"  \n [7] \"Съ тобою горестей душа моя незнаетъ,\"       \n [8] \"И сердцу скорбному не изменитъ покой!\"      \n [9] \"Надежда мрачный путь звездою озаряетъ,\"     \n[10] \"И я мирюсь съ враждебною судьбой! . . •\"    \n[11] \"Теперь, за дальними, свирепыми морями\"      \n[12] \"Твой сладкій гласъ не оживитъ меня!\"        \n[13] \"Взойдетъ заря надъ злачными холмами,\"       \n[14] \"Появится въ лучахъ светило дня —\"           \n[15] \"Напрасно! все кругомъ покрыто мглою.\"       \n[16] \"Неслышится мне сладкій ігівой привѣтъ.\"     \n[17] \"Все радости, надежды всѣ съ тобою —\"        \n[18] \"И опустелъ безъ милой свѣтъ!\"               \n[19] \"Подруга милая, скажи, что край прелестный,\" \n[20] \"Что мирныя, тенисты я поля,\"                \n[21] \"Что своенравныя судьбы приветъ мнѣ лестный,\"\n[22] \"Когда съ тобой въ разлуке я.\"               \n[23] \"Но другъ мои! горесть отл етаетъ\"           \n[24] \"На быстрыхъ времени крылахъ,\"               \n[25] \"И радость сердце посещ аетъ. . . .\"         \n[26] \"Моя надежда — въ небесахъ!. . .\"            \n[27] \"Когдажъ опять смягченными судьбами\"         \n[28] \"Я въ радости къ подруге понесусь,\"          \n[29] \"Коснусь волшебныхъ струнъ волшебными пер\"   \n[30] \"стами\"                                      \n[31] \"И, съ резвою мечтою примирюсь.\"             \n[32] \"А, Б — фЪ.\"                                 \n\n\nЧтобы заменить все вхождения, используем str_replace_all(). Можно произвести сразу несколько замен, задав вектор соответствий:\n\ntext3 &lt;- text2 |&gt; \n  str_squish() |&gt; \n  str_replace_all(c(\"і\" = \"и\", \"ѣ\" = \"е\"))\n\n\n\n\n\n\n\nЗадание\n\n\n\nВ пакете stringr есть небольшой датасет words. Найдите все слова с последовательностью символов wh. Сколько слов содержат два гласных после w? Найдите все слова в words, в которых за w следует согласный. Замените всю пунктуацию в строке “tomorrow?and-tomorrow_and!tomorrow” на пробелы.\n\n\n\n\n4.1.2 Якоря и квантификация\nЯкоря позволяют искать последовательности символов в начале или в конце строки. Знак ^ (вне квадратных скобок!) означает начало строки, а знак $ – конец. Мнемоническое правило: First you get the power (^) and then you get the money ($).\n\nstr_subset(text3, \",$\")\n\n[1] \"Съ тобою горестей душа моя незнаетъ,\"       \n[2] \"Надежда мрачный путь звездою озаряетъ,\"     \n[3] \"Взойдетъ заря надъ злачными холмами,\"       \n[4] \"Подруга милая, скажи, что край прелестный,\" \n[5] \"Что мирныя, тенисты я поля,\"                \n[6] \"Что своенравныя судьбы приветъ мне лестный,\"\n[7] \"На быстрыхъ времени крылахъ,\"               \n[8] \"Я въ радости къ подруге понесусь,\"          \n\n\n\nstr_subset(text3, \"^Ч\")\n\n[1] \"Что мирныя, тенисты я поля,\"                \n[2] \"Что своенравныя судьбы приветъ мне лестный,\"\n\n\nНайдем строки, которые начинаются со строчной:\n\nstr_subset(text3, \"^[а-я]\")\n\n[1] \"стами\"\n\n\nТеперь найдем все строки, в которых больше одного знака пунктуации или пробела в конце. Для этого нам нужны не только якоря, но и квантификаторы. Квантификатор после символа, символьного класса или группы определяет, сколько раз предшествующее выражение может встречаться.\n\n\n\nПредставление\nЧисло повторений\nЭквивалент\n\n\n\n\n?\nНоль или одно\n{0,1}\n\n\n*\nНоль или более\n{0,}\n\n\n+\nОдно или более\n{1,}\n\n\n\nТочное число повторений (интервал) можно задать в фигурных скобках:\n\n\n\nПредставление\nЧисло повторений\n\n\n\n\n{n}\nРовно n раз\n\n\n{m,n}\nОт m до n включительно\n\n\n{m,}\nНе менее m\n\n\n{,n}\nНе более n\n\n\n\n\nstr_subset(text3, \"\\\\W{2,}$\")\n\n[1] \"( Э л е г и я ,)\"                         \n[2] \"Когда я отдохну въ объятияхъ твоихъ? . •.\"\n[3] \"И я мирюсь съ враждебною судьбой! . . •\"  \n[4] \"Появится въ лучахъ светило дня —\"         \n[5] \"Все радости, надежды все съ тобою —\"      \n[6] \"И радость сердце посещ аетъ. . . .\"       \n[7] \"Моя надежда — въ небесахъ!. . .\"          \n\n\n\n\n\n\n\n\nЗадание\n\n\n\nНайдите все слова в words, которые заканчиваются на x. Найдите все слова, которые начинаются (или не начинаются) на b или на g.\n\n\n\n\n4.1.3 Метасимволы и экранирование\nВсе метасимволы представлены в таблице ниже.\n\n\n\nОписание\nСимвол\n\n\n\n\nоткрывающая квадратная скобка\n[\n\n\nзакрывающая квадратная скобка\n]\n\n\nобратная косая черта\n\\\n\n\nкарет\n^\n\n\nзнак доллара\n$\n\n\nточка\n.\n\n\nвертикальная черта\n|\n\n\nзнак вопроса\n?\n\n\nастериск\n*\n\n\nплюс\n+\n\n\nоткрывающая фигурная скобка\n{\n\n\nзакрывающая фигурная скобка\n}\n\n\nоткрывающая круглая скобка\n(\n\n\nзакрывающая круглая скобка\n)\n\n\n\nКвадратные скобки используются для создания классов, карет и знак доллара – это якоря, но карет внутри квадратных скобок может также быть отрицанием. Точка – это любой знак.\n\n# любой символ после знака вопроса\nstr_subset(text3, \"\\\\?.\") \n\n[1] \"Когда я отдохну въ объятияхъ твоихъ? . •.\"\n\n\nДве косые черты перед знаком вопроса означают экранирование. Оно используется тогда, когда необходимо найти буквальную точку, буквальный знак вопроса и т.п., т.е. превратить метасимвол в литерал. Для этого перед знаком ставится косая черта. Но так как сама косая черта – это метасимвол, но нужно две косые черты, первая из которых экранирует вторую.\nЧасто используется последовательность .* для обозначения любого количества любых символов между двумя частями регулярного выражения. Вот так находим любой знак между двумя (буквальными) точками:\n\nstr_extract(text3, \"\\\\..\\\\.\")\n\n [1] NA    NA    NA    NA    NA    NA    NA    NA    NA    \". .\" NA    NA   \n[13] NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   \n[25] \". .\" \". .\" NA    NA    NA    NA    NA    NA   \n\n\nВот так – любое число знаков между двумя точками.\n\nstr_extract(text3, \"\\\\..*\\\\.\")\n\n [1] NA        NA        NA        NA        NA        \". •.\"    NA       \n [8] NA        NA        \". .\"     NA        NA        NA        NA       \n[15] NA        NA        NA        NA        NA        NA        NA       \n[22] NA        NA        NA        \". . . .\" \". . .\"   NA        NA       \n[29] NA        NA        NA        NA       \n\n\nВ регулярных выражениях квантификаторам соответствует максимально длинная строка из возможных (квантификаторы являются жадными, англ. greedy). Чтобы этого избежать, надо поставить после квантификатора знак вопроса. Это сделает его ленивым.\n\n\n\nregex\nзначение\n\n\n\n\n??\n0 или 1, лучше 0\n\n\n*?\n0 или больше, как можно меньше\n\n\n+?\n1 или больше, как можно меньше\n\n\n{n,m}?\nот n до m, как можно меньше\n\n\n\nПример:\n\nstr_extract(text3, \"\\\\..*?\\\\.\")\n\n [1] NA     NA     NA     NA     NA     \". •.\" NA     NA     NA     \". .\" \n[11] NA     NA     NA     NA     NA     NA     NA     NA     NA     NA    \n[21] NA     NA     NA     NA     \". .\"  \". .\"  NA     NA     NA     NA    \n[31] NA     NA    \n\n\n\n\n\n\n\n\nЗадание\n\n\n\nДана строка “tomorrow (and) tomorrow (and) tomorrow”. Необходимо удалить первые скобки с их содержанием. Узнайте, все ли предложения в sentences (входит в stringr) кончаются на точку. Найдите все слова в words, в которых есть любые два символа между b и k.\n\n\n\n\n4.1.4 Группировка и Look arounds\nДопустим, мы нашли несколько подряд знаков препинания и пробелов и хотим удалить лишние. Это можно сделать при помощи группировки\n\ntext4 &lt;- text3 |&gt; \n  # чтобы не потерять тире в конце строки\n  str_replace(\" —$\", \"—\") |&gt; \n  str_replace(\"(\\\\W)(\\\\W+)$\", \"\\\\1\")\n\ntext4\n\n [1] \"РАЗЛУКА.\"                                   \n [2] \"( Э л е г и я \"                             \n [3] \"Розалия, мой спутникъ неизменный\"           \n [4] \"На поле радостей земныхъ!\"                  \n [5] \"Розалия, мой другъ, хранитель несравненный!\"\n [6] \"Когда я отдохну въ объятияхъ твоихъ?\"       \n [7] \"Съ тобою горестей душа моя незнаетъ,\"       \n [8] \"И сердцу скорбному не изменитъ покой!\"      \n [9] \"Надежда мрачный путь звездою озаряетъ,\"     \n[10] \"И я мирюсь съ враждебною судьбой!\"          \n[11] \"Теперь, за дальними, свирепыми морями\"      \n[12] \"Твой сладкий гласъ не оживитъ меня!\"        \n[13] \"Взойдетъ заря надъ злачными холмами,\"       \n[14] \"Появится въ лучахъ светило дня—\"            \n[15] \"Напрасно! все кругомъ покрыто мглою.\"       \n[16] \"Неслышится мне сладкий игивой приветъ.\"     \n[17] \"Все радости, надежды все съ тобою—\"         \n[18] \"И опустелъ безъ милой светъ!\"               \n[19] \"Подруга милая, скажи, что край прелестный,\" \n[20] \"Что мирныя, тенисты я поля,\"                \n[21] \"Что своенравныя судьбы приветъ мне лестный,\"\n[22] \"Когда съ тобой въ разлуке я.\"               \n[23] \"Но другъ мои! горесть отл етаетъ\"           \n[24] \"На быстрыхъ времени крылахъ,\"               \n[25] \"И радость сердце посещ аетъ.\"               \n[26] \"Моя надежда — въ небесахъ!\"                 \n[27] \"Когдажъ опять смягченными судьбами\"         \n[28] \"Я въ радости къ подруге понесусь,\"          \n[29] \"Коснусь волшебныхъ струнъ волшебными пер\"   \n[30] \"стами\"                                      \n[31] \"И, съ резвою мечтою примирюсь.\"             \n[32] \"А, Б — фЪ.\"                                 \n\n\nНам осталось удалить твердые знаки в конце слов (то есть перед пробелами, пунктуацией или в конце строки). Используем для этого так называемые look arounds.\n\n\n\n\n\n\n\n\nЗапись\nНазвание на русском\nОписание\n\n\n\n\n(?=...)\nПоложительный просмотр вперёд\nСовпадает, если … находится в текущей позиции (но не захватывает его в результат).\n\n\n(?!...)\nОтрицательный просмотр вперёд\nСовпадает, если … не находится в текущей позиции (не захватывает в результат).\n\n\n(?&lt;=...)\nПоложительный просмотр назад\nСовпадает, если … находится сразу перед текущей позицией (длина … должна быть ограниченной).\n\n\n(?&lt;!...)\nОтрицательный просмотр назад\nСовпадает, если … не находится сразу перед текущей позицией (длина … должна быть ограниченной).\n\n\n\nstr_view(text4, \"[ъЪ](?=\\\\W)\", html = TRUE)\n\n\nТеперь удалим такие знаки препинания, которые следуют за другими знаками препинания в конце строки. Также добавим в контекст сам конец строки (иначе остается с твердым знаком слово “отлетает”).\n\ntext5 &lt;- str_remove_all(text4, \"[ъЪ](?=\\\\W|$)\")\ntext5\n\n [1] \"РАЗЛУКА.\"                                  \n [2] \"( Э л е г и я \"                            \n [3] \"Розалия, мой спутник неизменный\"           \n [4] \"На поле радостей земных!\"                  \n [5] \"Розалия, мой друг, хранитель несравненный!\"\n [6] \"Когда я отдохну в объятиях твоих?\"         \n [7] \"С тобою горестей душа моя незнает,\"        \n [8] \"И сердцу скорбному не изменит покой!\"      \n [9] \"Надежда мрачный путь звездою озаряет,\"     \n[10] \"И я мирюсь с враждебною судьбой!\"          \n[11] \"Теперь, за дальними, свирепыми морями\"     \n[12] \"Твой сладкий глас не оживит меня!\"         \n[13] \"Взойдет заря над злачными холмами,\"        \n[14] \"Появится в лучах светило дня—\"             \n[15] \"Напрасно! все кругом покрыто мглою.\"       \n[16] \"Неслышится мне сладкий игивой привет.\"     \n[17] \"Все радости, надежды все с тобою—\"         \n[18] \"И опустел без милой свет!\"                 \n[19] \"Подруга милая, скажи, что край прелестный,\"\n[20] \"Что мирныя, тенисты я поля,\"               \n[21] \"Что своенравныя судьбы привет мне лестный,\"\n[22] \"Когда с тобой в разлуке я.\"                \n[23] \"Но друг мои! горесть отл етает\"            \n[24] \"На быстрых времени крылах,\"                \n[25] \"И радость сердце посещ ает.\"               \n[26] \"Моя надежда — в небесах!\"                  \n[27] \"Когдаж опять смягченными судьбами\"         \n[28] \"Я в радости к подруге понесусь,\"           \n[29] \"Коснусь волшебных струн волшебными пер\"    \n[30] \"стами\"                                     \n[31] \"И, с резвою мечтою примирюсь.\"             \n[32] \"А, Б — ф.\"                                 \n\n\n\n\n4.1.5 Оборачиваем в функцию\n\nnormalize_text &lt;- function(text) {\n  # подумайте, нужно ли вам удалять строки с цифрами!\n  text[!str_detect(text, \"\\\\d\") & nchar(text) != 0] |&gt; \n    str_squish() |&gt; \n    str_replace_all(c(\"і\" = \"и\", \"ѣ\" = \"е\")) |&gt;\n    str_replace(\" —$\", \"—\") |&gt; \n    str_replace(\"(\\\\W)(\\\\W+)$\", \"\\\\1\") |&gt; \n    str_remove_all(\"[ъЪ](?=\\\\W|$)\")\n}\n\nnormalize_text(text)\n\n [1] \"РАЗЛУКА.\"                                  \n [2] \"( Э л е г и я \"                            \n [3] \"Розалия, мой спутник неизменный\"           \n [4] \"На поле радостей земных!\"                  \n [5] \"Розалия, мой друг, хранитель несравненный!\"\n [6] \"Когда я отдохну в объятиях твоих?\"         \n [7] \"С тобою горестей душа моя незнает,\"        \n [8] \"И сердцу скорбному не изменит покой!\"      \n [9] \"Надежда мрачный путь звездою озаряет,\"     \n[10] \"И я мирюсь с враждебною судьбой!\"          \n[11] \"Теперь, за дальними, свирепыми морями\"     \n[12] \"Твой сладкий глас не оживит меня!\"         \n[13] \"Взойдет заря над злачными холмами,\"        \n[14] \"Появится в лучах светило дня—\"             \n[15] \"Напрасно! все кругом покрыто мглою.\"       \n[16] \"Неслышится мне сладкий игивой привет.\"     \n[17] \"Все радости, надежды все с тобою—\"         \n[18] \"И опустел без милой свет!\"                 \n[19] \"Подруга милая, скажи, что край прелестный,\"\n[20] \"Что мирныя, тенисты я поля,\"               \n[21] \"Что своенравныя судьбы привет мне лестный,\"\n[22] \"Когда с тобой в разлуке я.\"                \n[23] \"Но друг мои! горесть отл етает\"            \n[24] \"На быстрых времени крылах,\"                \n[25] \"И радость сердце посещ ает.\"               \n[26] \"Моя надежда — в небесах!\"                  \n[27] \"Когдаж опять смягченными судьбами\"         \n[28] \"Я в радости к подруге понесусь,\"           \n[29] \"Коснусь волшебных струн волшебными пер\"    \n[30] \"стами\"                                     \n[31] \"И, с резвою мечтою примирюсь.\"             \n[32] \"А, Б — ф.\"                                 \n\n\nВ зависимости от задачи, продумайте свою нормализацию. Она может включать в себя склейку переносов и другие преобразования.\n\nwriteLines(text5[-c(1,2,32)], con = \"../ocr/rosalia_norm.txt\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Нормализация и оценка</span>"
    ]
  },
  {
    "objectID": "regex.html#оценка-качества-распознавания",
    "href": "regex.html#оценка-качества-распознавания",
    "title": "4  Нормализация и оценка",
    "section": "4.2 Оценка качества распознавания",
    "text": "4.2 Оценка качества распознавания\n\n\n\n _________________________________ \n&lt;Этот раздел еще дорабатывается.&gt;\n --------------------------------- \n      \\\n       \\\n\n        ^__^ \n        (oo)\\ ________ \n        (__)\\         )\\ /\\ \n             ||------w|\n             ||      ||\n\n\n\n4.2.1 Метрики качества OCR: CER и WER\nДля оценки качества распознавания текста (OCR) стандартно используются две метрики — CER (Character Error Rate) и WER (Word Error Rate). Обе рассчитываются на основе расстояния Левенштейна — минимального числа вставок, удалений или замен, необходимых для преобразования одного текста в другой.\n\nCER (ошибки на символ):\nCER = (редакционное расстояние по символам) / (число символов в эталонном тексте)\nWER (ошибки на слова):\nWER = (редакционное расстояние по словам) / (число слов в эталонном тексте)\n\nЭталонный текст — это корректная разметка (ground truth), а распознанный текст — результат работы OCR.\nЗачем нужны обе метрики:\n\nCER чувствительнее к отдельным опечаткам, диакритическим знакам и пунктуации.\nWER лучше отражает читабельность и пригодность текста для поиска, анализа и других практических задач — поэтому особенно полезна при оценке итогового качества корпуса.\n\nДля работы нам понадобятся следующие пакеты.\n\nlibrary(stringdist)\nlibrary(stringi)\n\nТакже загрузим для сравнения три текста: эталон и два результата распознавания (один из них очень плохой и не нормализованный).\n\nref &lt;- readLines(\"../ocr/rosalia_gt.txt\") |&gt; \n  str_c(collapse = \"\\n\")\nhyp1 &lt;- readLines(\"../ocr/rosalia_norm.txt\") |&gt; \n  str_c(collapse = \"\\n\")\nhyp2 &lt;- readLines(\"../ocr/rosalia_3.txt\") |&gt; \n  str_c(collapse = \"\\n\") \n\n\n\n4.2.2 CER: ред. расстояние по символам / длина эталона\nНапишем фунκцию, которая будет сравнивать эталон с гипотезой.\n\ncer &lt;- function(ref, hyp) {\n  \n  dist &lt;- stringdist(ref, hyp, method = \"lv\") # Левенштейн\n  nref &lt;- nchar(ref, type = \"chars\")\n  if (nref == 0) return(NA_real_)\n  dist / nref\n}\n\n\ncer(ref, hyp1)\n\n[1] 0.007494647\n\ncer(ref, hyp2)\n\n[1] 0.2109208\n\n\n\n\n4.2.3 WER: ред. расстояние по словам / число слов эталона\n\nwer &lt;- function(ref, hyp) {\n  \n  # Разбиваем на слова, удаляя пустые строки\n  ref_words &lt;- unlist(strsplit(ref, \"\\\\s+\"))\n  hyp_words &lt;- unlist(strsplit(hyp, \"\\\\s+\"))\n  \n  ref_words &lt;- ref_words[ref_words != \"\"]\n  hyp_words &lt;- hyp_words[hyp_words != \"\"]\n  \n  # Создаем матрицу для расчета расстояния Левенштейна\n  n_ref &lt;- length(ref_words)\n  n_hyp &lt;- length(hyp_words)\n  \n  # Инициализируем матрицу\n  d &lt;- matrix(0, nrow = n_ref + 1, ncol = n_hyp + 1)\n  d[,1] &lt;- 0:n_ref\n  d[1,] &lt;- 0:n_hyp\n  \n  # Заполняем матрицу расстояний\n  for (i in 1:n_ref) {\n    for (j in 1:n_hyp) {\n      if (ref_words[i] == hyp_words[j]) {\n        d[i+1, j+1] &lt;- d[i, j]  # слова совпадают\n      } else {\n        d[i+1, j+1] &lt;- min(\n          d[i, j+1] + 1,   # удаление\n          d[i+1, j] + 1,   # вставка  \n          d[i, j] + 1      # замена\n        )\n      }\n    }\n  }\n  \n  # Возвращаем WER\n  d[n_ref + 1, n_hyp + 1] / n_ref\n}\n\n\nwer(ref, hyp1)\n\n[1] 0.0625\n\nwer(ref, hyp2)\n\n[1] 0.5486111",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Нормализация и оценка</span>"
    ]
  },
  {
    "objectID": "regex.html#видео",
    "href": "regex.html#видео",
    "title": "4  Нормализация и оценка",
    "section": "4.3 Видео",
    "text": "4.3 Видео\n\nВидео 2025 г.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Нормализация и оценка</span>"
    ]
  },
  {
    "objectID": "xml.html",
    "href": "xml.html",
    "title": "5  Разметка TEI XML",
    "section": "",
    "text": "5.1 Основы XML\nXML (от англ. eXtensible Markup Language) — расширяемый язык разметки. Слово “расширяемый” означает, что список тегов не зафиксирован раз и навсегда: пользователи могут вводить свои собственные теги и создавать так называемые настраиваемые языки разметки (Холзнер 2004, 29). Один из таких настраиваемых языков – это TEI (Text Encoding Initiative), о котором будет сказано дальше.\nДля работы нам понадобятся следующие библиотеки:\nНазначение языков разметки заключается в описании структурированных документов. Структура документа представляется в виде набора вложенных в друг друга элементов (дерева XML). У элементов есть открывающие и закрывающие теги. Все составляющие части документа обобщаются в пролог и корневой элемент. Корневой элемент — обязательная часть документа, в которую вложены все остальные элементы. Пролог может включать объявления, инструкции обработки, комментарии.\nВ правильно сформированном XML открывающий и закрывающий тег вложенного элемента всегда находятся внутри одного родительского элемента.\nСоздадим простой XML из строки. Сначала идет инструкция по обработке XML (со знаком вопроса), за ней следует объявление типа документа (с восклицательным знаком) и открывающий тег корневого элемента. В этот корневой элемент вложены все остальные элементы.\nstring_xml &lt;- '&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;!DOCTYPE recipe&gt;\n&lt;recipe name=\"хлеб\" preptime=\"5min\" cooktime=\"180min\"&gt;\n   &lt;title&gt;\n      Простой хлеб\n   &lt;/title&gt;\n   &lt;composition&gt;\n      &lt;ingredient amount=\"3\" unit=\"стакан\"&gt;Мука&lt;/ingredient&gt;\n      &lt;ingredient amount=\"0.25\" unit=\"грамм\"&gt;Дрожжи&lt;/ingredient&gt;\n      &lt;ingredient amount=\"1.5\" unit=\"стакан\"&gt;Тёплая вода&lt;/ingredient&gt;\n   &lt;/composition&gt;\n   &lt;instructions&gt;\n     &lt;step&gt;\n        Смешать все ингредиенты и тщательно замесить. \n     &lt;/step&gt;\n     &lt;step&gt;\n        Закрыть тканью и оставить на один час в тёплом помещении. \n     &lt;/step&gt;\n     &lt;step&gt;\n        Замесить ещё раз, положить на противень и поставить в духовку.\n     &lt;/step&gt;\n   &lt;/instructions&gt;\n&lt;/recipe&gt;'",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Разметка TEI XML</span>"
    ]
  },
  {
    "objectID": "xml.html#основы-xml",
    "href": "xml.html#основы-xml",
    "title": "5  Разметка TEI XML",
    "section": "",
    "text": "5.1.1 Библиотека xml2\nДля работы с xml понадобится установить библиотеку xml2. Функция read_xml() создаст объект, представляющий дерево XML.\n\ndoc &lt;- read_xml(string_xml)\nclass(doc)\n\n[1] \"xml_document\" \"xml_node\"    \n\n\nФункция xml_root() позволяет извлечь корневой элемент вместе со всеми детьми.\n\nrootnode &lt;- xml_root(doc)\nrootnode\n\n{xml_document}\n&lt;recipe name=\"хлеб\" preptime=\"5min\" cooktime=\"180min\"&gt;\n[1] &lt;title&gt;\\n      Простой хлеб\\n   &lt;/title&gt;\n[2] &lt;composition&gt;\\n  &lt;ingredient amount=\"3\" unit=\"стакан\"&gt;Мука&lt;/ingredient&gt;\\n ...\n[3] &lt;instructions&gt;\\n  &lt;step&gt;\\n        Смешать все ингредиенты и тщательно зам ...\n\n\nУ корневого элемента есть “дети”. Это набор узлов.\n\nxml_children(rootnode)\n\n{xml_nodeset (3)}\n[1] &lt;title&gt;\\n      Простой хлеб\\n   &lt;/title&gt;\n[2] &lt;composition&gt;\\n  &lt;ingredient amount=\"3\" unit=\"стакан\"&gt;Мука&lt;/ingredient&gt;\\n ...\n[3] &lt;instructions&gt;\\n  &lt;step&gt;\\n        Смешать все ингредиенты и тщательно зам ...\n\n\nУ детей есть имена, которые можно извлечь специальной функцией.\n\nxml_name(xml_children(rootnode))\n\n[1] \"title\"        \"composition\"  \"instructions\"\n\n\n\n\n5.1.2 Выбор элементов\nОбращаться к узлам можно по имени или по индексу.\n\n# 1. Выбрать узел по имени:\ncomposition_node &lt;- xml_find_first(rootnode, \"composition\")\ncomposition_node\n\n{xml_node}\n&lt;composition&gt;\n[1] &lt;ingredient amount=\"3\" unit=\"стакан\"&gt;Мука&lt;/ingredient&gt;\n[2] &lt;ingredient amount=\"0.25\" unit=\"грамм\"&gt;Дрожжи&lt;/ingredient&gt;\n[3] &lt;ingredient amount=\"1.5\" unit=\"стакан\"&gt;Тёплая вода&lt;/ingredient&gt;\n\n\n\n# 2. Выбрать узел по индексу (например, второй дочерний узел):\ncomposition_node &lt;- xml_children(rootnode)[[2]]\ncomposition_node\n\n{xml_node}\n&lt;composition&gt;\n[1] &lt;ingredient amount=\"3\" unit=\"стакан\"&gt;Мука&lt;/ingredient&gt;\n[2] &lt;ingredient amount=\"0.25\" unit=\"грамм\"&gt;Дрожжи&lt;/ingredient&gt;\n[3] &lt;ingredient amount=\"1.5\" unit=\"стакан\"&gt;Тёплая вода&lt;/ingredient&gt;\n\n\n\n# 3. Комбинировать выбор: второй узел -&gt; первый элемент:\ningr_node_1 &lt;- xml_find_first(composition_node, \"ingredient\")\ningr_node_1\n\n{xml_node}\n&lt;ingredient amount=\"3\" unit=\"стакан\"&gt;\n\n\n\n\n5.1.3 Значения узлов и атрибутов\nНо обычно нам нужен не элемент как таковой, а его содержание (значение). Чтобы добраться до него, используем функцию xml_text():\n\nxml_children(composition_node) |&gt; \n  xml_text()\n\n[1] \"Мука\"        \"Дрожжи\"      \"Тёплая вода\"\n\n\nМожно уточнить атрибуты узла при помощи xml_attrs():\n\nxml_children(composition_node) |&gt; \n  xml_attrs()\n\n[[1]]\n  amount     unit \n     \"3\" \"стакан\" \n\n[[2]]\n amount    unit \n \"0.25\" \"грамм\" \n\n[[3]]\n  amount     unit \n   \"1.5\" \"стакан\" \n\n\nЧтобы извлечь значение атрибута, используем функцию xml_attr(). Первым аргументом функции передаем xml-узел, вторым – имя атрибута.\n\nxml_attr(xml_children(composition_node), \"unit\")\n\n[1] \"стакан\" \"грамм\"  \"стакан\"\n\n\n\n\n5.1.4 Синтаксис XPath\nДобраться до узлов определенного уровня можно также при помощи синтаксиса XPath. XPath – это язык запросов к элементам XML-документа. С его помощью можно описать “путь” до нужного узла: абсолютный (начиная с корневого элемента) или относительный. В пакете xml синтаксис XPath поддерживает функция xml_find_all().\n\n# абсолютный путь\nxml_find_all(rootnode, \"/recipe//composition//ingredient\")\n\n{xml_nodeset (3)}\n[1] &lt;ingredient amount=\"3\" unit=\"стакан\"&gt;Мука&lt;/ingredient&gt;\n[2] &lt;ingredient amount=\"0.25\" unit=\"грамм\"&gt;Дрожжи&lt;/ingredient&gt;\n[3] &lt;ingredient amount=\"1.5\" unit=\"стакан\"&gt;Тёплая вода&lt;/ingredient&gt;\n\n# относительный путь\nxml_find_all(rootnode, \"//composition//ingredient\")\n\n{xml_nodeset (3)}\n[1] &lt;ingredient amount=\"3\" unit=\"стакан\"&gt;Мука&lt;/ingredient&gt;\n[2] &lt;ingredient amount=\"0.25\" unit=\"грамм\"&gt;Дрожжи&lt;/ingredient&gt;\n[3] &lt;ingredient amount=\"1.5\" unit=\"стакан\"&gt;Тёплая вода&lt;/ingredient&gt;\n\n# атрибут unit == \"стакан\"\nxml_find_all(rootnode, \"//composition//ingredient[@unit='стакан']\")\n\n{xml_nodeset (2)}\n[1] &lt;ingredient amount=\"3\" unit=\"стакан\"&gt;Мука&lt;/ingredient&gt;\n[2] &lt;ingredient amount=\"1.5\" unit=\"стакан\"&gt;Тёплая вода&lt;/ingredient&gt;\n\n\n\n\n\n\n\n\nНа заметку\n\n\n\nВ большинстве случаев функция требует задать пространство имен (namespace), но в нашем случае оно не определено, поэтому пока передаем только дерево и путь до узла. С пространством имен встретимся чуть позже!\n\n\n\n\n5.1.5 От дерева к таблице\nПри работе с xml в большинстве случаев наша задача – извлечь значения определеннных узлов или их атрибутов и сохранить их в прямоугольном формате.\n\n# Получаем узлы:\ntitle &lt;- xml_find_all(rootnode, \"title\") |&gt; \n  xml_text() |&gt; \n  trimws()\n\ningredient_ns &lt;- xml_find_all(rootnode, \"//composition//ingredient\")\n\ntibble(\n  title  = title,\n  ingredients = xml_text(ingredient_ns),\n  unit = xml_attr(ingredient_ns, \"unit\"),\n  amount = xml_attr(ingredient_ns, \"amount\")\n) |&gt; \n  print()\n\n# A tibble: 3 × 4\n  title        ingredients unit   amount\n  &lt;chr&gt;        &lt;chr&gt;       &lt;chr&gt;  &lt;chr&gt; \n1 Простой хлеб Мука        стакан 3     \n2 Простой хлеб Дрожжи      грамм  0.25  \n3 Простой хлеб Тёплая вода стакан 1.5   \n\n\nТеперь рассмотрим более сложные примеры.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Разметка TEI XML</span>"
    ]
  },
  {
    "objectID": "xml.html#разметка-tei",
    "href": "xml.html#разметка-tei",
    "title": "5  Разметка TEI XML",
    "section": "5.2 Разметка TEI",
    "text": "5.2 Разметка TEI\nTEI (Text Encoding Initiative) — специализированный язык разметки на основе XML, разработанный как средство формального кодирования наиболее значимых текстологических свойств документа: физических параметров рукописи, критического аппарата, лингвистической информации, выходных данных, сведений об авторе, обстоятельствах публикации и первоисточнике (Скоринкин 2016). TEI появился в 1987 г. и в наши дни стал де-факто стандартом для создания цифровых гуманитарных ресурсов.\nОсновная задача структурированной разметки — формальное эксплицитное представление некоторых свойств документа, заложенных в нем имплицитно. Например, для человека очевидно, где в тексте романа кончается одна часть и начинается другая, какие герои упоминаются в той или иной главе, какие реплики кем произнесены. Однако для машины ничего из этого не является «очевидным» — электронный текст без разметки остается не более чем цепочкой символов.\nБольшая часть размеченных литературных корпусов хранится именно в формате XML. Это очень удобно, и вот почему: с помощью тегов XML мы можем достать из документа именно то, что нам интересно: определенную главу, речи конкретных персонажей, слова на иностранных языках и т.п.\nИспользование TEI обеспечивает:\n\nХранение богатой метаинформации о тексте и его носителях;\nКодирование структуры текста и лингвистической разметки;\nНезависимость от конкретного ПО;\nОткрытость для доработки и расширения;\nОптимизацию для автоматической обработки.\n\nДобавлять и удалять разметку может любой пользователь в редакторе XML кода или даже в простом текстовом редакторе. Стандарт TEI предоставляет исследователям универсальный метаязык для обмена текстологической информацией и встраивает документы в мировую коллекцию машиночитаемых текстов.\n\n5.2.1 Структура документа TEI\nКорневой элемент в документах TEI называется TEI, внутри него располагается элемент teiHeader с метаинформацией о документе и элемент text. Последний содержит текст документа с элементами, определяющими его структурное членение.\n&lt;TEI&gt;\n  &lt;teiHeader&gt;&lt;/teiHeader&gt;\n  &lt;text&gt;&lt;/text&gt;\n&lt;/TEI&gt;\nПример оформления документа можно посмотреть по ссылке.\n\n\n5.2.2 teiHeader\nУ teiHeader есть четыре главных дочерних элемента:\n\nfileDesc (описание документа c библиографической информацией)\nencodingDesc (описание способа кодирование первоисточника)\nprofileDesc (“досье” на текст, например отправитель и получатель для писем, жанр, используемые языки, обстоятельства создания, место написания и т.п.)\nrevisionDesc (история изменений документа).\n\nЭлемент fileDesc должен содержать полную библиографическую информацию о первоисточнике. Пример для повести Л.Н. Толстого «Детство»:\n&lt;fileDesc&gt;\n  &lt;titleStmt&gt;\n    &lt;title&gt;Повесть «Детство». Электронное издание.&lt;/title&gt;\n    &lt;author&gt;Толстой Л.Н.&lt;/author&gt;\n    &lt;editor&gt;Иванов И.И.&lt;/editor&gt;\n    &lt;respStmt&gt;\n      &lt;resp&gt;Подготовка и разметка метаинформации для электронного издания&lt;/resp&gt;\n      &lt;name&gt;Иванов И.И.&lt;/name&gt;\n    &lt;/respStmt&gt;\n  &lt;/titleStmt&gt;\n  &lt;publicationStmt&gt;\n    &lt;publisher&gt;Школа лингвистики &lt;orgName&gt;НИУ ВШЭ&lt;/orgName&gt;&lt;/publisher&gt;\n    &lt;availability&gt;\n      &lt;p&gt;Распространяется свободно&lt;/p&gt;\n    &lt;/availability&gt;\n  &lt;/publicationStmt&gt;\n  &lt;sourceDesc&gt;\n    &lt;biblStruct&gt;\n      &lt;author&gt;Толстой Л.Н.&lt;/author&gt;\n      &lt;title level=\"a\"&gt;Детство&lt;/title&gt;\n      &lt;monogr&gt;\n        &lt;title level=\"m\"&gt;Полное собрание сочинений. Том 1&lt;/title&gt;\n        &lt;imprint&gt;\n          &lt;pubPlace&gt;Москва&lt;/pubPlace&gt;\n          &lt;publisher&gt;Государственное издательство \"Художественная литература\"&lt;/publisher&gt;\n          &lt;date when=\"1935\"/&gt;\n        &lt;/imprint&gt;\n      &lt;/monogr&gt;\n    &lt;/biblStruct&gt;\n  &lt;/sourceDesc&gt;\n&lt;/fileDesc&gt;\nЭлемент &lt;profileDesc&gt; содержит метаданные, относящиеся непосредственно к тексту:\n&lt;profileDesc&gt;\n  &lt;creation&gt;\n    &lt;date when=\"1852\"&gt;1852&lt;/date&gt;\n    &lt;placeName&gt;Москва&lt;/placeName&gt;\n    &lt;placeName&gt;станица Старогладковская&lt;/placeName&gt;\n    &lt;placeName&gt;Тифлис&lt;/placeName&gt;\n  &lt;/creation&gt;\n  &lt;langUsage&gt;\n    &lt;language ident=\"rus\" usage=\"99\"&gt;Русский&lt;/language&gt;\n    &lt;language ident=\"fra\" usage=\"0,5\"&gt;Французский&lt;/language&gt;\n    &lt;language ident=\"deu\" usage=\"0,5\"&gt;Немецкий&lt;/language&gt;\n  &lt;/langUsage&gt;\n  &lt;textClass&gt;\n    &lt;catRef type=\"type\" target=\"#short_novel\"/&gt;\n  &lt;/textClass&gt;\n&lt;/profileDesc&gt;\n\n\n5.2.3 Варианты и исправления\nВ самом тексте язык TEI дает возможность представлять разные варианты (авторские, редакторские, корректорские и др.) Основным средством параллельного представления является элемент choice. Например, в тексте Лукреция вы можете увидеть такое:\nsic calor atque &lt;choice&gt;&lt;reg&gt;aer&lt;/reg&gt;&lt;orig&gt;aër&lt;/orig&gt;&lt;/choice&gt; et venti caeca potestas\nЗдесь reg указывает на нормализованное написание, а orig – на оригинальное.\nДля исправления ошибок используются элементы &lt;sic&gt; («так у автора») и &lt;corr&gt; («исправленное написание»):\n&lt;choice&gt;\n  &lt;sic&gt;вихремъ&lt;/sic&gt;\n  &lt;corr resp=\"#editor1\"&gt;верхомъ&lt;/corr&gt;\n&lt;/choice&gt;\nАтрибут resp содержит ссылку на идентификатор редактора.\n\n\n5.2.4 Структурная разметка\nTEI предоставляет богатый набор элементов для разметки структуры текста:\n\n&lt;text&gt; — текст целиком\n&lt;body&gt; — основное содержание текста\n&lt;div&gt; — структурное деление (глава, часть, раздел)\n&lt;p&gt; — параграф\n&lt;l&gt; — стихотворная строка\n&lt;lg&gt; — группа стихотворных строк (строфа)\n&lt;sp&gt; — речь персонажа в драме\n&lt;stage&gt; — ремарка\n\nПример разметки поэзии:\n&lt;lg type=\"quatrain\"&gt;\n  &lt;l met=\"+-|+-|+-|+-\"&gt;Дар напрасный, дар случайный,&lt;/l&gt;\n  &lt;l met=\"+-|+-|+-|+\"&gt;Жизнь, зачем ты мне дана?&lt;/l&gt;\n  &lt;l met=\"+-|+-|+-|+-\"&gt;Иль зачем судьбою тайной&lt;/l&gt;\n  &lt;l met=\"+-|+-|--|+\"&gt;Ты на казнь осуждена?&lt;/l&gt;\n&lt;/lg&gt;",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Разметка TEI XML</span>"
    ]
  },
  {
    "objectID": "xml.html#кейс-горе-от-ума",
    "href": "xml.html#кейс-горе-от-ума",
    "title": "5  Разметка TEI XML",
    "section": "5.3 Кейс: “Горе от ума”",
    "text": "5.3 Кейс: “Горе от ума”\nСкачаем по из репозитория проекта Dracor “Горе от ума” Грибоедова и преобразуем xml в прямоугольный формат таким образом, чтобы для каждой реплики был указан акт, сцена и действующее лицо.\n\n\n\n\n\n\nНа заметку\n\n\n\nДля работы с корпусом Dracor в среде R существует пакет rdracor. Он позволяет доставать тексты пьес сразу в виде таблицы.\n\n\n\nurl &lt;- \"https://raw.githubusercontent.com/dracor-org/rusdracor/main/tei/griboyedov-gore-ot-uma.xml\"\ndownload_xml(url, file = \"griboedov.xml\")\n\n\ndoc &lt;- read_xml(\"griboedov.xml\")\n\n# определить пространство имён\nns &lt;- xml_ns(doc)\nns\n\nd1 &lt;-&gt; http://www.tei-c.org/ns/1.0\n\n\nПространство имён (namespace) в XML — это механизм, который позволяет однозначно различать элементы и атрибуты с одинаковыми именами, но из разных словарей или стандартов. Оно действует как “фамилия” для элемента. Чтобы задать “фамилию”, её связывают с уникальным идентификатором (обычно это URI, в нашем случае http://www.tei-c.org/ns/1.0). Для удобства этому идентификатору присваивают короткий префикс.\n\n# Найти все строки (tei:l)\nline_nodes &lt;- xml_find_all(doc, \"//d1:l\", ns)\n\n# Извлечь текст каждой строки\nline_text &lt;- xml_text(line_nodes)\n\nline_text |&gt; \n  head()\n\n[1] \"Светает!.. Ах! как скоро ночь минула!\"  \n[2] \"Вчера просилась спать — отказ.\"         \n[3] \"«Ждем друга». — Нужен глаз да глаз,\"    \n[4] \"Не спи, покудова не скатишься со стула.\"\n[5] \"Теперь вот только что вздремнула,\"      \n[6] \"Уж день!.. сказать им...\"               \n\n\nТеперь нам надо для каждой реплики найти информацию о том, кто говорит: она хранится в теге &lt;speaker&gt;. То есть нам надо подняться на два этажа вверх (на уровень &lt;sp&gt;), а потом спуститься к его другому “ребенку”, &lt;speaker&gt;. Для этого используем синтаксис XPath: сначала при помощи ancestor::d1:sp поднимаемся вверх по дереву и выбираем всех предков узла, которые являются элементами sp, а затем спускаемся к ребенку speaker этого найденного sp. Так список спикеров будет равно числу стихов.\n\n# line_nodes — вектор узлов &lt;l&gt;\nspeakers &lt;- xml_find_first(line_nodes, \"ancestor::d1:sp/d1:speaker\", ns = ns) |&gt; \n  xml_text()\n\nspeakers |&gt; \n  head()\n\n[1] \"Лизанька\" \"Лизанька\" \"Лизанька\" \"Лизанька\" \"Лизанька\" \"Лизанька\"\n\n\nАналогичным образом находим явление и акт.\n\nscenes &lt;- xml_find_first(line_nodes, \"ancestor::d1:div[@type='scene']/d1:head\", ns = ns) |&gt; \n  xml_text()\n\nscenes |&gt; \n  tail()\n\n[1] \"Явление 15\" \"Явление 15\" \"Явление 15\" \"Явление 15\" \"Явление 15\"\n[6] \"Явление 15\"\n\n\n\nacts &lt;- xml_text(\n  xml_find_first(line_nodes, \"ancestor::d1:div[@type='act']/d1:head\", ns = ns)\n)\n\nacts |&gt; \n  sample(6)\n\n[1] \"Действие четвертое\" \"Действие третье\"    \"Действие второе\"   \n[4] \"Действие второе\"    \"Действие первое\"    \"Действие первое\"   \n\n\nНам осталось объединить все векторы в одну таблицу.\n\nwoe_from_wit &lt;- tibble(\n  act = acts,\n  scene = scenes,\n  speaker = speakers,\n  text = line_text\n)\n\n\n\n\n\n\n\n\n\nact\nscene\nspeaker\ntext\n\n\n\n\nДействие первое\nЯвление 1\nЛизанька\nСветает!.. Ах! как скоро ночь минула!\n\n\nДействие первое\nЯвление 1\nЛизанька\nВчера просилась спать — отказ.\n\n\nДействие первое\nЯвление 1\nЛизанька\n«Ждем друга». — Нужен глаз да глаз,\n\n\nДействие первое\nЯвление 1\nЛизанька\nНе спи, покудова не скатишься со стула.\n\n\nДействие первое\nЯвление 1\nЛизанька\nТеперь вот только что вздремнула,\n\n\nДействие первое\nЯвление 1\nЛизанька\nУж день!.. сказать им...",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Разметка TEI XML</span>"
    ]
  },
  {
    "objectID": "xml.html#видео-к-уроку",
    "href": "xml.html#видео-к-уроку",
    "title": "5  Разметка TEI XML",
    "section": "5.4 Видео к уроку",
    "text": "5.4 Видео к уроку\n\nВидео 2025 г.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Разметка TEI XML</span>"
    ]
  },
  {
    "objectID": "xml.html#домашнее-задание",
    "href": "xml.html#домашнее-задание",
    "title": "5  Разметка TEI XML",
    "section": "5.5 Домашнее задание",
    "text": "5.5 Домашнее задание\n\nДедлайн: 14 ноября 21-00.\nСсылка: https://classroom.github.com/a/l-jxHG39\nОценивание: 0/1\nДанные, подробные инструкции и заготовку для скрипта вы найдете в репозитории. Репозиторий надо клонировать (создать новый локальный проект под контролем версий), отредактировать скрипт согласно инструкции (не переименовывайте файл!), запушить изменения.\nПроверка автоматическая, обычно занимает до 20 минут, выполняется после каждого коммита / пуша. Можно пушить сколько угодно раз до дедлайна. В случае прохождения всех тестов (после обновления страницы) вы увидите зеленую галочку.\n\n\n\nПочему это не быстро? Потому что GitHub Actions при каждой проверке запускает “чистую” виртуальную машину (как правило, Ubuntu), где установлены только базовые вещи типа R, Python и т.д.\nЕсли тесты не пройдены, напротив коммита будет красный крест.\n\n\n\nВы можете пройти на вкладку Actions (см. фото выше), найти там свой коммит (вы же его как-то назвали, помните?) и посмотреть ошибку. После исправления ошибки сделайте новый коммит.\n\nВот так выглядит вкладка Actions. Желтый цвет означает, что workflow в работе.\n Если нажать на коммит (здесь: sumbit hw xml) -&gt; test -&gt; Run tests, можно увидеть детали проверки.\n\n\nВнимательно читайте сообщения об ошибках! Их можно и нужно показывать LLM (например, DeepSeek), которые помогут доработать код.\nВаша задача: добиться прохождения всех тестов! В противном случае задание не засчитывается.\n\n\nПодбробнее о структуре XML документов и способах работы с ними вы можете прочитать в книгах: (Nolan и Lang 2014) и (Холзнер 2004).\n\n\n\n\nNolan, D., и D. T. Lang. 2014. XML and Web Technologies for Data Science with R. Springer.\n\n\nСкоринкин, Даниил. 2016. «Электронное представление текста с помощью стандарта разметки TEI», 90–108.\n\n\nХолзнер, Стивен. 2004. Энциклопедия XML. Питер.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Разметка TEI XML</span>"
    ]
  },
  {
    "objectID": "POS.html",
    "href": "POS.html",
    "title": "6  Лемматизация и тематическое моделирование",
    "section": "",
    "text": "6.1 Данные\nОсновные этапы NLP включают в себя токенизацию, морфологический и синтаксический анализ, а также анализ семантики и прагматики. В этом уроке речь пойдет про первые три этапа. Мы научимся разбивать текст на токены (слова), определять морфологические характеристики слов и находить их начальные формы (леммы), а также анализировать структуру предложения с использованием синтаксических парсеров.\nЗа основу для всех эти вычислений мы возьмем три философских трактата, написанных на английском языке. Это хронологически и тематически близкие тексты:\nДанные были извлечены из открытой библиотеки Gutengerg при помощи пакета {gutenbergr}и приведены к опрятному виду. Скачать подготовленный таким образом корпус можно здесь.\nload(\"../data/emp_corpus.Rdata\")\nДелим корпус на слова уже известным вам способом.\ncorpus_words &lt;- emp_corpus |&gt; \n  unnest_tokens(word, text)\n\ncorpus_words\nБольшая часть слов, которые мы сейчас видим в корпусе – это шумовые слова, или стоп-слова, не несущие смысловой нагрузки.\nauthor_word_counts &lt;- corpus_words  |&gt; \n  count(author, word, sort = T) \n\nauthor_word_counts |&gt; \n  slice_head(n = 15) |&gt; \n  ggplot(aes(reorder(word, n), n, fill = word)) +\n  geom_col(show.legend = F) + \n  facet_wrap(~author, scales = \"free\") +\n  coord_flip() +\n  theme_light()\nОбратите внимание: абсолютная частотность – плохой показатель для текстов разной длины. Чтобы тексты было проще сравнивать, следует разделить показатели частотности на общее число токенов в тексте.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Лемматизация и тематическое моделирование</span>"
    ]
  },
  {
    "objectID": "POS.html#данные",
    "href": "POS.html#данные",
    "title": "6  Лемматизация и тематическое моделирование",
    "section": "",
    "text": "“Опыт о человеческом разумении” Джона Локка (1690), первые две книги;\n“Трактат о принципах человеческого знания” Джорджа Беркли (1710);\n“Исследование о человеческом разумении” Дэвида Юма (1748).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Лемматизация и тематическое моделирование</span>"
    ]
  },
  {
    "objectID": "POS.html#наиболее-характерные-слова",
    "href": "POS.html#наиболее-характерные-слова",
    "title": "6  Лемматизация и тематическое моделирование",
    "section": "6.2 Наиболее характерные слова",
    "text": "6.2 Наиболее характерные слова\nНаиболее частотные слова наименее подвержены влиянию тематики, поэтому их используют для стилометрического анализа. Если отобрать наиболее частотные после удаления стоп-слов, то мы получим достаточно адекватное отражение тематики документов.\nЕсли же мы необходимо найти наиболее характерные для документов токены, то применяется другая мера, которая называется tf-idf (term frequency - inverse document frequency).\n\nЛогарифм единицы равен нулю, поэтому если слово встречается во всех документах, его tf-idf равно нулю. Чем выше tf-idf, тем более характерно некое слово для документа. При этом относительная частотность тоже учитывается! Например, Беркли один раз упоминает “сахарные бобы”, а Локк – “миндаль”, но из-за редкой частотности tf-idf для подобных слов будет низкой.\nФункция bind_tf_idf() принимает на входе тиббл с абсолютной частотностью для каждого слова.\n\nauthor_word_tfidf &lt;- author_word_counts |&gt; \n  bind_tf_idf(word, author, n)\n\nauthor_word_tfidf\n\n\n  \n\n\n\nВот так выглядят наиболее характерные слова для каждого автора\n\nauthor_word_tfidf |&gt; \n  group_by(author) |&gt;\n  arrange(-tf_idf) |&gt; \n  top_n(15) |&gt; \n  ungroup() |&gt; \n  ggplot(aes(reorder_within(word, tf_idf, author), tf_idf, fill = author)) +\n  geom_col(show.legend = F) +\n  labs(x = NULL, y = \"tf-idf\") +\n  facet_wrap(~author, scales = \"free\") +\n  scale_x_reordered() +\n  coord_flip()\n\n\n\n\n\n\n\n\nНа такой диаграмме авторы совсем не похожи друг на друга, но будьте осторожны: все то, что их сближает (а это не только служебные части речи!), сюда просто не попало. Можно также заметить, что ряд характерных слов связаны не столько с тематикой, сколько со стилем: чтобы этого избежать, можно использовать лемматизацию или задать правило для замены вручную.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Лемматизация и тематическое моделирование</span>"
    ]
  },
  {
    "objectID": "POS.html#лемматизация-и-pos-тэггинг",
    "href": "POS.html#лемматизация-и-pos-тэггинг",
    "title": "6  Лемматизация и тематическое моделирование",
    "section": "6.3 Лемматизация и POS-тэггинг",
    "text": "6.3 Лемматизация и POS-тэггинг\nЛемматизация – приведение слов к начальной форме (лемме). Как правило, она проводится одновременно с частеречной разметкой (POS-tagging). Все это умеет делать UDPipe – обучаемый конвейер (trainable pipeline), для которого существует одноименный пакет в R.\nОсновным форматом файла для него является CoNLL-U. Файлы в таком формате хранятся в так называемых трибанках, то есть коллекциях уже размеченных текстов (название объясняется тем, что синтаксическая структура предложений представлена в них в виде древовидных графов). Файлы CoNLL-U используются для обучения нейросетей, но для большинства языков доступны хорошие предобученные модели, работать с которыми достаточно просто.\nПакет udpipe позволяет работать со множеством языков (всего 65), для многих из которых представлено несколько моделей, обученных на разных трибанках. Прежде всего нужно выбрать и загрузить модель (список). Описания моделей доступны на сайте https://universaldependencies.org/.\n\n# скачиваем модель в рабочую директорию\n#udpipe_download_model(language = \"english-gum\")\n\n# загружаем модель\nenglish_gum &lt;- udpipe_load_model(file = \"english-gum-ud-2.5-191206.udpipe\")\n\n# аннотируем (это займет несколько минут)\nemp_ann &lt;- udpipe_annotate(english_gum, emp_corpus$text, doc_id = emp_corpus$author)\n\nРезультат возвращается в формате CoNLL-U; это широко применяемый формат представления результат морфологического и синтаксического анализа текстов.\nВот пример разбора предложения:\n\nCтроки слов содержат следующие поля:\n\nID: индекс слова, целое число, начиная с 1 для каждого нового предложения; может быть диапазоном токенов с несколькими словами.\nFORM: словоформа или знак препинания.\nLEMMA: Лемма или основа словоформы.\nUPOSTAG: тег части речи из универсального набора проекта UD, который создавался для того, чтобы аннотации разных языков были сравнимы между собой.\nXPOSTAG: тег части речи, который выбрали исследователи под конкретные нужды языка\nFEATS: список морфологических характеристик.\nHEAD: идентификатор (номер) синтаксической вершины текущего токена. Если такой вершины нет, то ставят ноль (0).\nDEPREL: характер синтаксической зависимости.\nDEPS: Список вторичных зависимостей.\nMISC: любая другая аннотация.\n\nДля работы данные удобнее трансформировать в прямоугольный формат.\n\nemp_pos &lt;- as_tibble(emp_ann) |&gt; \n  select(-paragraph_id)\n\nemp_pos \n\n\n\n\n  \n\n\n\n\n6.3.1 Поля UPOS и XPOS\nМорфологическая аннотация, которую мы получили, дает возможность выбирать и группировать различные части речи. Например, существительные.\n\nemp_pos |&gt; \n  filter(upos == \"NOUN\") |&gt; \n  select(doc_id, token, lemma, upos, xpos)\n\n\n  \n\n\n\nПосчитать части речи можно так:\n\nupos_counts &lt;- emp_pos |&gt;\n  count(doc_id, upos, sort = TRUE) \n\nupos_counts\n\n\n  \n\n\n\nОтносительные значения:\n\ntotal_counts &lt;- upos_counts |&gt; \n count(doc_id, wt = n, name = \"sum_n\")\n\npos_share &lt;- upos_counts |&gt; \n  left_join(total_counts) |&gt; \n  mutate(share = round( (n/sum_n), 2))\n\npos_share |&gt; \n  ggplot(aes(reorder(upos, share), share, fill = upos)) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  theme_light() +\n  facet_wrap(~doc_id, scales = \"free\")\n\n\n\n\n\n\n\n\nОтберем наиболее частотные имена существительные и имена собственные.\n\nnouns &lt;- emp_pos  |&gt; \n  filter(upos %in% c(\"NOUN\", \"PROPN\")) |&gt; \n  count(doc_id, lemma, sort = TRUE) \n\nnouns\n\n\n  \n\n\n\n\nnouns |&gt; \n  group_by(doc_id) |&gt; \n  slice_head(n = 10) |&gt; \n  ggplot(aes(reorder_within(lemma, n, doc_id), n, fill = lemma)) +\n  geom_col(show.legend = FALSE) +\n  theme_light() +\n  coord_flip() +\n  scale_x_reordered() +\n  facet_wrap(~ doc_id, scales = \"free\") +\n  xlab(NULL)\n\n\n\n\n\n\n\n\nСравните с результатом, который вы получили, считая TF-IDF.\nВ отличие от UPOS (Universal Part-Of-Speech), XPOS (Language-specific Part-Of-Speech) – это теги частей речи, используемые в национальных корпусах. Форматы тегов и их детализация могут значительно меняться от языка к языку.\n\n\n6.3.2 Поля FEATS и DEP_REL\nДопустим, нам нужны лишь определенные формы: например, прилагательные в превосходной степени.\n\nsuperlatives &lt;- emp_pos  |&gt; \n  filter(str_detect(feats, \"Degree=Sup\") & upos == \"ADJ\") |&gt; \n  select(doc_id, token)\n\nsuperlatives_counts &lt;- superlatives |&gt; \n  count(doc_id, token, sort = TRUE) |&gt; \n  group_by(doc_id) |&gt; \n  slice_head(n = 15)\n\n\nsuperlatives_counts |&gt; \n  ggplot(aes(reorder_within(token, n, doc_id), n, fill = doc_id)) +\n  geom_col(show.legend = FALSE) +\n  coord_flip() +\n  theme_light() +\n  facet_wrap(~ doc_id, scales = \"free\") +\n  scale_x_reordered() +\n  xlab(NULL)\n\n\n\n\n\n\n\n\nАналогичным образом можно отбирать синтаксические признаки (DEP_REL) и их комбинации, а также визуализировать деревья зависимостей для отдельных предложений при помощи пакета {textplot}.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Лемматизация и тематическое моделирование</span>"
    ]
  },
  {
    "objectID": "POS.html#совместная-встречаемость-слов",
    "href": "POS.html#совместная-встречаемость-слов",
    "title": "6  Лемматизация и тематическое моделирование",
    "section": "6.4 Совместная встречаемость слов",
    "text": "6.4 Совместная встречаемость слов\nФункция cooccurence() из пакета udpipe позволяет выяснить, сколько раз некий термин встречается совместно с другим термином, например:\n\nслова встречаются в одном и том же документе/предложении/параграфе;\nслова следуют за другим словом;\nслова находятся по соседству с другим словом на расстоянии n слов.\n\nВыясним, какие существительные чаще встречаются в одном предложении у Локка:\n\nlocke_nouns &lt;-  emp_pos |&gt; \n  filter(doc_id == \"Locke\") |&gt; \n  filter(upos == \"NOUN\")\n\nlocke_nouns\n\n\n  \n\n\n\n\ncooc &lt;- cooccurrence(locke_nouns, term = \"lemma\", \n                     group = \"sentence_id\") |&gt;\n  as_tibble() |&gt; \n  filter(cooc &gt; 70) |&gt; \n  filter(term1 != \"idea\", term2 != \"idea\")\n\ncooc\n\n\n  \n\n\n\nЭтот результат легко визуализировать, используя пакет ggraph:\n\nlibrary(igraph)\nlibrary(ggraph)\n\nwordnetwork &lt;- graph_from_data_frame(cooc)\n\n\nggraph(wordnetwork, layout = \"fr\") +\n  geom_edge_arc(aes(width = cooc), alpha = 0.8, edge_colour = \"grey90\", show.legend=FALSE) +\n  geom_node_label(aes(label = name), col = \"#1f78b4\", size = 4) +\n  theme_void() +\n  labs(title = \"Совместная встречаемость существительных в предложении\")\n\nWarning in geom_node_label(aes(label = name), col = \"#1f78b4\", size = 4):\nIgnoring unknown parameters: `label.size`\n\n\nWarning: The `trans` argument of `continuous_scale()` is deprecated as of ggplot2 3.5.0.\nℹ Please use the `transform` argument instead.\n\n\n\n\n\n\n\n\n\nЧтобы узнать, какие слова чаще стоят рядом, используем ту же функцию, но с другими аргументами:\n\ncooc2 &lt;- cooccurrence(locke_nouns$lemma, \n                      relevant = locke_nouns$upos %in% \"NOUN\", \n                      skipgram = 1) |&gt; \n  as_tibble() |&gt; \n  filter(cooc &gt; 10)\n\ncooc2\n\n\n  \n\n\n\n\nwordnetwork &lt;- graph_from_data_frame(cooc2)\n\nggraph(wordnetwork, layout = \"fr\") +\n  geom_edge_link(aes(width = cooc), edge_colour = \"grey90\", edge_alpha=0.8, show.legend = F) +\n  geom_node_label(aes(label = name), col = \"#1f78b4\") +\n  labs(title = \"Слова, стоящие рядом в тексте\") +\n  theme_void()",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Лемматизация и тематическое моделирование</span>"
    ]
  },
  {
    "objectID": "llm.html",
    "href": "llm.html",
    "title": "7  Работа с LLM",
    "section": "",
    "text": "7.1 Что такое LLM?\nБольшие языковые модели — это алгоритмы искусственного интеллекта, обученные на огромных объемах текстовых данных. Они могут генерировать, анализировать и преобразовывать текст, что делает их ценным инструментом для цифровых гуманитарных наук.\nПрименение в филологии:\nНекоторые ограничения:\nВозможное решение:\nlibrary(ellmer)\nlibrary(ollamar)\nlibrary(xml2)\nlibrary(tidyverse)\nlibrary(diffobj)\nМы будем работать с пакетом {ellmer} https://ellmer.tidyverse.org/, разработанным для удобного взаимодействия с большими языковыми моделями (LLM) через различные API.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Работа с LLM</span>"
    ]
  },
  {
    "objectID": "llm.html#модели",
    "href": "llm.html#модели",
    "title": "7  Добавление разметки с LLM",
    "section": "",
    "text": "Большая часть моделей требует денег за API =(\nЕсть бесплатный пробный период у Gemini, но из России воспользоваться им не получится без VPN =/\nЕсть полностью бесплатные локальные модели. Они тяжелые и не всегда умные.\nКопипаста через телеграм-чат - не наш метод.\nРазные хитрости.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Добавление разметки с LLM</span>"
    ]
  },
  {
    "objectID": "llm.html#получение-ключа-api",
    "href": "llm.html#получение-ключа-api",
    "title": "7  Работа с LLM",
    "section": "7.2 Получение ключа API",
    "text": "7.2 Получение ключа API\nAPI (Application programming interface) это набор правил, по которым приложения или части программы общаются друг с другом.\nИдем на сайт https://openrouter.ai/, регистрируемся, получаем ключ (дайте ему осмысленное название), копируем и сразу сохраняем.\n\nSys.setenv(OPENROUTER_API_KEY = \"ваш_ключ_api\")\n\nИли отредактируйте файл .Renviron в домашней директории:\n\n# usethis::edit_r_environ()\n\nПосле чего добавьте строку в файл OPENROUTER_API_KEY=ваш_ключ_api и перезапустите сессию.\nПроверить:\n\nSys.getenv(\"OPENROUTER_API_KEY\")",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Работа с LLM</span>"
    ]
  },
  {
    "objectID": "llm.html#начало-работы",
    "href": "llm.html#начало-работы",
    "title": "7  Добавление разметки с LLM",
    "section": "7.3 Начало работы",
    "text": "7.3 Начало работы\n\nlibrary(ellmer)\npackageVersion(\"ellmer\")\n\n[1] '0.3.0'\n\n\n\nchat &lt;- chat_openrouter(\n  system_prompt = \"You always reply in Latin\",\n  api_key = Sys.getenv(\"OPENROUTER_API_KEY\"),\n  model = NULL\n)\n\n\nchat$chat(\"На сколько частей разделена Галлия?\")\n# Error in `req_perform_connection()`:\n# ! HTTP 402 Payment Required.\n# ℹ Insufficient credits. Add more using\n#   https://openrouter.ai/settings/credits\n# Run `rlang::last_trace()` to see where the error occurred.\n\nСписок бесплатных моделей можно уточнить здесь https://openrouter.ai/models\n\nchat &lt;- chat_openrouter(\n  system_prompt = \"You always reply in Latin\",\n  api_key = Sys.getenv(\"OPENROUTER_API_KEY\"),\n  model = \"openai/gpt-oss-20b:free\"\n)\n\nchat$chat(\"На сколько частей разделена Галлия?\")\n# Gallia in tres partes dividitur: Gallia Narbonensis, Gallia \n# Lugdunensis, et Gallia Belgica.\n\nЕсли все получилось, идем дальше.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Добавление разметки с LLM</span>"
    ]
  },
  {
    "objectID": "llm.html#создание-промпта",
    "href": "llm.html#создание-промпта",
    "title": "7  Добавление разметки с LLM",
    "section": "7.4 Создание промпта",
    "text": "7.4 Создание промпта\n(Тут будет подробнее про стратегии написания промптов)\n\nsystem_prompt &lt;- \"You are an experienced TEI encoder specializing in geographic markup. Your task is to identify and tag all place references in the text using proper TEI &lt;place&gt; elements.\n\nINSTRUCTIONS:\n1. Identify ALL geographic references including:\n   - Cities, towns, villages (e.g., Paris, London)\n   - Countries, regions, states (e.g., France, Tuscany, California)\n   - Geographic features (e.g., Rhine River, Alps, Mediterranean Sea)\n   - Buildings and landmarks (e.g., Eiffel Tower, Westminster Abbey)\n   - Fictional places (e.g., Hogwarts, Middle-earth)\n\n2. Use this tagging format:\n   - Simple places: &lt;place&gt;Paris&lt;/place&gt;\n   - With type attribute: &lt;place type='city'&gt;Paris&lt;/place&gt;\n   - With key/ID: &lt;place key='paris_france'&gt;Paris&lt;/place&gt;\n\n3. TYPES to use:\n   - settlement (cities, towns, villages)\n   - country \n   - region\n   - building\n   - landmark\n   - waterway\n   - mountain\n   - fictional\n\n4. RULES:\n   - Tag the complete place name as it appears\n   - Don't tag directional references like 'north', 'eastern' unless part of proper name\n   - Include adjectives when part of the place name (e.g., 'New York', 'Great Britain')\n   - For ambiguous cases, prioritize the most specific geographic reading\n\n5. Return the complete text with all place references properly tagged.\"",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Добавление разметки с LLM</span>"
    ]
  },
  {
    "objectID": "llm.html#добавление-разметки",
    "href": "llm.html#добавление-разметки",
    "title": "7  Добавление разметки с LLM",
    "section": "7.5 Добавление разметки",
    "text": "7.5 Добавление разметки\n\nuser_prompt &lt;- \"Может быть, никто из живущих в Москве не знает так хорошо окрестностей города сего, как я, потому что никто чаще моего не бывает в поле, никто более моего не бродит пешком, без плана, без цели — куда глаза глядят — по лугам и рощам, по холмам и равнинам. Всякое лето нахожу новые приятные места или в старых новые красоты.\n\nНо всего приятнее для меня то место, на котором возвышаются мрачные, готические башни Си...нова монастыря. Стоя на сей горе, видишь на правой стороне почти всю Москву, сию ужасную громаду домов и церквей, которая представляется глазам в образе величественного амфитеатра: великолепная картина, особливо когда светит на нее солнце, когда вечерние лучи его пылают на бесчисленных златых куполах, на бесчисленных крестах, к небу возносящихся! Внизу расстилаются тучные, густо-зеленые цветущие луга, а за ними, по желтым пескам, течет светлая река, волнуемая легкими веслами рыбачьих лодок или шумящая под рулем грузных стругов, которые плывут от плодоноснейших стран Российской империи и наделяют алчную Москву хлебом. На другой стороне реки видна дубовая роща, подле которой пасутся многочисленные стада; там молодые пастухи, сидя под тению дерев, поют простые, унылые песни и сокращают тем летние дни, столь для них единообразные. Подалее, в густой зелени древних вязов, блистает златоглавый Данилов монастырь; еще далее, почти на краю горизонта, синеются Воробьевы горы. На левой же стороне видны обширные, хлебом покрытые поля, лесочки, три или четыре деревеньки и вдали село Коломенское с высоким дворцом своим.\"\n\nchat &lt;- chat_openrouter(\n  system_prompt = system_prompt,\n  api_key = Sys.getenv(\"OPENROUTER_API_KEY\"),\n  model = \"openai/gpt-oss-20b:free\"\n)\n\nresponse &lt;- chat$chat(user_prompt)\n# Может быть, никто из живущих в &lt;place \n# type='settlement'&gt;Москву&lt;/place&gt; не знает так хорошо окрестностей \n# города сего, как я, потому что никто чаще моего не бывает в поле, \n# никто более моего не бродит пешком, без плана, без цели — куда \n# глаза глядят — по лугам и рощам, по холмам и равнинам. Всякое лето \n# нахожу новые приятные места или в старых новые красоты.\n# \n# Но всего приятнее для меня то место, на котором возвышаются \n# мрачные, готические башни &lt;place type='building'&gt;Си…нова \n# монастыря&lt;/place&gt;. Стоя на сей горе, видишь на правой стороне почти\n# всю &lt;place type='settlement'&gt;Москва&lt;/place&gt;, сию ужасную громаду \n# домов и церквей, которая представляется глазам в образе \n# величественного амфитеатра: великолепная картина, особливо когда \n# светит на нее солнце, когда вечерние лучи его пылают на \n# бесчисленных златых куполах, на бесчисленных крестах, к небу \n# возносящихся! Внизу расстилаются тучные, густо-зеленые цветущие \n# луга, а за ними, по желтым пескам, течет светлая река, волнуемая \n# легкими веслами рыбачьих лодок или шумящая под рулем грузных \n# стругов, которые плывут от плодоноснейших стран &lt;place \n# type='region'&gt;Российской империи&lt;/place&gt; и наделяют алчную &lt;place \n# type='settlement'&gt;Москву&lt;/place&gt; хлебом. На другой стороне реки \n# видна дубовая роща, подле которой пасутся многочисленные стада; там\n# молодые пастухи, сидя под тенью дерев, поют простые, унылые песни и\n# сокращают тем летние дни, столь для них единообразные. Подалее, в \n# густой зелени древних вязов, блистает златоглавый &lt;place \n# type='building'&gt;Данилов монастырь&lt;/place&gt;; еще далее, почти на краю\n# горизонта, синеются &lt;place type='mountain'&gt;Воробьевы горы&lt;/place&gt;. \n# На левой же стороне видны обширные, хлебом покрытые поля, лесочки, \n# три или четыре деревеньки и вдали село &lt;place \n# type='settlement'&gt;Коломенское&lt;/place&gt; с высоким дворцом своим.\n\nНа первый взгляд, модель справилась неплохо. “Российскую империю” стоило тегировать как “страну”, а не “регион” (подобные случаи можно прописать в промпте).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Добавление разметки с LLM</span>"
    ]
  },
  {
    "objectID": "llm.html#добавление-пролога",
    "href": "llm.html#добавление-пролога",
    "title": "7  Добавление разметки с LLM",
    "section": "7.6 Добавление пролога",
    "text": "7.6 Добавление пролога\n\nadd_tei_prologue &lt;- function(marked_text, \n                            title = \"Карамзин Н.М. Бедная Лиза\", \n                            author = \"Карамзин, Николай Михайлович\",\n                            date = \"1792\") {\n  \n  prologue &lt;- sprintf('&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\"&gt;\n  &lt;teiHeader&gt;\n    &lt;fileDesc&gt;\n      &lt;titleStmt&gt;\n        &lt;title&gt;%s&lt;/title&gt;\n        &lt;author&gt;%s&lt;/author&gt;\n      &lt;/titleStmt&gt;\n      &lt;publicationStmt&gt;\n        &lt;p&gt;Цифровое издание для исследовательских целей&lt;/p&gt;\n      &lt;/publicationStmt&gt;\n      &lt;sourceDesc&gt;\n        &lt;p&gt;Оригинальный текст %s года&lt;/p&gt;\n      &lt;/sourceDesc&gt;\n    &lt;/fileDesc&gt;\n  &lt;/teiHeader&gt;\n  &lt;text&gt;\n    &lt;body&gt;\n      &lt;p&gt;%s&lt;/p&gt;\n    &lt;/body&gt;\n  &lt;/text&gt;\n&lt;/TEI&gt;', title, author, date, marked_text)\n  \n  return(prologue)\n}\n\nПрименяем к нашему тексту.\n\ntei_document &lt;- add_tei_prologue(response)\n\nСохраняем в файл.\n\nwriteLines(tei_document, \"bednaya_liza_fragment.xml\", useBytes = TRUE)\n\nПроверяем валидность XML.\n\nlibrary(xml2)\nxml_doc &lt;- read_xml(\"bednaya_liza_fragment.xml\")\nclass(xml_doc)\n\nПрежде чем масштабировать, проверим, нет ли галлюцинаций в оригинале (такое, увы, бывает).",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Добавление разметки с LLM</span>"
    ]
  },
  {
    "objectID": "llm.html#сравнение-с-исходником",
    "href": "llm.html#сравнение-с-исходником",
    "title": "7  Добавление разметки с LLM",
    "section": "7.7 Сравнение с исходником",
    "text": "7.7 Сравнение с исходником\nИзвлекаем текст из параграфа.\n\nns &lt;- c(tei = \"http://www.tei-c.org/ns/1.0\")\n\ntext_content &lt;- xml_doc |&gt; \n    xml_find_all(\".//tei:body//tei:p\", ns) |&gt; \n    xml_text() |&gt;\n    paste(collapse = \"nn\")\n\nВыводим результат.\n\ncat(text_content)\n\nТеперь можно сравнивать.\n\nlibrary(diffobj)\n\ndiffChr(trimws(text), trimws(text_content), mode = \"sidebyside\")\n\n\nУпс. Машинка действительно кое-что поправила, и не в лучшую сторону.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Добавление разметки с LLM</span>"
    ]
  },
  {
    "objectID": "llm.html#метрики",
    "href": "llm.html#метрики",
    "title": "7  Добавление разметки с LLM",
    "section": "7.8 Метрики",
    "text": "7.8 Метрики\nhttps://digitalcommons.unl.edu/r-journal/415/\nИмеет смысл сравнить несколько моделей и выбрать лучшую.\n\nlibrary(stringdist)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n# Sample data\noriginal_text &lt;- \"The quick brown fox jumps over the lazy dog\"\nmodel_outputs &lt;- list(\n  model_A = \"The quikc brown fox jumps over the lazy dog\", # one typo\n  model_B = \"A brow fox jumped over  lazy dog\",  # the worst\n  model_C = \"The quick brown fox jumps over the lazy dog\" # exact match\n)\n\nСчитаем расстояние.\nLevenshtein distance - подсчитывает минимальное количество вставок, удалений и замен - Классическая метрика, широко используется\nOptimal String Alignment (OSA) - добавляет транспозиции смежных символов - Не удовлетворяет неравенству треугольника - Используется по умолчанию в stringdist\nDamerau-Levenshtein - полная версия с множественными транспозициями - Является настоящей метрикой (удовлетворяет всем свойствам)\n\ncompare_texts &lt;- function(original, outputs) {\n  results &lt;- data.frame(\n    model = names(outputs),\n    Levenshtein = sapply(outputs, function(x) stringdist(original, x, method = \"lv\")),\n    DamerauLevenshtein = sapply(outputs, function(x) stringdist(original, x, method = \"dl\")),\n    OptimalStringAlignment = sapply(outputs, function(x) stringdist(original, x, method = \"osa\"))\n    )\n  return(results)\n}\n\n# Compare all models\ncomparison_results &lt;- compare_texts(original_text, model_outputs)\nprint(comparison_results)\n\n          model Levenshtein DamerauLevenshtein OptimalStringAlignment\nmodel_A model_A           2                  1                      1\nmodel_B model_B          15                 15                     15\nmodel_C model_C           0                  0                      0\n\n\nВажно! Для корректно оценки необходимо вручную оценить теги.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Добавление разметки с LLM</span>"
    ]
  },
  {
    "objectID": "llm.html#как-улучшить-результат",
    "href": "llm.html#как-улучшить-результат",
    "title": "7  Добавление разметки с LLM",
    "section": "7.9 Как улучшить результат",
    "text": "7.9 Как улучшить результат\n\n7.9.1 Доработка промпта\nДобавьте четкие инструкции о сохранении исходного текста:\n\nsystem_prompt &lt;- \"You are an experienced TEI encoder specializing in geographic markup. \n\nCRITICAL: You must preserve the original text EXACTLY as provided. Do not correct spelling, grammar, or punctuation. Do not modernize language or fix any perceived errors.\n\nYour task is to identify and tag all place references using proper TEI &lt;place&gt; elements WITHOUT changing the original text in any way.\n\n[остальные инструкции...]\n\nIMPORTANT: Return the text with ONLY the place tags added. Everything else must remain identical to the input.\"\n\n\n\n7.9.2 Альтернативные модели\nПопробуйте разные модели - некоторые лучше следуют инструкциям:\n\nmodels_to_test &lt;- c(\n  \"anthropic/claude-3-haiku:beta\",\n  \"meta-llama/llama-3.1-8b-instruct:free\",\n  \"microsoft/wizardlm-2-8x22b\",\n  \"openai/gpt-oss-20b:free\"\n)\n\nТестируем на небольшом фрагменте.\n\nbest_model &lt;- test_models(models_to_test, sample_text)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Добавление разметки с LLM</span>"
    ]
  },
  {
    "objectID": "share.html",
    "href": "share.html",
    "title": "8  Публикационная система Quarto",
    "section": "",
    "text": "8.1 О воспроизводимости\nПолученный в результате количественных исследований результат должен быть проверяем и воспроизводим. Это значит, что в большинстве случаев недостаточно просто рассказать, что вы проделали. Теоретически читатель должен иметь возможность проделать тот же путь, что и автор: воcпроизвести его результаты, но в обратном направлении.\nДля этого должны выполняться три основных требования:\nУже на этапе планирования исследования очень важно продумать, как вы будете его документировать. Важно помнить, что код пишется не только для машин, но и для людей, поэтому стоит документировать не только то, что вы делали, но и почему. R дает для этого множество возможностей, главная из которых – это Markdown.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Публикационная система Quarto</span>"
    ]
  },
  {
    "objectID": "share.html#о-воспроизводимости",
    "href": "share.html#о-воспроизводимости",
    "title": "8  Публикационная система Quarto",
    "section": "",
    "text": "На заметку\n\n\n\nВоспроизводимость (reproducibility) – это не то же, что повторяемость (replicability). Ученый, который повторяет исследование, проводит его заново на новых данных. Воспроизведение – гораздо более скромная задача, не требующая таких ресурсов, как повторение (Winter 2020, 47).\n\n\n\n\nдоступность данных и метаданных;\nдоступность компьютерного кода;\nдоступность программного обеспечения.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Публикационная система Quarto</span>"
    ]
  },
  {
    "objectID": "share.html#markdown",
    "href": "share.html#markdown",
    "title": "8  Публикационная система Quarto",
    "section": "8.2 Markdown",
    "text": "8.2 Markdown\nMarkdown – это облегчённый язык разметки. Он позволяет создавать документы разного формата – не только HTML (веб-страницы), но и PDF и Word. Markdown дает возможность создания полностью воспроизводимых документов, сочетающих код и поясняющий текст. Этот язык используется для создания сайтов, статей, книг, презентаций, отчетов, дашбордов и т.п. Этот курс написан с использованием Markdown.\nЧтобы начать работать с документами .rmd, нужен пакет rmarkdown; в RStudio он уже предустановлен. Создание нового документа .rmd происходит из меню.\nПо умолчанию документ .rmd снабжен шапкой yaml. Она не обязательна. Здесь содержатся данные об авторе, времени создания, формате, сведения о файле с библиографией и т.п.\n---\ntitle: \"Demo\"\nauthor: \"My name\"\ndate: \"2025-11-10\"\noutput: html_document\n---\nТакже в документе .rmd скорее всего будет простой текст и блоки кода. Чтобы “сшить” html (pdf, doc), достаточно нажать кнопку knit либо запустить в консоли код: rmarkdown::render(\"Demo.Rmd\"). После этого в рабочей директории появится новый файл (html, pdf, или doc), которым можно поделиться с коллегами, грантодателями или друзьями.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Публикационная система Quarto</span>"
    ]
  },
  {
    "objectID": "share.html#quarto",
    "href": "share.html#quarto",
    "title": "8  Публикационная система Quarto",
    "section": "8.3 Quarto",
    "text": "8.3 Quarto\nРаботать с маркдауном мы будем, используя издательскую систему Quarto с открытым исходным кодом. Она позволяет создавать и публиковать статьи, презентации, информационные панели, веб-сайты, блоги и книги в HTML, PDF, MS Word, ePub и других форматах. В общем, обычный Markdown тоже позволяет все это делать, но чуть сложнее. Quarto объединяет различные пакеты из экосистемы R Markdown воедино и значительно упрощает работу с ними. Подробнее см. практическое руководство “Quarto: The Definitive Guide”.\n\n\n\n\n\n\nЗадание\n\n\n\nСоздайте новый .qmd документ. Потренируйтесь запускать код и сшивать документ в .html, .pdf, .docx.\n\n\nДля .pdf может понадобиться установка LaTeX.\n\n# install.packages(\"tinytex\")\ntinytex::install_tinytex()\n# to uninstall TinyTeX, run\n# tinytex::uninstall_tinytex()\n\nМожно указать сразу несколько форматов для файла, как показано здесь, и “сшить” их одновременно:\n\nquarto::quarto_render(\n  \"untitled.qmd\", \n  output_format = c(\"pdf\", \"html\", \"docx\")\n)",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Публикационная система Quarto</span>"
    ]
  },
  {
    "objectID": "share.html#шапка-yaml",
    "href": "share.html#шапка-yaml",
    "title": "8  Публикационная система Quarto",
    "section": "8.4 Шапка YAML",
    "text": "8.4 Шапка YAML\nОсновные параметры документа хранятся в YAML-шапке. К ним относятся format, title, subtitle, date, date-format, author, abstract, lang, toc, number-sections и другие.\nПопробуйте изменить шапку своего .qmd-документа и заново его сшить. Сравните с предыдущей версией.\n---\ntitle: \"Заголовок\"\nsubtitle: \"Подзаголовок\"\nformat: html\nauthor: locusclassicus\ndate: today\ndate-format: D.MM.YYYY\nabstract: Значенье бублика нам непонятно.\nlang: ru\ntoc: true\nnumber-sections: true\n---\n\nПоле execute позволяет задать параметры всех фрагментов кода в документе, например:\n---\nexecute:\n  echo: false\n  fig-width: 9\n---\n  \nНо для отдельных кусков кода эти настройки можно поменять:\n```\n#| echo: true\n\nsqrt(16)\n```\nПараметр df-print позволяет выбрать один из возможных способов отображения датафреймов:\n\ndefault — стандартный, как в консоли;\ntibble — стандартный, как в консоли, но в формате tibble;\nkable — минималистичный вариант, подходит для всех видов документов;\npaged — интерактивная таблица, подходит для html страниц.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Публикационная система Quarto</span>"
    ]
  },
  {
    "objectID": "share.html#синтаксис-markdown",
    "href": "share.html#синтаксис-markdown",
    "title": "8  Публикационная система Quarto",
    "section": "8.5 Синтаксис Markdown",
    "text": "8.5 Синтаксис Markdown\n\n8.5.1 Заголовки\nЗаголовки разного уровня задаются при помощи решетки:\n# Заголовок первого уровня\n## Заголовок второго уровня\n### Заголовок третьего уровня\n#### Заголовок четвёртого уровня\nПример заголовка третьего уровня:\n\n\n8.5.2 Форматирование\n*курсив*  \n_курсив_\n\n**полужирный**  \n__полужирный__\n\n***полужирный курсив***  \n___полужирный курсив___\n\n~~зачеркнутый~~\n\n&lt;mark&gt;выделение&lt;/mark&gt;\nПример:\nкурсив\nполужирный\nуж и не знаю как выделить\nзачеркнутый\nвыделение\n\n\n8.5.3 Списки\nНумерованный список\n1. Пункт первый\n2. Пункт второй\n3. Пункт третий\nПример:\n\nПункт первый\nПункт второй\nПункт третий\n\nМаркированный список\n- Пункт первый\n- Пункт второй\n- Пункт третий\nПример:\n\nПункт первый\nПункт второй\nПункт третий\n\nТакже Markdown позволяет делать вложенные списки:\n1. Пункт первый\n    - Подпункт первый\n    - Подпункт второй\n2. Пункт второй\nПример:\n\nПункт первый\n\nПодпункт первый\nПодпункт второй\n\nПункт второй\n\nСамое удобное, что элементы списка не обязательно нумеровать:\n(@) Пункт первый.\n(@) Пункт не знаю какой.\n\nПункт первый.\nПункт не знаю какой.\n\n\n\n8.5.4 Ссылки\n[Текст ссылки](http://antibarbari.ru/)\nПример:\nТекст ссылки\n\n\n8.5.5 Изображения\n![Текст описания](https://upload.wikimedia.org/wikipedia/commons/thumb/3/30/Holbein-erasmus.jpg/548px-Holbein-erasmus.jpg)\nПример:\n\n\n\nМоя картинка\n\n\nДва нюанса:\n\nможно давать ссылки на локальные файлы (то есть такие файлы, которые хранятся на компьютере), но имейте в виду, что такой код не будет работать у другого пользователя;\nизображения можно вставлять, пользуясь непосредственно разметкой html.\n\n&lt;img src=\"images/my_image.jpg\" width=40%&gt;\n\n\n8.5.6 Блоки кода\nМожно вставлять непосредственно в текст; для этого код выделяют одинарным обратным апострофом (грависом). Но чаще код дают отдельным блоком. Эти блоки можно именовать; тогда в случае ошибки будет сразу понятно, где она случилась.\n```{}\nsome code here\n```\nВ фигурных скобках надо указать язык, например {r}, только в этом случае код будет подсвечиваться и выполняться.\nТам же в фигурных скобках можно задать следующие параметры:\n\neval = FALSE код будет показан, но не будет выполняться;\ninclude = FALSE код будет выполнен, но ни код, ни результат не будут показаны;\necho = FALSE код будет выполнен, но не показан, результаты при этом видны;\nmessage = FALSE или warning = FALSE прячет сообщения или предупреждения;\nresults = 'hide' не распечатывает результат, а fig.show = 'hide' прячет графики;\nerror = TRUE “сшивание” продолжается, даже если этот блок вернул ошибку.\n\n\n\n8.5.7 Цитаты\n&gt; Omnia praeclara rara.\nПример:\n\nOmnia praeclara rara.\n\nЦитата с подписью может быть оформлена так:\n&gt; Omnia praeclara rara.\n&gt;\n&gt; --- Cicero\nПример:\n\nOmnia praeclara rara.\n— Cicero\n\n\n\n8.5.8 Разделители\nЧтобы создать горизонтальную линию, можно использовать ---, *** или ___.\nПример:\n\n\n\n8.5.9 Таблицы\nТаблицы можно задать вручную при помощи дефисов - и вертикальных линий |; идеальная точность при этом не нужна. Перед таблицей обязательно оставляйте пустую строку, иначе волшебство не сработает.\n\n| Фрукты   | Калории  |\n| -----  | ---- |\n| Яблоко   | 52  |\n| Апельсин | 47  |\nПример:\n\n\n\nФрукты\nКалории\n\n\n\n\nЯблоко\n52\n\n\nАпельсин\n47\n\n\n\nПо умолчанию Markdown распечатывает таблицы так, как они бы выглядели в консоли.\n\ndata(\"iris\")\nhead(iris)\n\n\n  \n\n\n\nДля дополнительного форматирования можно использовать функцию knitr::kable():\n\nknitr::kable(iris[1:6, ], caption = \"Таблица knitr\")\n\n\nТаблица knitr\n\n\nSepal.Length\nSepal.Width\nPetal.Length\nPetal.Width\nSpecies\n\n\n\n\n5.1\n3.5\n1.4\n0.2\nsetosa\n\n\n4.9\n3.0\n1.4\n0.2\nsetosa\n\n\n4.7\n3.2\n1.3\n0.2\nsetosa\n\n\n4.6\n3.1\n1.5\n0.2\nsetosa\n\n\n5.0\n3.6\n1.4\n0.2\nsetosa\n\n\n5.4\n3.9\n1.7\n0.4\nsetosa\n\n\n\n\n\nИнтерактивную таблицу можно создать так:\n\nDT::datatable(iris[1:6,])\n\n\n\n\n\n\n\n8.5.10 Чек-листы\n- [x] Таблицы\n- [ ] Графики\nПример:\n\nТаблицы\nГрафики\n\n\n\n8.5.11 Внутренние ссылки\nУдобны для навигации по документу. К названию любого раздела можно добавить {#id}.\n[Вернуться к чек-листам](#id)\nПример:\nВернуться к чек-листам\n\n\n8.5.12 Графики\nMarkdown позволяет встраивать любые графики.\n\nlibrary(ggplot2)\nggplot(aes(x = Sepal.Length, y = Petal.Length, col = Species), data = iris) +\n  geom_point(show.legend = F)\n\n\n\n\n\n\n\n\nДля интерактивных графиков понадобится пакет plotly:\n\nlibrary(plotly)\nplot_ly(data=iris, x = ~Sepal.Length, y = ~Petal.Length, color = ~Species)\n\n\n\n\n\nПодробное руководство по созданию интерактивных графиков можно найти на сайте https://plotly.com/r/.\n\n\n8.5.13 Математические формулы\nПишутся с использованием синтаксиса LaTeX, о котором можно прочитать подробнее здесь.\nФормулы заключаются в одинарный $, если пишутся в строку, и в двойной $$, если отдельным блоком.\n\\cos (2\\theta) = \\cos^2 \\theta - \\sin^2 \\theta\nВот так это выглядит в тексте: \\(\\cos (2\\theta) = \\cos^2 \\theta - \\sin^2 \\theta\\).\nА вот так – блоком:\n\\[\\cos (2\\theta) = \\cos^2 \\theta - \\sin^2 \\theta\\]\n\n\n8.5.14 Смайлы\nУдобнее вставлять через визуальный редактор (“шестеренка” &gt; Use Visual Editor), но можно и без него:\n\n# devtools::install_github(\"hadley/emo\")\nlibrary(emo)\nemo::ji(\"apple\")\n\n🍎 \n\n\nКод можно записать в строку, тогда смайл появится в тексте: 💀.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Публикационная система Quarto</span>"
    ]
  },
  {
    "objectID": "share.html#библиография",
    "href": "share.html#библиография",
    "title": "8  Публикационная система Quarto",
    "section": "8.6 Библиография",
    "text": "8.6 Библиография\nMarkdown позволяет добавлять библиографию в формате BibTeX. BibTeX — программное обеспечение для создания форматированных списков библиографии; обычно используется совместно с LaTeX’ом. Многие сайты, например GoogleScholar, позволяют экспортировать библиографические записи в формате BibTeX. При необходимости запись можно исправить вручную.\nКаждая запись имеет следующую форму.\n@book{winter2020,\n  author = {Bodo Winter},\n  title = \"{Statistics for Linguists: An Introduction Using R}\",\n  year = {2020},\n  publisher = {Routledge}\n}\nЗдесь book — тип записи («книга»), winter2020 — метка-идентификатор записи, дальше список полей со значениями.\nОдна запись описывает ровно одну публикацию статью, книгу, диссертацию, и т. д. Подробнее о типах записей можно посмотреть вот здесь.\nПодобные записи хранятся в текстовом файле с расширением .bib. Чтобы привязать библиографию, нужно указать имя файла в шапке yaml.\n---\nbibliography: bibliography.bib\n---\nДальше, чтобы добавить ссылку, достаточно ввести ключ публикации после @ (в квадратных скобках, чтобы публикация отражалась в круглых): [@wickham2016].\nПример:\n(Wickham и Grolemund 2016).\nМожно интегрировать BibTex с Zotero или другим менеджером библиографии. Для этого придется установить специальное расширение.\nЧтобы изменить стиль цитирования, необходимо добавить в шапку yaml название csl-файла (CSL - Citation Style Language), например:\n---\noutput: html_document\nbibliography: references.bib\ncsl: archiv-fur-geschichte-der-philosophie.csl\n---\nНайти необходимый csl-файл можно, например, в репозитории стилей Zotero.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Публикационная система Quarto</span>"
    ]
  },
  {
    "objectID": "share.html#публикация-html",
    "href": "share.html#публикация-html",
    "title": "8  Публикационная система Quarto",
    "section": "8.7 Публикация html",
    "text": "8.7 Публикация html\nДля публикации на RPubs понадобится установить пакеты packrat, rsconnect.\nПри публикации страницы на https://rpubs.com/ следует добавить в шапку две строчки:\n\n---\nembed-resources: true\nstandalone: true\n---\n\nЭто позволит корректно отобразить локальные фото, графики и сохранит оформление.\n\n\n\n\nWickham, Hadley, и Garrett Grolemund. 2016. R for Data Science. O’Reilly. https://r4ds.had.co.nz/index.html.\n\n\nWinter, Bodo. 2020. Statistics for Linguists: An Introduction Using R. Routledge.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Публикационная система Quarto</span>"
    ]
  },
  {
    "objectID": "POS.html#тематическое-моделирование",
    "href": "POS.html#тематическое-моделирование",
    "title": "6  Лемматизация и тематическое моделирование",
    "section": "6.5 Тематическое моделирование",
    "text": "6.5 Тематическое моделирование\nВы можете легко преобразовать аннотированный тибл в матрицу “документ-термин” (document-term-matrix), которая используется во многих других пакетах для анализа текста. В данном случае мы будем выделять темы (topics) на уровне предложений.\nПреимущество {udpipe} по сравнению с другими пакетами заключается в следующем:\n\nтематическое моделирование (topic modelling) можно проводить непосредственно по нужным словам, так как их легко определить с помощью тегов частей речи: чаще всего интересуют только существительные и глаголы или, например, только прилагательные, если вы хотите кластеризовать текст по тональности (sentiment clustering);\nбольше не нужно создавать длинные списки стоп-слов;\nкроме того, можно работать с леммами, а не с исходными формами слов, что позволяет схожим словам лучше группироваться друг с другом;\nвы легко можете включать составные ключевые слова.\n\nОтбираем только существительные.\n\nemp_pos$topic_level_id &lt;- unique_identifier(emp_pos, fields = c(\"doc_id\", \"sentence_id\"))\n\ndtf &lt;- emp_pos |&gt; \n  filter(upos == \"NOUN\")\n\n\ndtf &lt;- document_term_frequencies(dtf, document = \"topic_level_id\", term = \"lemma\")\nhead(dtf)\n\n\n  \n\n\n\n\ndtm &lt;- document_term_matrix(x = dtf)\n\n\ndtm_clean &lt;- dtm_remove_lowfreq(dtm, minfreq = 5)\nsample(dtm_colsums(dtm_clean), 10)\n\n    Quality acceptation        snow   ourselves        size    building \n          8           7          11          27          26           5 \n hypothesis      mother    sickness    ignorant \n         22           8          11           8 \n\n\n\nlibrary(topicmodels)\nm &lt;- LDA(dtm_clean, k = 4, method = \"Gibbs\", \n         control = list(nstart = 5, burnin = 2000, best = TRUE, seed = 1:5))\n\nЧтобы интерпретировать тематическую модель и подобрать подходящие названия темам, вы можете получить наиболее часто встречающиеся термины для каждой темы, указав минимальную вероятность появления термина и минимальное количество отображаемых терминов.\n\ntopicterminology &lt;- predict(m, type = \"terms\", \n                            min_posterior = 0.005, \n                            min_terms = 3)\ntopicterminology\n\n$topic_001\n            term        prob\n1           body 0.063299870\n2           part 0.055656535\n3         motion 0.042793360\n4        thought 0.032819738\n5           time 0.026481362\n6      existence 0.022380060\n7         number 0.021727580\n8          space 0.020981889\n9         matter 0.020049775\n10         place 0.019490506\n11      duration 0.019210872\n12       nothing 0.019024449\n13     extension 0.017719490\n14         world 0.013338553\n15      anything 0.012965708\n16      distance 0.012313228\n17        figure 0.011940382\n18        person 0.011940382\n19     something 0.010635422\n20           end 0.010355788\n21 consciousness 0.009144040\n22         light 0.009050828\n23    appearance 0.008864405\n24          side 0.008025503\n25       measure 0.007745868\n26          rest 0.007745868\n27            be 0.007652657\n28          hand 0.007652657\n29          year 0.007466234\n30    difficulty 0.007186600\n31           sun 0.007186600\n32           eye 0.007000177\n33        length 0.007000177\n34    succession 0.006813754\n35         think 0.006720543\n36      infinity 0.006254486\n37        moment 0.005974852\n38      particle 0.005695217\n39        animal 0.005602006\n40      identity 0.005602006\n41   supposition 0.005602006\n42        change 0.005508794\n43          line 0.005508794\n44          mark 0.005508794\n45         sight 0.005135949\n46      solidity 0.005042737\n\n$topic_002\n         term        prob\n1        idea 0.245654014\n2        mind 0.109205398\n3       thing 0.069582283\n4        name 0.034144708\n5       sense 0.030796276\n6   substance 0.030145192\n7        word 0.027261820\n8     quality 0.018518691\n9    relation 0.017960619\n10  sensation 0.016100379\n11     spirit 0.013775078\n12 perception 0.013217006\n13     colour 0.013123994\n14       sort 0.011914838\n15     memory 0.010519658\n16   distinct 0.010426646\n17 reflection 0.010240622\n18       mode 0.007915322\n19        one 0.007915322\n20      sound 0.007729298\n21    essence 0.006520142\n22     notice 0.006520142\n23   occasion 0.006055082\n24   language 0.005869058\n\n$topic_003\n            term        prob\n1          power 0.050329463\n2         action 0.040791100\n3         object 0.037384542\n4         nature 0.035632598\n5         effect 0.025996905\n6          cause 0.025802244\n7  understanding 0.018891798\n8      operation 0.018599807\n9     experience 0.018113156\n10          pain 0.017918496\n11          life 0.015874561\n12          will 0.015095919\n13        manner 0.013149314\n14      pleasure 0.012857324\n15      instance 0.012759993\n16         event 0.012176012\n17        degree 0.011786691\n18       nothing 0.011494700\n19          kind 0.011397370\n20     happiness 0.010910719\n21   philosopher 0.010618728\n22          case 0.010229407\n23       subject 0.010132077\n24          view 0.010034747\n25           law 0.009742756\n26     connexion 0.009353435\n27          good 0.009256105\n28 consideration 0.008964114\n29       liberty 0.008964114\n30        desire 0.008769454\n31         force 0.008380133\n32  circumstance 0.008185472\n33    uneasiness 0.007990812\n34       passion 0.007017510\n35        regard 0.006530859\n36        course 0.006433528\n37     necessity 0.006433528\n38   observation 0.006433528\n39         state 0.006433528\n40       respect 0.006044207\n41     inference 0.005557556\n42      occasion 0.005460226\n43     attention 0.005265566\n\n$topic_004\n          term        prob\n1          man 0.112073717\n2       reason 0.037138741\n3    principle 0.032014155\n4    knowledge 0.025342525\n5        other 0.022635197\n6          use 0.022345126\n7        truth 0.022055055\n8          way 0.021184843\n9       notion 0.018960966\n10 proposition 0.014029761\n11    argument 0.013062858\n12     opinion 0.012482717\n13        soul 0.012386026\n14        rule 0.011419123\n15    question 0.009968769\n16  philosophy 0.009872079\n17       child 0.009775388\n18        fact 0.009775388\n19        term 0.009775388\n20     mankind 0.009582008\n21     faculty 0.009291937\n22   reasoning 0.008711795\n23  impression 0.008228344\n24     miracle 0.008131654\n25       order 0.007454821\n26    evidence 0.007068060\n27     variety 0.006971370\n28 consequence 0.006874680\n29         age 0.006777989\n30         viz 0.006681299\n31      answer 0.006584609\n32  conclusion 0.006391228\n33       doubt 0.006391228\n34       proof 0.006197848\n35       maxim 0.006004467\n36   testimony 0.006004467\n37     purpose 0.005907777\n38  difference 0.005811087\n39    doctrine 0.005811087\n40   character 0.005714396\n41  foundation 0.005521016\n42   sentiment 0.005230945\n43   authority 0.005134254\n44   discourse 0.005134254\n45    judgment 0.005134254\n46      people 0.005134254\n\n\nКроме того, мы также можем легко использовать модель для предсказания, к какой теме принадлежит новый документ. Функция predict корректно возвращает значение NA для тех документов, в которых отсутствуют слова, использованные в модели, что обычно вызывает затруднения в других пакетах R. Также функция позволяет присваивать каждой теме метки и показывает разницу в вероятности между наиболее вероятной темой и следующей по вероятности, что полезно для оценки чёткости (разграниченности) ваших тем.\n\nscores &lt;- predict(m, newdata = dtm_clean, type = \"topics\", \n                  labels = c(\"physics\", \"psychology\", \"ethics\", \"epistemology\"))\n\nАргумент labels присваивает пользовательские имена темам в итоговом результате предсказания.\nВизуализируем топики.\n\nemp_topics &lt;- merge(emp_pos, scores, by.x=\"topic_level_id\", by.y=\"doc_id\")\n\n\nwordnetwork &lt;- subset(emp_topics, topic %in% 1 & lemma %in% topicterminology[[1]]$term)\n\n\nwordnetwork &lt;- cooccurrence(wordnetwork, group = c(\"topic_level_id\"), term = \"lemma\")\nwordnetwork &lt;- graph_from_data_frame(wordnetwork)\n\n\nggraph(wordnetwork, layout = \"fr\") +\n  geom_edge_link(aes(width = cooc, edge_alpha = cooc), edge_colour = \"pink\")  +\n  geom_node_text(aes(label = name), col = \"darkgreen\", size = 4) +\n  theme_graph(base_family = \"Arial Narrow\") +\n  labs(title = \"Words in topic Physics \", subtitle = \"Nouns Cooccurrence\")",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Лемматизация и тематическое моделирование</span>"
    ]
  },
  {
    "objectID": "POS.html#видео",
    "href": "POS.html#видео",
    "title": "6  Лемматизация и тематическое моделирование",
    "section": "6.6 Видео",
    "text": "6.6 Видео\n\nВидео 2025 г.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Лемматизация и тематическое моделирование</span>"
    ]
  },
  {
    "objectID": "POS.html#домашнее-задание",
    "href": "POS.html#домашнее-задание",
    "title": "6  Лемматизация и тематическое моделирование",
    "section": "6.7 Домашнее задание",
    "text": "6.7 Домашнее задание\nПо ссылке вы найдете датасет со сказками Салтыкова-Щедрина (в формате .Rdata). Вам необходимо аннотировать сказки, используя модель SynTagRus.\nПосле этого ответьте на вопросы по ссылке. Задание считается выполненным, если верные ответы даны на 3 из 5 вопросов.\nОшибки лемматизации и морфологического анализа игнорируйте.\nДедлайн: 28 ноября, 21-00.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Лемматизация и тематическое моделирование</span>"
    ]
  },
  {
    "objectID": "llm.html#что-такое-llm",
    "href": "llm.html#что-такое-llm",
    "title": "7  Работа с LLM",
    "section": "",
    "text": "автоматическая разметка текстов (TEI);\nизвлечение структурированных данных;\nраспознавание изображений;\nавтоматическая классификация;\nи многое другое.\n\n\n\nбольшая часть моделей требует денег за доступ по API;\nк некоторым моделям не получится подключиться без VPN;\nполностью бесплатные локальные модели тяжелые и не всегда “умные”;\nкопипаста через телеграм-чат - не наш метод.\n\n\n\nOpenRouter https://openrouter.ai/ — это агрегатор LLM‑моделей (OpenAI, Anthropic, Meta, Mistral и др.) с единым API. Можно выбрать бесплатные модели (с лимитами) и вызывать их из R/RStudio. Обратите внимание: число запросов в день на бесплатном плане ограничено 10 кредитами! Перед началом работы проверьте, на что вы даете разрешение моделям: https://openrouter.ai/settings/privacy.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Работа с LLM</span>"
    ]
  },
  {
    "objectID": "llm.html#начало-работы-c-openrouter",
    "href": "llm.html#начало-работы-c-openrouter",
    "title": "7  Работа с LLM",
    "section": "7.3 Начало работы c OpenRouter",
    "text": "7.3 Начало работы c OpenRouter\nСоздаем объект chat, который представляет собой интерфейс для общения с языковой моделью через определённый сервис (в данном случае — сервис OpenRouter). Это специальная переменная, которая хранит в себе всю нужную информацию для того, чтобы отправлять запросы и получать ответы от нейросети (например, GPT).\n\nchat &lt;- chat_openrouter(\n  system_prompt = \"Отвечай по-русски, будь краток.\",\n  api_key = Sys.getenv(\"OPENROUTER_API_KEY\"),\n  model = \"openai/gpt-oss-20b:free\"\n)\n\n\nchat$chat(\"Что такое метафора?\")\n\nПопробуйте разные бесплатные модели.\n\nchat &lt;- chat_openrouter(\n  system_prompt = \"Отвечай по-русски, будь краток.\",\n  api_key = Sys.getenv(\"OPENROUTER_API_KEY\"),\n  model = \"meta-llama/llama-3.3-70b-instruct:free\"\n)\n\nchat$chat(\"Что такое метафора?\")\n\nДля интерактивного взаимодействия с моделью из консоли используйте команду:\n\nlive_console(chat)\n\n# ╔═══════════════════════════════╗\n# ║ Entering chat console.        ║\n# ║ Use \"\"\" for multi-line input. ║\n# ║ Type 'Q' to quit.             ║\n# ╚═══════════════════════════════╝",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Работа с LLM</span>"
    ]
  },
  {
    "objectID": "llm.html#резервный-вариант-ollama",
    "href": "llm.html#резервный-вариант-ollama",
    "title": "7  Работа с LLM",
    "section": "7.4 Резервный вариант: Ollama",
    "text": "7.4 Резервный вариант: Ollama\nOllama — это инструмент для запуска и использования больших языковых моделей (LLM, Large Language Models) на вашем компьютере. В отличие от облачных сервисов (OpenAI, Google, Mistral и др.), Ollama работает локально: ваши данные никуда не уходят, модели скачиваются прямо на ваш компьютер.\nСкачайте и установите Ollama. Перейдите на сайт: https://ollama.com/ Выберите вашу операционную систему (Windows, Mac, Linux) и следуйте инструкциям по установке.\nПосле этого установите пакет {ollamar} и скачайте нужные модели.\n\nlibrary(ollamar)\ntest_connection() \n# &lt;httr2_response&gt;\n# GET http://localhost:11434/\n# Status: 200 OK\n# Content-Type: text/plain\n# Body: In memory (17 bytes)\n\n\nollamar::list_models()\n# ollamar::pull(\"gemma2:2b\")\n\nПосле установки эти модели доступны также через {ellmer}. Локальные модели могут медленнее работать (зависит от вычислительных ресурсов компьютера и параметров модели).\n\nchat &lt;- chat_ollama(\n  model = \"gemma2:2b\"\n)\n\nchat$chat(\"Что такое метафора?\")\n\nПоследние версии Ollama позволяют работать в облаке; для этого требуется регистрация.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Работа с LLM</span>"
    ]
  },
  {
    "objectID": "llm.html#распознавание-изображений",
    "href": "llm.html#распознавание-изображений",
    "title": "7  Работа с LLM",
    "section": "7.5 Распознавание изображений",
    "text": "7.5 Распознавание изображений\nНекоторые модели принимают на входе изображения.\n\nchat &lt;- chat_openrouter(\n  system_prompt = \"Ты дружелюбный ассистент, который отвечает по-русски.\",\n  api_key = Sys.getenv(\"OPENROUTER_API_KEY\"),\n  model = \"qwen/qwen2.5-vl-32b-instruct:free\"\n)\n\nchat$chat(\n  content_image_url(\"https://www.r-project.org/Rlogo.png\"),\n  \"Что на изображении?\"\n)\n\nПопробуйте использовать модель для распознавания. Запишите ответ в переменную, если планируете его дальше использовать.\n\n\nres &lt;- chat$chat(\n  content_image_file(\"processed.png\"),\n  \"Распознай текст на изображении. \"\n)\n\n# Текст на изображении:\n# \n# &gt; \n# &gt; Просим огласить следующий факт: Бывшавший в 1894 г. из Вятской губ. \n# Бауман (ветеринарный врач, служивший в Саратовском земстве в 95–96 гг.)\n# удачно скрылся от преследований шпионов, попав случайно в совершенно \n# незнакомую местность, село Хлебное, Задонского уезда, Воронежской \n# губернии. Измученный голодом и продолжительной дорогой пьяный, он \n# резонно решил обратиться за содействием к самому интеллигентному \n# представителю деревни, к земскому врачу Валериану Валерьевичу.\n# &gt; \n# &gt;",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Работа с LLM</span>"
    ]
  },
  {
    "objectID": "llm.html#файлы-приложения",
    "href": "llm.html#файлы-приложения",
    "title": "7  Работа с LLM",
    "section": "7.6 Файлы-приложения",
    "text": "7.6 Файлы-приложения\nК запросу можно прикрепить файл pdf, например, для реферирования или перевода. Результат может вас разочаровать.\n\nchat &lt;- chat_openrouter(\n  system_prompt = \"Ты профессор философии с 30-летним опытом, специалист по теории познания.\",\n  api_key = Sys.getenv(\"OPENROUTER_API_KEY\"),\n  model = \"openai/gpt-oss-20b:free\"\n)\n\nchat$chat(\n  content_pdf_url(\"https://fitelson.org/proseminar/gettier.pdf\"),\n  \"Резюмируй в одном предложении статью Э. Геттиера.\"\n)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Работа с LLM</span>"
    ]
  },
  {
    "objectID": "llm.html#извлечение-структурированных-данных",
    "href": "llm.html#извлечение-структурированных-данных",
    "title": "7  Работа с LLM",
    "section": "7.7 Извлечение структурированных данных",
    "text": "7.7 Извлечение структурированных данных\nСтруктурированные данные можно извлекать из текста, pdf или изображений.\n\nchat &lt;- chat_openrouter(\n  api_key = Sys.getenv(\"OPENROUTER_API_KEY\"),\n  model = \"openai/gpt-oss-20b:free\"\n)\n\nchat$chat_structured(\n  \"Extract metadata from the attached pdf file.\",\n content_pdf_url(\"https://fitelson.org/proseminar/gettier.pdf\"),\n type = type_object(\n   author_name = type_string(\"Surname, Name\"), \n   title = type_string(\"Title of the publication\"),\n   year = type_number(\"year of publication\"),\n   publication_name = type_string(\"Journal title\")\n )\n)\n\n# $author_name\n# [1] \"Edmund L. Gettier\"\n# \n# $title\n# [1] \"Is Justified True Belief Knowledge?\"\n# \n# $year\n# [1] 1963\n# \n# $publication_name\n# [1] \"Philosophical Review\"",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Работа с LLM</span>"
    ]
  },
  {
    "objectID": "llm.html#конвейер-обработки",
    "href": "llm.html#конвейер-обработки",
    "title": "7  Работа с LLM",
    "section": "7.8 Конвейер обработки",
    "text": "7.8 Конвейер обработки\nПишем функцию-помощника и проверяем на одной ссылке.\n\nget_summary_pdf &lt;- function(path) {\n  message(paste0(\"Writing summary for \", path))\n  \n  prompt &lt;- \"Summarize the following article concisely in a single paragraph, using only information contained within the article. Do not use markdown formatting or bullet points.\"\n  \n  response &lt;- chat$chat(prompt,\n                        content_pdf_url(path),\n                        echo = FALSE\n                        )\n  return(response)\n}\n\nПоехали!\n\nget_summary(\"https://fitelson.org/proseminar/gettier.pdf\")\n\n# Gettier shows that the classical tripartite definition of knowledge, (a) “S knows \n# that P iff P is true, S believes P, and S is justified in believing P” (p. 1), fails \n# to give a sufficient condition for knowing, arguing that justification can be \n# satisfied by false premises or by logical entailments that do not guard against \n# mistaken sources (“First, in that sense of ‘justified’ … it is possible for a person \n# to be justified in believing a proposition that is in fact false” – p. 1). He notes \n# that the same reasoning applies to Chisholm’s and Ayer’s formulations, writing “The \n# same argument will show that (b) and (c) fail if ‘has adequate evidence for’ or ‘has \n# the right to be sure that’ is substituted for ‘is justified in believing that’ \n# throughout” (p. 1). Case I presents a situation in which Smith, justified by evidence\n# about Jones, accepts a true claim about the future office‑holder but does not know \n# it; the text states “Smith does not know that (e) is true” (p. 2). Case II constructs\n# disjunctive claims from justified belief in Jones owning a Ford, yet one claim is \n# true for an unrelated reason and the author notes “Smith does not know that (h) is \n# true” (p. 3). These counterexamples demonstrate that conditions (b) and (c) are \n# likewise insufficient, and that justified‑true belief is not a sufficient account of \n# knowledge (p. 3).\n\nПохожая функция для чтения html-страницы.\n\nget_summary_html&lt;- function(url) {\n  message(paste0(\"Writing summary for \", url))\n  \n  prompt &lt;- \"Summarize the following article concisely in a single paragraph, using only information contained within the article. Do not use markdown formatting or bullet points.\"\n  \n  response &lt;- chat$chat(prompt,\n                        url,\n                        #echo = FALSE\n                        )\n  return(response)\n}\n\n\nget_summary_html(\"https://plato.stanford.edu/archives/sum2022/entries/plato-parmenides/\")\n\n# The Stanford Encyclopedia entry on Plato’s dialogue *Parmenides* explains that the \n# work is one of the earliest surviving Platonic dialogues in which the young Socrates \n# encounters the older Parmenides, a pre‑Socratic philosopher famous for his paradoxes \n# and his doctrine of the One, and a young Zeno whose paradoxes he must defend. In the \n# dialogue Parmenides first showcases the difficulty of reconciling the multiplicity of\n# the world with the Unity of Being, using a series of thought experiments and \n# arguments that reveal the contradictions in Zeno’s reasoning. Plato uses this \n# encounter to probe the limits of dialectical method, illustrating how Socrates, so \n# far defended as a model of philosophical inquiry, is brought into conflict with the \n# very challenge of logical certainty; the discussion ends with Parmenides urging a \n# more rigorous formulation of ideas before they can be related to the sensible world. \n# The entry further demonstrates how the dialogue serves as a vehicle for questioning \n# the method of Platonic theory‑of‑forms by showing that even the most careful \n# dialectical examination can expose hidden contradictions, thereby encouraging the \n# reader to consider whether the Forms can be established on the basis of mere logical \n# manipulation alone. (See sections “Context” and “Solution”)\n\nТеперь сохраним вектор ссылок и применим к каждой из них нашу функцию.\n\nurls &lt;- c(\"https://plato.stanford.edu/archives/sum2022/entries/plato-timaeus/\",\n          \"https://plato.stanford.edu/archives/sum2022/entries/plato-parmenides/\"\n          )\n\nФормируем таблицу.\n\nsummaries &lt;- map(urls, get_summary_html)\n\nresults &lt;- tibble(\n  url = urls,\n  summary = summaries\n)\n\n\nresults$summary[1]\n\n# Timaeus, a Platonic dialogue written around 360 BCE, centers on the speaker Timaeus \n# who reports the conversation with Socrates and aged Parmenides during which a \n# cosmological system is presented: the world is described as a rational, living \n# organism created by an infinitely good Craftsman (the Demiurge) who imposes \n# mathematical order on chaos through the arrangement of the celestial spheres, the \n# Earth, and the elements; the dialogue also addresses the nature of the soul, the \n# faculties of perception, and the relationship between the sensible world and the \n# intelligible Forms, raising questions about the existence of a perfect, unchanging \n# realm of Ideas and the way this realm informs the physical cosmos; the article \n# examines the text’s historical context, its methodological significance for Platonic \n# epistemology and metaphysics, and the interpretive debates over how thoroughly the \n# dialogue can be read as a cosmological treatise rather than mere philosophical \n# rhetoric.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Работа с LLM</span>"
    ]
  },
  {
    "objectID": "llm.html#разметка-текстов",
    "href": "llm.html#разметка-текстов",
    "title": "7  Работа с LLM",
    "section": "7.9 Разметка текстов",
    "text": "7.9 Разметка текстов\nСистемный промпт для TEI разметки. Подробнее о стратегиях написания промптов см. в материале “Системного блока”.\n\nsystem_prompt &lt;- \"You are an expert TEI encoder specializing in Russian literary texts.\n\nCRITICAL RULES:\n1. Preserve the original text EXACTLY - no spelling corrections, no modernization\n2. Tag only clear geographic references\n3. Maintain original punctuation and capitalization\n\nTAGGING GUIDELINES:\n- Cities: &lt;place type='city'&gt;Москва&lt;/place&gt;\n- Rivers: &lt;place type='river'&gt;Волга&lt;/place&gt;  \n- Buildings: &lt;place type='building'&gt;Кремль&lt;/place&gt;\n- Regions: &lt;place type='region'&gt;Сибирь&lt;/place&gt;\n- Use 'fictional' for imaginary places\n\nRETURN FORMAT:\nReturn only the text with added TEI tags, no additional commentary.\"\n\nТекст, который будем аннотировать.\n\nuser_prompt &lt;- \"Может быть, никто из живущих в Москве не знает так хорошо окрестностей города сего, как я, потому что никто чаще моего не бывает в поле, никто более моего не бродит пешком, без плана, без цели — куда глаза глядят — по лугам и рощам, по холмам и равнинам. Всякое лето нахожу новые приятные места или в старых новые красоты.\nНо всего приятнее для меня то место, на котором возвышаются мрачные, готические башни Си...нова монастыря. Стоя на сей горе, видишь на правой стороне почти всю Москву, сию ужасную громаду домов и церквей, которая представляется глазам в образе величественного амфитеатра: великолепная картина, особливо когда светит на нее солнце, когда вечерние лучи его пылают на бесчисленных златых куполах, на бесчисленных крестах, к небу возносящихся! Внизу расстилаются тучные, густо-зеленые цветущие луга, а за ними, по желтым пескам, течет светлая река, волнуемая легкими веслами рыбачьих лодок или шумящая под рулем грузных стругов, которые плывут от плодоноснейших стран Российской империи и наделяют алчную Москву хлебом. На другой стороне реки видна дубовая роща, подле которой пасутся многочисленные стада; там молодые пастухи, сидя под тению дерев, поют простые, унылые песни и сокращают тем летние дни, столь для них единообразные. Подалее, в густой зелени древних вязов, блистает златоглавый Данилов монастырь; еще далее, почти на краю горизонта, синеются Воробьевы горы. На левой же стороне видны обширные, хлебом покрытые поля, лесочки, три или четыре деревеньки и вдали село Коломенское с высоким дворцом своим.\"\n\n\nchat &lt;- chat_openrouter(\n  system_prompt = system_prompt,\n  api_key = Sys.getenv(\"OPENROUTER_API_KEY\"),\n  model = \"openai/gpt-oss-20b:free\", \n  echo = FALSE\n)\n\nresult &lt;- chat$chat(user_prompt)\n\n\nwrite_lines(result, file = \"test.xml\")\n\n\nmarked_text &lt;- read_lines(\"test.xml\")\nmarked_text\n\n[1] \"Может быть, никто из живущих в &lt;place type='city'&gt;Москву&lt;/place&gt; не знает так хорошо окрестностей города сего, как я, потому что никто чаще моего не бывает в поле, никто более моего не бродит пешком, без плана, без цели — куда глаза глядят — по лугам и рощам, по холмам и равнинам. Всякое лето нахожу новые приятные места или в старых новые красоты. Но всего приятнее для меня то место, на котором возвышаются мрачные, готические башни &lt;place type='building'&gt;Си...нова монастыря&lt;/place&gt;. Стоя на сей горе, видишь на правой стороне почти всю &lt;place type='city'&gt;Москва&lt;/place&gt;, сию ужасную громаду домов и церквей, которая представляется глазам в образе величественного амфитеатра: великолепная картина, особливо когда светит на нее солнце, когда вечерние лучи его пылают на бесчисленных златых куполах, на бесчисленных крестах, к небу возносящихся! Внизу расстилаются тучные, густо-зеленые цветущие луга, а за ними, по желтым пескам, течет светлая река, волнуемая легкими веслами рыбачьих лодок или шумящая под рулем грузных стругов, которые плывут от плодоноснейших стран Российской империи и наделяют алчную &lt;place type='city'&gt;Москву&lt;/place&gt; хлебом. На другой стороне реки видна дубовая роща, подле которой пасутся многочисленные стада; там молодые пастухи, сидя под тенью дерев, поют простые, унылые песни и сокращают тем летние дни, столь для них единообразные. Подалее, в густой зелени древних вязов, блистает златоглавый &lt;place type='building'&gt;Данилов монастырь&lt;/place&gt;; еще далее, почти на краю горизонта, синеются &lt;place type='region'&gt;Воробьевы горы&lt;/place&gt;. На левой же стороне видны обширные, хлебом покрытые поля, лесочки, три или четыре деревеньки и вдали село &lt;place type='city'&gt;Коломенское&lt;/place&gt; с высоким дворцом своим.\"\n\n\nФайл можно отредактировать вручную, но прежде, чем это делать, попробуйте\n\nсравнить работу разных моделей;\nусовершенствовать системный промпт, добавить больше примеров.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Работа с LLM</span>"
    ]
  },
  {
    "objectID": "llm.html#создание-полных-tei-документов",
    "href": "llm.html#создание-полных-tei-документов",
    "title": "7  Работа с LLM",
    "section": "7.10 Создание полных TEI документов",
    "text": "7.10 Создание полных TEI документов\nНиже показано минимальное решение. Отредактируйте код с учетом тех метаданных, которые необходимо сохранить. Ориентируйтесь на стандарты TEI.\n\ncreate_complete_tei &lt;- function(marked_text, metadata = list()) {\n  default_metadata &lt;- list(\n    title = \"Неизвестное произведение\",\n    author = \"Неизвестный автор\", \n    date = \"Не датировано\",\n    language = \"ru\"\n  )\n  \n  metadata &lt;- modifyList(default_metadata, metadata)\n  \n  tei_template &lt;- '&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\"&gt;\n  &lt;teiHeader&gt;\n    &lt;fileDesc&gt;\n      &lt;titleStmt&gt;\n        &lt;title&gt;%s&lt;/title&gt;\n        &lt;author&gt;%s&lt;/author&gt;\n      &lt;/titleStmt&gt;\n      &lt;publicationStmt&gt;\n        &lt;p&gt;Автоматически размеченный текст для исследовательских целей&lt;/p&gt;\n      &lt;/publicationStmt&gt;\n      &lt;sourceDesc&gt;\n        &lt;p&gt;Оригинальный текст: %s&lt;/p&gt;\n      &lt;/sourceDesc&gt;\n    &lt;/fileDesc&gt;\n    &lt;profileDesc&gt;\n      &lt;langUsage&gt;\n        &lt;language ident=\"%s\"&gt;Русский&lt;/language&gt;\n      &lt;/langUsage&gt;\n    &lt;/profileDesc&gt;\n  &lt;/teiHeader&gt;\n  &lt;text&gt;\n    &lt;body&gt;\n      &lt;div&gt;\n        &lt;p&gt;%s&lt;/p&gt;\n      &lt;/div&gt;\n    &lt;/body&gt;\n  &lt;/text&gt;\n&lt;/TEI&gt;'\n  \n  sprintf(tei_template, \n          metadata$title, \n          metadata$author, \n          metadata$date, \n          metadata$language,\n          marked_text)\n}\n\n\n# Пример использования\nmetadata &lt;- list(\n  title = \"Отрывок из 'Бедной Лизы'\",\n  author = \"Карамзин, Николай Михайлович\",\n  date = \"1792\",\n  language = \"ru\"\n)\n\ncomplete_tei &lt;- create_complete_tei(marked_text, metadata)\n\ncat(complete_tei)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Работа с LLM</span>"
    ]
  },
  {
    "objectID": "llm.html#сравнение-с-оригиналом",
    "href": "llm.html#сравнение-с-оригиналом",
    "title": "7  Работа с LLM",
    "section": "7.11 Сравнение с оригиналом",
    "text": "7.11 Сравнение с оригиналом\nC валидным xml можно работать так обычно (см. урок 5)\n\ndoc &lt;- read_xml(\"complete_tei.xml\") \nns &lt;- xml_ns(doc)\n\ntext_content &lt;- doc |&gt; \n    xml_find_all(\"//d1:body//d1:p\") |&gt; \n    xml_text() \n\ntext_content\n\n[1] \"Может быть, никто из живущих в Москву не знает так хорошо окрестностей города сего, как я, потому что никто чаще моего не бывает в поле, никто более моего не бродит пешком, без плана, без цели — куда глаза глядят — по лугам и рощам, по холмам и равнинам. Всякое лето нахожу новые приятные места или в старых новые красоты. Но всего приятнее для меня то место, на котором возвышаются мрачные, готические башни Си...нова монастыря. Стоя на сей горе, видишь на правой стороне почти всю Москва, сию ужасную громаду домов и церквей, которая представляется глазам в образе величественного амфитеатра: великолепная картина, особливо когда светит на нее солнце, когда вечерние лучи его пылают на бесчисленных златых куполах, на бесчисленных крестах, к небу возносящихся! Внизу расстилаются тучные, густо-зеленые цветущие луга, а за ними, по желтым пескам, течет светлая река, волнуемая легкими веслами рыбачьих лодок или шумящая под рулем грузных стругов, которые плывут от плодоноснейших стран Российской империи и наделяют алчную Москву хлебом. На другой стороне реки видна дубовая роща, подле которой пасутся многочисленные стада; там молодые пастухи, сидя под тенью дерев, поют простые, унылые песни и сокращают тем летние дни, столь для них единообразные. Подалее, в густой зелени древних вязов, блистает златоглавый Данилов монастырь; еще далее, почти на краю горизонта, синеются Воробьевы горы. На левой же стороне видны обширные, хлебом покрытые поля, лесочки, три или четыре деревеньки и вдали село Коломенское с высоким дворцом своим.\"\n\n\n\nlibrary(diffobj)\ndiffobj::diffChr(user_prompt, text_content, mode = \"sidebyside\")",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Работа с LLM</span>"
    ]
  },
  {
    "objectID": "llm.html#начало-работы-с-ollama",
    "href": "llm.html#начало-работы-с-ollama",
    "title": "7  Работа с LLM",
    "section": "7.4 Начало работы с Ollama",
    "text": "7.4 Начало работы с Ollama\nOllama — это инструмент для запуска и использования больших языковых моделей (LLM, Large Language Models) на вашем компьютере. В отличие от облачных сервисов (OpenAI, Google, Mistral и др.), Ollama работает локально: ваши данные никуда не уходят, модели скачиваются прямо на ваш компьютер.\nСкачайте и установите Ollama. Перейдите на сайт: https://ollama.com/ Выберите вашу операционную систему (Windows, Mac, Linux) и следуйте инструкциям по установке.\nПосле этого установите пакет {ollamar} и скачайте нужные модели.\n\nlibrary(ollamar)\ntest_connection() \n# &lt;httr2_response&gt;\n# GET http://localhost:11434/\n# Status: 200 OK\n# Content-Type: text/plain\n# Body: In memory (17 bytes)\n\n\nollamar::list_models()\n# ollamar::pull(\"gemma2:2b\")\n\nПосле установки эти модели доступны также через {ellmer}. Локальные модели могут медленнее работать (зависит от вычислительных ресурсов компьютера и параметров модели).\n\nchat &lt;- chat_ollama(\n  model = \"gemma2:2b\"\n)\n\nchat$chat(\"Что такое метафора?\")\n\nПоследние версии Ollama позволяют работать в облаке; для этого требуется регистрация. После регистрации идете на сайте Settings -&gt; Keys и создаете новый ключ API. Список облачных моделей доступен здесь https://ollama.com/blog/cloud-models.\n\nchat &lt;- chat_ollama(\n  system_prompt = \"Отвечай по-русски, будь краток.\",\n  api_key = Sys.getenv(\"OLLAMA_API_KEY\"),\n  # важно указать именно облачную модель\n  model = \"gpt-oss:120b-cloud\"\n)\n\nchat$chat(\"Что такое метафора?\")\n# Метафора — образный приём, при котором слово или выражение \n# переносит значение с одного предмета на другой за счёт их \n# сходства, но без использования сравнительных союзов (как, будто). \n# Это способ сравнения, когда один объект «становится» другим в \n# переносном смысле.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Работа с LLM</span>"
    ]
  },
  {
    "objectID": "llm.html#параметры-модели",
    "href": "llm.html#параметры-модели",
    "title": "7  Работа с LLM",
    "section": "7.12 Параметры модели",
    "text": "7.12 Параметры модели\nДля настройки параметров модели в {ellmer} есть специальная функция. Мы отрегулируем температуру – гиперпараметр, который контролирует уровень случайности и “креативности” при генерации текста. Манипулируя температурой, можно управлять балансом между предсказуемостью и разнообразием генерируемого текста.\n\nparams_cold &lt;- params(temperature = 0)\nparams_hot &lt;- params(temperature = 2)\n\nСравним поведение одной модели с разной температурой. Максимальная креативность (для моделей OpenAi = 2) граничит с бессвязностью:\n\nchat &lt;- chat_openrouter(\n  system_prompt = \"Ты всегда отвечаешь одним предложением\",\n  api_key = Sys.getenv(\"OPENROUTER_API_KEY\"),\n  model = \"openai/gpt-oss-20b:free\", \n  params = params_hot\n  )\n\nchat$chat(\"Что такое метафора?\")\n# Метафора – это перенесённое, сравнениеобразное \n# соображение, когда признак либо качества предмета \n# описывается термином, относящимся именно быту, но \n# обозначая другой предмет.\n\nЧем “холоднее” модель, тем более предсказуема выдача. Результаты повторных запросов будут отличаться минимально.\n\nchat &lt;- chat_openrouter(\n  system_prompt = \"Ты всегда отвечаешь одним предложением\",\n  api_key = Sys.getenv(\"OPENROUTER_API_KEY\"),\n  model = \"openai/gpt-oss-20b:free\",\n  params = params_cold\n)\n\nchat$chat(\"Что такое метафора?\")\n# Метафора — это фигура речи, при которой слово или \n# выражение переносит значение из одного предмета в \n# другой, создавая образное сравнение без использования \n# союзов «как», «словно» и т.п.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Работа с LLM</span>"
    ]
  }
]