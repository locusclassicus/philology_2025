# Табличные данные. Анализ датасета

В этом уроке мы научимся работать с “прямоугольными”, т.е. табличными, данными на примере [корпуса русской элегии](https://dataverse.pushdom.ru/dataset.xhtml?persistentId=doi:10.31860/openlit-2019.11-C001&version=1.0) 1815—1835 гг., собранного и опубликованного Антониной Мартыненко в 2020 г.

Существуют два основных “диалекта” R, один из которых опирается главным образом на функции и структуры данных базового R, а другой пользуется синтаксисом `tidyverse`. `Tidyverse` – это семейство пакетов (метапакет), разработанных Хадли Уикхемом и др., которое включает в себя в том числе пакеты `dplyr`, `ggplot2` и многие другие.

```{r}
library(tidyverse)
```

## Импорт табличных данных

Файл можно скачать вручную по ссылке выше или воспользоваться специальной функцией.

```{r eval=FALSE}
url <- "https://dataverse.pushdom.ru/api/access/datafile/:persistentId?persistentId=doi:10.31860/openlit-2019.11-C001/6EPZFO"
```

В окружении появится объект url. Это строка, т.е. последовательность символов. Передаем ее в качестве аргумента функции download.file(); вторым аргументом указываем название файла-назначения:

```{r eval=FALSE}
download.file(url, destfile = "elegies.tab")
```

После этого можно прочитать файл в окружение:

```{r eval=FALSE}
elegies_tbl <- read_tsv("elegies.tab")
```

```{r echo=FALSE}
elegies_tbl <- read_tsv("../datasets/elegies/elegies_metadata.tab")
```

## Анализ и обобщение данных

### Tibble

Основная структура данных в tidyverse – это tibble, современный вариант датафрейма. Тиббл, как говорят его разработчики, это ленивые и недовольные датафреймы: они делают меньше и жалуются больше. Это позволяет решать проблемы на более ранних этапах, что, как правило, приводит к созданию более чистого и выразительного кода.

Основные отличия от обычного датафрейма:

- усовершенствованный метод print(), не нужно постоянно вызывать head();
- нет имен рядов;
- допускает синтаксически “неправильные” имена столбцов;
- при индексировании не превращается в вектор.

Преобразуем наш тиббл в датафрейм для сравнения.

```{r}
elegies_df <- as.data.frame(elegies_tbl)
```

### Dplyr

“Грамматика манипуляции данных”, лежащая в основе dplyr, предоставляет последовательный набор глаголов, которые помогают решать наиболее распространенные задачи манипулирования данными:

- `mutate()` добавляет новые переменные, которые являются функциями существующих переменных;
- `select()` выбирает переменные (столбцы) на основе их имен;
- `filter()` выбирает наблюдения (ряды) на основе их значений;
- `summarise()` обобщает значения;
- `arrange()` изменяет порядок следования строк.

Все эти глаголы естественным образом сочетаются с функцией `group_by()`, которая позволяет выполнять любые операции “по группам”, и с оператором pipe `|>` из пакета `magrittr`.

В итоге получается лаконичный и читаемый код. Узнаем, за какие года у нас есть элегии.

```{r}
elegies_tbl |> 
  count(Year) |> 
  print()
```


Отберем элегии 1824 г. и выясним, какие авторы их писали.

```{r}
elegies_tbl |> 
  filter(Year == 1824) |> # используем логический оператор для выбора
  count(Author) |>  #  можно задать  аргумент sort = TRUE
  arrange(-n)  |>   # не нужно, если sort = TRUE
  print()
```

:::{.callout-warning icon=false}
Теперь попробуйте сформулировать новые вопросы и ответить на них при помощи этого датасета. 
:::

## Импорт текстовых данных

Скачаем архив элегий и распакуем его.

```{r eval=FALSE}
url = "https://dataverse.pushdom.ru/api/access/datafile/:persistentId?persistentId=doi:10.31860/openlit-2019.11-C001/SKGO9Q"

download.file(url, "corpus.zip")
# trying URL 'https://dataverse.pushdom.ru/api/access/datafile/:persistentId?persistentId=doi:10.31860/openlit-2019.11-C001/SKGO9Q'
# Content type 'application/zip; name="elegies_corpus.zip";charset=UTF-8' length 806772 bytes (787 KB)
# ==================================================
# downloaded 787 KB
```

После выполнения команды ниже в рабочей директории должна появиться папка corpus.

```{r eval=FALSE}
unzip("corpus.zip")
```

Заглянем в папку и сохраним список файлов.

```{r}
elegies_files <- list.files("corpus", full.names = TRUE)
```


Чтобы распечатать пути к первым шести файлам, используйте команду head().

```{r}
head(elegies_files)
```

Создадим таблицу со всеми текстами и их id. Функция `str_c()` из пакета `stringr` позволяет объединить несколько строк в одну (через пробел).

```{r}
elegies_texts <- tibble(title = elegies_files,
                        text = map_chr(elegies_files, 
                                       \(x) str_c(read_lines(x), collapse = " ")
                                       )
                        )

elegies_texts |> 
  print()
```


Теперь преобразуем столбец `title`: оставим только `id`.

```{r}
elegies_sep <- elegies_texts |> 
  mutate(title = str_remove(title, "corpus/")) |> 
  separate(title, into = c("id", NA)) |>  # отбрасываем все после id 
  mutate(id = as.numeric(id))

elegies_sep |> 
  print()
```


## Объединение данных

Теперь мы можем объединить метаданные с конкретными текстами.

Отберем из датасета только Пушкина и Баратынского (Пушкиных там двое, так что указываем инициалы. Вертикальная черта - это логичеческий оператор “ИЛИ”. Функция str_detect() возвращает логический вектор, который используется для фильтрации.

```{r}
elegies_selection <- elegies_tbl |> 
  filter(str_detect(Author, "Баратынский |Пушкин А.С.")) |> 
  rename(First_line = `First line`) |>  # убираем пробел из названия столбца
  select(id, Author, Year, Source_name, Title, First_line)
```


После этого объединяем два тиббла:

```{r}
elegies_joined <- elegies_selection |> 
  left_join(elegies_sep)
```

## Токенизация

Разделим тексты на токены. Для этого надо установить библиотеку tidytext.

```{r}
library(tidytext)
elegies_tokens <- elegies_joined |> 
  unnest_tokens(output = "word", input = "text")
```

Слова можно лемматизировать, подробнее об этом см. здесь.

## Удаление стоп-слов

Удалим самые частотные слова. Для этого сначала сохраним их список. Подробнее см. здесь.

```{r}
library(stopwords)
sw <- stopwords("ru")
sw
```

```{r}
elegies_clean <- elegies_tokens |> 
  filter(!word %in% sw)

elegies_clean |> 
  print()
```

## Подсчет частотностей

Узнаем, сколько всего слов приходится на каждого автора в корпусе.

```{r}
elegies_clean |> 
  group_by(Author) |> 
  summarise(n = n()) |> 
  print()
```


Упс! У нас два Баратынских. Исправим:

```{r}
elegies_clean <- elegies_clean |> 
  mutate(Author = case_when(str_detect(Author, "Баратынский") ~ "Баратынский Е.А.",
                   .default = Author))
```

Снова проверим.

```{r} 
elegies_clean |> 
  group_by(Author) |> 
  summarise(n = n()) |> 
  print()
```

Найдем самые частотные слова у Пушкина и Баратынского. Обратите внимание, что результат вычислений не сохраняется.

```{r}
elegies_clean |> 
  count(word, sort = TRUE) |> 
  print()
```


Так мы получили абсолютные значения. Чтобы посчитать долю, немного изменим код:

```{r}
top_words <- elegies_clean |> 
  group_by(Author) |> 
  count(word, sort = TRUE) |> 
  mutate(perc = (n / sum(n)) * 100) |> 
  arrange(-perc) |> 
  slice_max(n = 10, order_by = perc)

top_words |> 
  print()
```

## Визуализации

В tidyverse входит пакет ggplot2 для визуализации данных. В его основе лежит идея “грамматики графических элементов” Лиланда Уилкинсона [@мастицкий2017] (отсюда “gg” в названии).

Функция `ggplot()` имеет два основных аргумента: `data` и `mapping`. Аргумент `mapping` задает эстетические атрибуты геометрических объектов. Обычно используется в виде `mapping = aes(x, y)`, где `aes()` означает `aesthetics`.

Под “эстетикой” подразумеваются графические атрибуты, такие как размер, форма или цвет. Вы не увидите их на графике, пока не добавите какие-нибудь “геомы” – геометрические объекты (точки, линии, столбики и т.п.). Эти объекты могут слоями накладываться друг на друга [@wickham2016].

Мы построим столбиковую диаграмму.

```{r}
top_words |> 
  ggplot(aes(word, perc, fill = Author)) +
  geom_col() +
  facet_wrap(~Author, scales="free") +
  coord_flip() +
  theme_bw()
```

Каждый геометрический объект может иметь свои специфические параметры. Например, geom_point() может варьировать размер, цвет, форму и прозрачность точек, а geom_line() — тип, толщину и цвет линии. Эти параметры можно задавать как внутри aes() (когда они зависят от данных), так и вне её (когда задаются константы).

## Видео к этому уроку

- Видео [2025](https://vkvideo.ru/video91786643_456239073) г.

## Домашняя работа

Будет позже.

