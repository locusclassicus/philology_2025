# Распознавание изображений

В этом уроке мы освоим основной инструмент для распознавания печатного текста в R – пакет `tesseract`, а также научимся дообучать модели под конкретные задачи и шрифты. Для работы нам понадобятся следующие библиотеки:

```{r message=FALSE}
library(qpdf)
library(tesseract)
library(pdftools)
# install.packages("remotes")
# remotes::install_github("arcruz0/tesseractgt")
library(tesseractgt)
library(magick)
```

## Что такое OCR и tesseract

OCR (Optical Character Recognition) — это технология автоматического распознавания печатного текста на изображениях и преобразования его в машинно-читаемый формат. Эта технология позволяет “извлекать” текст из сканированных документов, фотографий, PDF-файлов и других графических форматов.

[Tesseract](https://ru.wikipedia.org/wiki/Tesseract) — это одна из самых популярных библиотек OCR с _открытым исходным кодом_, разработанная компанией Google. Tesseract поддерживает более 100 языков и может работать с различными типами изображений и форматами документов. Это совершенно бесплатно. Последние версии Tesseract используют обучение при помощи нейросетей (LSTM), и их можно дообучать под свои задачи, что очень удобно и не требует больших мощностей и продвинутых навыков программирования.  

Пакет `tesseract` в R представляет собой обертку для библиотеки Tesseract, которая позволяет:

- Распознавать текст с изображений различных форматов (PNG, JPEG, TIFF, PDF);
- Работать с многостраничными документами;
- Использовать предобученные модели для разных языков ([список](https://tesseract-ocr.github.io/tessdoc/Data-Files-in-different-versions.html));
- Настраивать параметры распознавания под конкретные задачи;
- Дообучать модели для улучшения качества распознавания специфических шрифтов или типов документов.

В отличие от онлайн-сервисов OCR, пакет `tesseract` работает локально, что обеспечивает:

- Конфиденциальность — данные не передаются третьим лицам;
- Скорость — нет задержек на передачу данных по сети;
- Настраиваемость — возможность тонкой настройки под конкретные задачи;
- Бесшовную интеграцию с экосистемой R для дальнейшего анализа данных.

Однако качество распознавания сильно зависит от качества исходного изображения, типа шрифта, языка документа и правильности настройки параметров. Именно поэтому важно уметь не только использовать готовые модели, но и дообучать их под специфические задачи.

```{r}
```

## Данные

В качестве упражнения мы возьмем ч. 6 № 6 журнала “Невский зритель” за 1821 г. ([источник](http://lib.pushkinskijdom.ru/Default.aspx?tabid=11373)). Чтобы не запутаться в выпусках, заберите нужный номер [из репозитория курса](https://github.com/locusclassicus/philology_2025/tree/main/ocr) и сохраните его на компьютер.

Журнал «Невский зритель» издавался в Петербурге ежемесячно с января 1820 г. по июнь 1821 г. Всего вышло 18 книжек журнала, составивших 6 частей. Все они доступны на сайте “Пушкинского дома”.

> Официальным издателем журнала был выпускник Московского университета Иван Матвеевич Сниткин (род. ок. 1792 г.). С января по апрель 1820 г. соиздателем «Невского зрителя» был В. К. Кюхельбекер; намеревался войти в число издателей и К. Ф. Рылеев (1797-1826), активный сотрудник журнала с октября 1820-го по февраль 1821 г. В разное время в журнале печатались произведения Пушкина, Кюхельбекера, Жуковского, Баратынского, Дельвига, а также Рылеева, поместившего в октябрьской книжке 1820 г. острейшую сатиру на Аракчеева «К временщику». ([Источник](https://www.gorkilib.ru/events/200-let-zhurnalu-nevskiy-zritel).)

## Выбор страниц

Для начала вырежем несколько страниц из pdf. Таким образом вы легко можете делить любые издания на главы, разделы и т.д. Сначала сохраняем путь к файлу в виде строки (у меня он лежит в папке `ocr`, но у вас путь может быть иной).

```{r}
my_files <- list.files("../ocr", pattern = "pdf", full.names = TRUE)
my_files[2] # нужный файл
```

Теперь вырежем из журнала две страницы. В `input` отдаем путь к файлу (как он выглядит на вашем компьютере); в `output` -- любой путь (или только имя и расширение) для нового файла (можете придумать свое); аргументу `pages` передайте номера страниц.

```{r eval=FALSE}
pdf_subset(input = my_files[2],
           output = "../ocr/НЗ1821_6_6[50-51].pdf",
           pages = 50:51)
```

После этого у вас на компьютере должен появиться pdf вот такого элегического содержания.

:::{layout-ncol=2}

![](./images/rosalia1.png)

![](./images/rosalia2.png)

:::

:::{.callout-tip icon=false}
Найдите в метаданных к корпусу русских элегий предположительную фамилию автора.
:::

Ответ: `r fitb("Бадульф")`.

## Извлечение текста из pdf

Если вам повезло, то pdf хранит уже распознанный текст. Такое бывает довольно часто (хотя иногда распознавание настолько плохое, что проще сделать вид, что его нет, и распознать заново). Проверим.

```{r}
text1 <- pdf_text(pdf = "../ocr/НЗ1821_6_6[50-51].pdf")
# как print(), но больше подходит для вывода текста (можете сравнить)
cat(text1)
```


Текст распознан достаточно хорошо, есть мелкие ошибки, но их можно исправить (о чем речь пойдет в следующем уроке). Если необходимо сохранить извлеченный из pdf текст для дальнейшей работы, это делается так:

```{r eval=FALSE}
# укажите свой путь или одно только имя
writeLines(text1, con = "../ocr/rosalia_1.txt")
```

Прежде чем двигаться дальше, убедитесь, что тест сохранился.

## Распознавание

Если текст не распознан (притворимся, что так и есть), то можно попробовать распознать при помощи `tesseract`. Однако есть нюанс: `tesseract` не знает дореформенного русского. Это значит, что все яти (ѣ), еры (ъ), фиты (Ѳ) и десятеричные и (і) превратятся во что-то странное. А еще трудности бывают с буквой "т", т.к. в XVIII и XIX в. ее иногда печатали по-другому.

Чтобы использовать предобученную модель, ее надо скачать при помощи функции `tesseract_download()`. Это делается один раз (поэтому у меня эта строчка закомментирована). Кстати, тессеракт способен "читать" тексты на нескольких языках, для этого передаем значение аргументу language так: `"rus+deu"`. Важно правильно указать код; если не уверены, еще раз загляните в [список моделей](https://tesseract-ocr.github.io/tessdoc/Data-Files-in-different-versions.html). После этого выведите список моделей.

```{r eval=FALSE}
# tesseract_download("rus")
tesseract_info()$available
```

Модель скачана, мы можем использовать ее для распознавания. Но на многое не рассчитываем, ведь это модель для современного русского, со старой орфографией она не знакома. 

Функция `pdf_ocr_text()` из пакета `{pdftools}` преобразует наш pdf в серию картинок и обращается к пакету `{tesseract}` для распознавания. 

```{r eval=FALSE}
text2 <- pdf_ocr_text("../ocr/НЗ1821_6_6[50-51].pdf", 
                      language = "rus")

cat(text2)

# Converting page 1 to НЗ1821_6_6[50-51]_1.png... done!
# Converting page 2 to НЗ1821_6_6[50-51]_2.png... done!

# 999939993993999999339993399999939939 9039303939
# РАЗЛУКА.
# (Элегтя.)
# ————-
# Розамя, мой спушникъь неизмённый
# На полЪ радосшей земныхь!
# Розал!я, мой другь, хранишель несравненный!
# Когда я ошдохну въ объяпияхь швоихъ?...
# Съ шобою горестей душа моя незнаеть,
# И сердцу скорбному не измЪнить покой!
# Надежда мрачный пушь звЪздою озаряепть,
# И я мирюсь съ враждебною судьбой!...
# ’Геперь, за дальними, свиофпыми морями
# Твой сладк!й гласъ не оживишьъ меня!
# Взойдеть заря надъ злачными холмами,
# Появишся въ лучахъ свЪшило дня —
# Напрасно! все кругомъ покрыпю мглою.
# Неслышишся мнЪ сладюй тивой привЪфить,
# ВсЪ5 радосши, надежды всЪ съ шобою —
# И опусш$ль безъ милой свЪзить’
# Подруга милая, скажи, чшо край прелесшный,
# Чпо мирвыя, тифвисптыя поля,
# Чтпо своенравныя судьбы привЪтьъ мн лесшный,
# Когда съ шобой въ разлук я.
# Но другь мой! горесмь ошленаепть
#  245
# На бысшрыхь времени крылахь,
# И радосшь сердце посфщаеть....
# Моя надежда — въ небесахь!...
# Когдажъ опяшь смягченными судьбами
# Я въ радосши къ подругЪ понесусь,
# Коснусь волшебныхь сшрунь волшебными пер-
# сшами
# И, сь рфзвою мечтшою примирюсь.
# Я, Б — $5.
```

Сохраним `text2` в отдельный файл для сравнения.

```{r eval=FALSE}
writeLines(text2, con = "../ocr/rosalia_2.txt")
```


Как быть, если результат распознавания не устраивает? 

- Первое: проверить, нет ли обученных моделей, которые справятся с вашей задачей. Можно поискать, например, [модели](https://huggingface.co/Serovvans/trocr-prereform-orthography) на Hugging Face. Но результат может будет зависеть от того, на каких шрифтах учили модель. 

- Второе: обученные модели можно также поискать в [Транскрибусе](https://sysblok.ru/digital-heritage/transkribus-kak-kompjuternoe-zrenie-pomogaet-perevodit-teksty-sirijskih-mistikov/) (например, [здесь](https://app.transkribus.org/models/public/text/russian-print-xviii-cent) и [здесь](https://app.transkribus.org/models/public/text/44358)). Но у Транскрибуса есть ряд ограничений: модели нельзя использовать локально, за расширенный функционал придется платить, и др. Бесплатно можно пользоваться готовыми приложениями.

- Наконец, можно дообучить уже существующую модель `tesseract`, как показано вот в этом [примере](https://arcruz0.github.io/posts/finetuning-tess/index.html). Этим мы сейчас и займемся.

## Конвертация pdf

Функция `pdf_ocr_text()` "подметет" за собой все картинки. Чтобы преобразовать pdf изображения и сохранить их на компьютере (например, для внешнего приложения по распознаванию текста или для создания обучающих данных), используем другую функцию. 

```{r eval=FALSE}
pdf_convert("../ocr/НЗ1821_6_6[50-51].pdf", 
            format = "png", 
            dpi = 300,
            pages = NULL,  # все страницы, или c(1,3,5) для конкретных
            filenames = NULL)
```

Запустите код и убедитесь, что в выбранной директории появились два файла с расширением `.png`. Они нам пригодятся чуть позже.

## Препроцессинг изображений 

Точность OCR зависит от качества исходного изображения. Часто можно улучшить результат, правильно масштабируя изображение, удаляя шум и артефакты или обрезая область, где находится текст. Отличный пакет `{magick}` содержит множество полезных функций для улучшения качества изображения. Что можно [попробовать](https://cran.r-project.org/web/packages/tesseract/vignettes/intro.html#Preprocessing_with_Magick):

- Если изображение наклонено, используйте `image_deskew()` и `image_rotate()`, чтобы выровнять текст по горизонтали.
- `image_trim()` обрезает поля с пробельными областями. Увеличьте параметр `fuzz`, чтобы лучше справляться с "шумом".
- Используйте `image_convert()` для преобразования изображения в градации серого.
- Если изображение слишком большое или слишком маленькое, изменение размера с помощью `image_resize()` может помочь `tesseract` определить размер текста.
- Используйте `image_modulate()` или `image_contrast()` для регулировки яркости/контраста, если это проблема.
- Попробуйте `image_reducenoise()` для автоматического удаления шума.
- С `image_quantize()` можно сократить количество цветов на изображении. Иногда это помогает усилить контраст и убрать артефакты.

Возьмем вот такое изображение и сравним результат распознавания до и после препроцессинга. 

![](images/IMG_5539.jpg)


```{r}
input <- image_read("./images/IMG_5539.jpg")

text1 <- input |> 
  tesseract::ocr(engine = "rus") 
```

```{r}
# Обработка изображения
processed <- input |>
  image_deskew() |> 
  image_resize("2000x") |>          
  image_convert(colorspace = "gray") |> 
  image_trim(fuzz = 40)  |> 
  image_modulate(brightness = 120, saturation = 0)  |>
  image_contrast(sharpen = 1) |>
  image_normalize() |>  
  image_despeckle() 
```

```{r eval=FALSE}
# Сохранение на диск (посмотреть результат)
image_write(processed, path = "./images/processed.png", format = "png", density = "300x300")
```


![](./images/processed.png) 


```{r}
# OCR на обработанном изображении
text2 <- tesseract::ocr(processed, engine = "rus")
```

![](./images/compare.png)

Что-то изменилось, но пока сложно сказать, в какую сторону `r emo::ji("thinking")`


Если проблема в том, что строки имеют разный наклон (например, из-за деформации страницы), то может потребоваться нелинейное преобразование (например, коррекция искажения). Это сложнее, и в `{magick}` нет прямых функций для этого. Возможно, потребуется использование других инструментов, в том числе предобработка в специализированном ПО.

## Файн-тюнинг

Начиная с версии 4, Tesseract использует нейронную сеть для распознавания текста, что позволяет дообучать модель для конкретных задач. Для дообучения необходимы _эталонные данные_ — фрагменты изображений с соответствующим им текстом.

### Подготовка изображений

Создайте папку с именем `{язык}-ground-truth/` (например, `orus-ground-truth/`) и поместите туда изображения текста. Названия файлов могут быть любыми. 

```{r eval=FALSE}
dir.create("orus-ground-truth")
```

Самый простой способ: сделать скриншоты вручную (чем больше, тем лучше). Вот пример:

![](images/ground_truth1.png)

Более продвинутый подход к нарезке изображений можно найти [здесь](https://github.com/ukolshurika/finetune-ocr-sample) (для Python). Мы нарежем изображение на отдельные слова в R. Для этого скачайте следующий [скрипт](https://github.com/locusclassicus/philology_2025/blob/main/helper_scripts/crop_words.R) и запустите его:

```{r}
source("../helper_scripts/crop_words.R")
```

В глобальном окружении появится функция `crop_words()`. Если хотите заглянуть внутрь, просто наберите `View(crop_words)`. Но разбираться в начинке необязательно. Вы же не всегда интересуетесь, что там под капотом других функций? Просто эту вы взяли не из пакета, а из GitHub'а. А можете сами написать, сохранить себе, и так же использовать внутри других скриптов.

Функция `crop_words()` принимает на входе путь до изображения (обязательный аргумент), название директории, куда будут сохранены слова (по умолчанию `words`), язык базовой модели (код `tesseract`, по умолчанию `rus`) и отступ вокруг слова при обрезке (в пикселях). Аргумент `overwrite` управляет тем, очищать ли существующие файлы `word_*.png` в `out_dir` перед сохранением (по умолчанию `FALSE`). 

Также функция проверяет наличие пакетов `magick`, `tesseract`, `tidyverse`; при отсутствии пытается установить их вместе с зависимостями и затем подключает.
Для корректной работы OCR с выбранным языком в системе должны быть установлены языковые данные Tesseract. Функция сохранит в папку изображения, а также вернет таблицу с метаданными (ее присвоим переменной; это не обязательно делать).

```{r eval=FALSE}
words_data <- crop_words(image_path = "../ocr/НЗ1821_6_6[50-51]_1.png",
           out_dir = "../ocr/orus-ground-truth",
           lang = "rus",
           pad = 0,
           overwrite = TRUE)
```


После этого в папке должно появиться нечто похожее:

![](images/words_view.png)
Чтобы "разрезать" на слова _несколько_ изображений, используем функции для итераций из пакета `purrr` (мы встречались с ними, когда читали сразу несколько текстовых файлов в окружение). 

Сначала собираем все пути до файлов в символьный вектор.

```{r}
img_paths <- list.files("../ocr", pattern = "png", full.names = TRUE)
img_paths
```

И запускаем итерации! 

```{r eval=FALSE}
walk(img_paths, crop_words, 
     out_dir = "../ocr/orus-ground-truth")
```

После запуска кода в папке должно появиться 157 файлов `png`. 

```{r eval=FALSE}
list.files("../ocr/orus-ground-truth") |> 
  length()
```

Обратите внимание на то, что функция `walk()`, в отличие от `map_chr()` из того же пакета `{purrr}`, ничего не сохраняет в окружение. Мы используем ее для повторного запуска `crop_words()`, которая последовательно нарезает страницы на слова и "сбрасывает" изображения слов в указанную директорию. То же самое можно было бы сделать так:

```{r eval=FALSE}
crop_words(image_paths[1])
crop_words(image_paths[2])

# ...и так далее!
```

Но, согласитесь, повторять это действие больше двух раз достаточно утомительно. Кроме того, у программистов считается плохим тоном "копипастить" один кусок кода более двух раз. Поэтому мы использовали функцию-итератор. Вжух.

### Текстовые файлы

Теперь для каждого изображения добавим текст (файлы в формате `.gt.txt`). Для ускорения процесса создания эталонных файлов можно использовать пакет `tesseractgt`. Для создания таких файлов используем базовую модель.

```{r eval=FALSE}
create_gt_txt(
  folder = "../ocr/orus-ground-truth",
  extension = "png", 
  engine = tesseract::tesseract(language = "rus")
)
```

Убедитесь, что файлы появились в директории. Это должно выглядеть примерно так:

![](images/img_and_text_view.png)
   

```{r}
gt <- list.files("../ocr/orus-ground-truth", pattern = "txt", full.names = TRUE)

res <- tibble::tibble(
  file = gt,
  n_lines = purrr::map_int(gt, ~ length(readLines(.x, warn = FALSE)))
)

res
```


Теперь самый важный этап: корректировка текстовых файлов. Исправить автоматически созданные файлы `.gt.txt` поможет специальная функция:

```{r eval=FALSE}
correct_gt_txt() 
```

![[Источник](https://arcruz0.github.io/posts/finetuning-tess/)](https://arcruz0.github.io/posts/finetuning-tess/imgs/addin.gif)

Если не видно папки с изображениями, смените рабочую директорию. Вот несколько полезных символов: 

:::{.callout-note icon=false}:::
Чаще всего используемые в дореформенной русской орфографии:

- Ять: Ѣ (U+0462), ѣ (U+0463)
- И десятеричное: І (U+0406), і (U+0456)
- Фита: Ѳ (U+0472), ѳ (U+0473)
- Ижица: Ѵ (U+0474), ѵ (U+0475)
- Твёрдый знак, еръ: Ъ (U+042A), ъ (U+044A)
:::

Исправьте несколько файлов (чем больше, тем лучше). 

Если видите ошибку `Warning: Error in writeImpl: Text to be written must be a length-one character vector`, сделайте следующее:

```{r eval=FALSE}
fix_gt_txt <- function(folder) {
  txts <- list.files(folder, pattern = "\\.txt$", full.names = TRUE)
  for (f in txts) {
    # читаем файл
    x <- readLines(f, warn = FALSE, encoding = "UTF-8")
    
    # если пусто → оставляем пустую строку
    if (length(x) == 0) {
      one_line <- ""
    } else {
      # склеиваем все строки через пробел
      one_line <- paste(x, collapse = " ")
      # убираем лишние пробелы
      one_line <- gsub("\\s+", " ", one_line)
      one_line <- trimws(one_line)
    }
    
    # записываем обратно в файл
    writeLines(enc2utf8(one_line), f, useBytes = TRUE)
  }
  message("Готово: все txt-файлы приведены к одной строке")
}

# запускаем
fix_gt_txt("../ocr/orus-ground-truth") # ваш путь к файлу
```

```{r}
# проверяем
res <- tibble::tibble(
  file = list.files("../ocr/orus-ground-truth", pattern = "txt", full.names = TRUE),
  n_lines = purrr::map_int(gt, ~ length(readLines(.x, warn = FALSE)))
)

res |> 
  head()
```

### Проверка версий 

В терминале проверьте версию `make`.

```{r eval=FALSE}
# в терминале  / PowerShell
gmake --version # для MacOS
make --v # для Windows
```

На MacOS установить новую GNU Make можно через Homebrew (это менеджер пакетов, его надо отдельно поставить: <https://brew.sh/>):

```{r eval=FALSE}
# в терминале!
brew install make
```


На Windows задача также решается при помощи менеджера пакетов -- например, Scoop <https://scoop.sh/>. Поставьте Scoop через Powershell: 

```{r eval=FALSE}
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser

irm get.scoop.sh | iex
```

После этого выполните в PowerShell команду:

```{r eval=FALSE}
scoop install make
```

Как вариант, в Windows 10 и 11 возможна установка `make` без `scoop` или других менеджеров пакетов; для этого в PowerShell напишите `winget install ezwinports.make`.

:::{.callout-note icon = false}
В среде Windows можно использовать терминал RStudio, однако для этого предварительно потребуется установить [RTools](https://cran.r-project.org/bin/windows/Rtools/) и перезапустить RStudio.
:::

После установки снова проверьте версию `make`.

```{r eval=FALSE}
# в терминале  / PowerShell
gmake --version # для MacOS
make --v # для Windows
```


###  Дообучение

Задача этого шага — подготовить материалы, нужные для обучения `Tesseract`. Сначала скачиваем служебный проект `tesstrain`, потом — языковые данные.

1) Откройте терминал: 

- macOS: Terminal.
- Linux: любой терминал.
- Windows: используйте [WSL](https://learn.microsoft.com/en-us/windows/wsl/install). Это полноценный Linux внутри Windows. Подходит для команды `make`. Если это сложно, пока пропустите этот шаг. 

2) Скачайте проект tesstrain с GitHub.

```{r eval=FALSE}
git clone https://github.com/tesseract-ocr/tesstrain.git

# Cloning into 'tesstrain'...
# remote: Enumerating objects: 1119, done.
# remote: Counting objects: 100% (475/475), done.
# remote: Compressing objects: 100% (61/61), done.
# remote: Total 1119 (delta 440), reused 416 (delta 414), pack-reused 644 (from 2)
# Receiving objects: 100% (1119/1119), 13.53 MiB | 2.49 MiB/s, done.
# Resolving deltas: 100% (659/659), done.
```

После этого у вас появится папка `tesstrain`. В ней лежат скрипты и файл `Makefile` — он описывает, что и как делать для обучения.

3) Перейдите в папку tesstrain. Команда смены каталога `cd` также работает и на macOS, и на Windows.

```{r eval=FALSE}
cd tesstrain
```

4) Скачайте языковые данные для обучения

- На Linux/WSL/Windows  запускайте так:

```{r eval=FALSE}
make tesseract-langdata
```

- На macOS:

```{r eval=FALSE}
gmake tesseract-langdata
```

Команда `gmake tesseract-langdata` (или `make tesseract-langdata`)  запускает утилиту (небольшую программу) `make` и выполняет задачу `tesseract-langdata`, описанную в `Makefile` проекта. В результате автоматически скачиваются официальные языковые данные Tesseract, необходимые для обучения, а именно `langdata` и/или `langdata_lstm` — наборы текстов, списки слов, правила пунктуации/нормализации и прочие файлы, которые используются при подготовке и обучении модели. Одним словом, данные готовятся для обучения.
 
Если все хорошо, на экране забегают какие-то цифирки. Все нормально, подождите.

```{r eval=FALSE}
# Connecting to raw.githubusercontent.com... connected. HTTP request sent, awaiting response... OK... Saving to...
```


### Структура каталога

Итог: после этих ~~мучений~~ команд у вас есть локальная копия `tesstrain`, вы находитесь в её каталоге, и в него загружены исходные языковые данные (`data`), без которых обучение своей модели Tesseract **не запустится**. 

На этом этапе структура каталога выглядит так:

```{r echo=FALSE, eval=FALSE}
library(fs)
fs::dir_tree(path = "../tesstrain",
             recurse = TRUE)
```

```{r eval=FALSE}
# ../tesstrain
# ├── LICENSE
# ├── Makefile
# ├── README.md
# ├── count_chars.py
# ├── data
# │   └── langdata
# │       ├── Arabic.unicharset
# │       ├── Armenian.unicharset
# │       ├── Bengali.unicharset
# │       ├── ...
# │       └── radical-stroke.txt
# ├── generate_eval_train.py
# ├── generate_gt_from_box.py
# ├── generate_line_box.py
# ├── generate_line_syllable_box.py
# ├── generate_wordstr_box.py
# ├── normalize.py
# ├── ocrd-testset.zip
# ├── ocrd.plot_cer.png
# ├── plot_cer.py
# ├── plot_log.py
# ├── requirements.txt
# ├── shuffle.py
# └── src
#     ├── README.md
#     ├── setup.cfg
#     ├── setup.py
#     └── tesstrain
#         ├── __init__.py
#         ├── __main__.py
#         ├── arguments.py
#         ├── generate.py
#         ├── language_specific.py
#         └── wrapper.py
``` 

Теперь нам надо переместить обучающие данные -- в нашем случае это `orus-ground-truth` в папку `data`. Можете просто скопировать вручную. Все, можно запускать дообучение. 

```{r eval=FALSE}
# в терминале!
# make на Windows/WSL
gmake training MODEL_NAME=orus START_MODEL=rus FINETUNE_TYPE=Impact LANG_TYPE=Both
```

Команда выше запускает "рецепт" обучения нейросети Tesseract. Этот рецепт под названием `training` автоматически готовит данные и запускает процесс дообучения модели распознавания текста.

Что означает каждая часть команды:

- `gmake training` — запустить задание `training` из файла правил (`Makefile`). Оно скачает/подготовит данные, запустит обучение и положит результат в папку с моделями.
- `MODEL_NAME=orus` — имя новой модели, которую вы хотите получить. В конце появится файл вроде `orus.traineddata`.
- `START_MODEL=rus` — не учить с нуля, а взять за основу существующую русскую модель `rus` и "докрутить" ее под новые данные. Это быстрее и надежнее.
- `FINETUNE_TYPE=Impact` — "бережное" дообучение: меняются только части сети, чтобы сохранить сильные стороны базовой модели и адаптировать её под ваши тексты.
- `LANG_TYPE=Both` — использовать оба набора языковых данных Tesseract (классический и LSTM), чтобы шире покрыть правила, словари и примеры. 

Дообучение занимает несколько минут. Воспользуйтесь перерывом, чтобы похвалить себя за выполнение сложнейшей задачи. Вы инициировали дообучение нейросети вообще-то `r emo::ji("cool")`  `r emo::ji("cool")` `r emo::ji("cool")`

### Установка модели

Найдите системную папку Tesseract:

```{r}
tesseract::tesseract_info()$datapath
```

Скопируйте сюда новую модель `orus.trainedata`, которая должна появиться в папке `data` после обучения.

Проверьте доступные модели:

```{r}
tesseract::tesseract_info()$available
```

Теперь можем использовать новую модель:

```{r}
text3 <- pdf_ocr_text("../ocr/НЗ1821_6_6[50-51].pdf", language = "orus")
```

Снова запишем. 

```{r eval=FALSE}
# укажите свой путь или одно только имя
writeLines(text3, con = "../ocr/rosalia_3.txt")
```

Эти тексты можно будет использовать для сравнения моделей. Для лучшего результата используйте больше обучающих данных.

Таким образом, дообучение Tesseract позволяет улучшить качество распознавания специализированных текстов;  Пакет `tesseractgt` существенно упрощает процесс подготовки обучающих данных.

## Видео к этому уроку

```{r echo=FALSE}
library(cowsay)
say("Будет добавлено позже", "egret")
```

## Домашнее задание

```{r echo=FALSE}
say("Будет добавлено позже", "owl")
```